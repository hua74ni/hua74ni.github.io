<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[rabbitMQ入门及应用]]></title>
    <url>%2F2018%2F08%2F16%2FrabbitMQ%E5%85%A5%E9%97%A8%E5%8F%8A%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[摘要: rabbitMQ入门及应用，此次学习在windows 10上。 rabbitMQ安装rabbit下载地址： rabbitmq官网 note: 下载rabbitmq之前，需要先下载安装rabbitmq需要的对应版本的erlang，并且先启动。需要配置 系统变量 N：ERLANG_HOME V：E:\erl10.0.1(erl对应的路径地址)再在 系统变量path中配置 %ERLANG_HOME%\bin; 即可。 rabbitMQ启动 启动rabbitMQ前，先验证erlang配置及启动是否正常。 在终端中：erl -v返回的结果：Eshell V10.0.1 (abort with ^G) 启动rabbit对应的命令 cd 到rabbitmq对应的路径中(rabbitmq_server-3.7.7\sbin) 再执行以下命令即可1.启动界面管理工具所需的插件rabbitmq-plugins enable rabbitmq_management2.启动rabbitmq服务rabbitmq-server.bat rabbitMQ应用 在此我就不粘贴出对应的demo了，因为官方的demo写的已经很好，大家只要对应学习rabbit版本的官方的demo即可。 自己写的demo代码位置在github上 hua74ni/daily_learning rabbitmq官方demo rabbitMQ学习中遇到的坑 直接启动rabbitmq-server.bat,会报以下的错误： Rabbit 启动报错 ERROR: distribution port 25672 in use on DESKTOP-GF3HC1K (by non-Erlang process?) 解决方案:原以为是 erl出了问题，在dos执行erl没问题，这时候回头锁定应该是rabbitMQ启动的问题了。在每次执行rabbit-server.bat 之前需要先执行 rabbitmq-plugins enable rabbitmq_management启动 rabbitmq需要的rabbitmq的一部分插件才可以正常启动rabbitmq服务。]]></content>
      <categories>
        <category>消息中间件</category>
      </categories>
      <tags>
        <tag>rabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[solr入门与应用]]></title>
    <url>%2F2018%2F08%2F12%2Fsolr%E5%85%A5%E9%97%A8%E4%B8%8E%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[摘要: solr入门与应用，本次学习solr的版本为5.5.5 前沿本次学习solr的版本为5.5.5。solr5.5.5版本下载地址solr5.5的版本后，不支持中文分词。使用的中文分词器是ik中文分词器下载地址 使用tomcat8。 note：tgz压缩格式常用于Unix的操作系统，而zip的压缩格式常用于windows的操作系统。 solr安装solr安装配置 解压后，将 solr5.5.5 目录下的 server/solr-webapp/webapp 重命名为solr放在 tomcat/webapps/ 文件夹中 在 tomcat/webapps/solr/ 文件夹中创建solrHome文件夹 打开 tomcat/webapps/solr/WEB-INF/web.xml ，并配置 solr/home 在 tomcat/webapp/solr/WEB-INF/ 文件夹中，创建classes文件夹 把 solr5.5.5/server/resource/log4j.properties 复制到上一步建立的classes目录中 把solr5.5.5/server/lib/ext/目录下的所有jar文件复制到tomcat/webapp/solr/WEB-INF/lib/中，这是一些日志用的jar包，不然启动报错。 启动tomcat，输入http://127.0.0.1:8080/solr/admin.html来访问到solr的控制界面了。 在 tomcat/solr/solrHome/ 文件夹中创建new_core文件夹。这是我们的一个core实例，然后把 solr5.5.5/server/solr/configsets/sample_techproducts_configs/conf/ 这个文件夹复制到 solrHome/new_core 中。 把 solr5.5.5/server/solr/solr.xml 复制到solrHome目录下。 在solr的管理控制台界面，添加一个new_core 这时就创建成功一个new_core的实例了。 安装Ik中文分词器 下载完IK中文词器后，cd到对应文件夹目录中，使用maven命令mvn install,将生存的jar包复制到 tomcat/webapp/solr/WEB-INF/lib/ 文件夹中。 打开 solrHome/new_core/conf/managed-schema 文件，在最下方，追加如下配置 启动tomcat，即可看到text_ik分词 插入文档我们可以在Documents中插入文本，这是一种Json格式的文本，字段分别是id、title，id为主键唯一性。这些对应的字段需要在前面提到的 managed-schema文件中被定义，才可以被插入成功，类似于数据库的概念。插入失败也就是按着这个思路进行排查错误，这里就不多说了。 12345&lt;field name=&quot;title&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot; /&gt;&lt;field name=&quot;id&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot; required=&quot;true&quot; multiValued=&quot;false&quot; /&gt;&lt;!-- 主键即唯一性 --&gt;&lt;uniqueKey&gt;id&lt;/uniqueKey&gt; 介绍下managed-schema中域的定义 在managed-schema这个文件中包含了 field 、 dynamicField 、 uniqueKey 、 copyField 、 fieldType 域的定义 field&lt;field name=&quot;id&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot; required=&quot;true&quot; multiValued=&quot;false&quot; /&gt; name： 域名 type： 域的类型，必须匹配类型，否则报错 indexed： 是否作为索引 stored： 是否存储 required： 是否必填，一般就主键需要，类似于 数据库的不为空 multiValued： 是否可以多值，以数组形式来存储，比如 商品图片地址(大图，中图，小图等) 配置动态域 dynamicField&lt;dynamicField name=&quot;*_i&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;true&quot; /&gt; name:域的名称，该域的名称是通过一个表达式来指定的，只要符合这这个规则，就可以使用这个域。比如 aa_i,bb_i,13_i等等，只要满足这个表达式皆可 type： 域的类型，必须匹配类型，否则报错 其余的和普通域一致 主键域 uniqueKey 指定一个唯一的主键，每一个文档中，都应该有一个唯一的主键，这个值不要随便改&lt;uniqueKey&gt;id&lt;/uniqueKey&gt; 复制域 copyField&lt;copyField source=&quot;cat&quot; dest=&quot;text&quot;/&gt; source: 源域dest:目标域复制域，将源域的内容复制到目标域中note: 作为目标域必须设置为允许多值，可能多个源域对应一个目标域，所以它需要以数组来存储。 域的类型 fieldType 1234567891011121314151617&lt;fieldType name=&quot;text_general&quot; class=&quot;solr.TextField&quot; positionIncrementGap=&quot;100&quot;&gt; &lt;analyzer type=&quot;index&quot;&gt; &lt;tokenizer class=&quot;solr.StandardTokenizerFactory&quot;/&gt; &lt;filter class=&quot;solr.StopFilterFactory&quot; ignoreCase=&quot;true&quot; words=&quot;stopwords.txt&quot; /&gt; &lt;!-- in this example, we will only use synonyms at query time &lt;filter class=&quot;solr.SynonymFilterFactory&quot; synonyms=&quot;index_synonyms.txt&quot; ignoreCase=&quot;true&quot; expand=&quot;false&quot;/&gt; --&gt; &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt; &lt;/analyzer&gt; &lt;analyzer type=&quot;query&quot;&gt; &lt;tokenizer class=&quot;solr.StandardTokenizerFactory&quot;/&gt; &lt;filter class=&quot;solr.StopFilterFactory&quot; ignoreCase=&quot;true&quot; words=&quot;stopwords.txt&quot; /&gt; &lt;filter class=&quot;solr.SynonymFilterFactory&quot; synonyms=&quot;synonyms.txt&quot; ignoreCase=&quot;true&quot; expand=&quot;true&quot;/&gt; &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt; &lt;/analyzer&gt;&lt;/fieldType&gt; 对应的属性说明 name: 域的名称 class: 指定solr的类型 analyzer: 分词器的配置 type: index(索引分词器)，query(查询分词器) tokenizer: 配置分词器 filter: 过滤器 业务实际应用entity: Subject managed-schema 文件中的 field 定义 123456789101112&lt;field name=&quot;title&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot; /&gt;&lt;field name=&quot;casts&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot; /&gt;&lt;!-- 先定义一个目标域 --&gt;&lt;field name=&quot;keywords&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;false&quot; multiValued=&quot;true&quot;/&gt; &lt;copyField source=&quot;title&quot; dest=&quot;keywords&quot;/&gt;&lt;copyField source=&quot;casts&quot; dest=&quot;keywords&quot;/&gt;通过对 keywords 传参数可实现 中文分词 以及 对 2个字段同时进行搜索的功能。类似于 中国你好 拆分为 中国 你好。title like &apos;%参数中文分词数组%&apos; or casts like &apos;%参数中文分词数组%&apos;. dataimport 导入数据库数据solr默认是没有开启dataimport这个功能的，所以我们要经过一点配置来开启它 首先找到 solr5.5.5/dist/solr-dataimporthandler-5.5.5.jar ，把这个文件复制到 tomcat/webapp/solr/WEB-INF/lib/ 文件夹中下，并且找到相应数据库的驱动包，也同样放到该目录。我这里用的是mysql的驱动包。 找到 solr5.5.5/example/example-DIH/solr/db/conf/db-data-config.xml，把其复制到 solrHome/new_core/conf/ 下，并改名为data-config.xml. 找到solrHome/new_core/conf/solrconfig.xml，并打开,在里面添加一段内容 123456&lt;requestHandler name=&quot;/dataimport&quot; class=&quot;solr.DataImportHandler&quot;&gt; &lt;lst name=&quot;defaults&quot;&gt; &lt;str name=&quot;config&quot;&gt;data-config.xml&lt;/str&gt; &lt;/lst&gt;&lt;/requestHandler&gt;``` 打开并编辑data-config.xml，完整的配置文件如下 1234567891011121314151617&lt;dataConfig&gt; &lt;dataSource type=&quot;JdbcDataSource&quot; driver=&quot;com.mysql.jdbc.Driver&quot; url=&quot;jdbc:mysql://127.0.0.1:3306/movie&quot; user=&quot;xxx&quot; password=&quot;xxx&quot; /&gt; &lt;document name=&quot;subjects&quot;&gt; &lt;entity name=&quot;subject&quot; transformer=&quot;ClobTransformer&quot; query=&quot;select * from subject &quot;&gt; &lt;!-- 每一个field映射着数据库中列与文档中的域，column是数据库列，name是solr的域(必须是在managed-schema文件中配置过的域才行) --&gt; &lt;field column=&quot;id&quot; name=&quot;id&quot;/&gt; &lt;field column=&quot;year&quot; name=&quot;year&quot;/&gt; &lt;field column=&quot;genres&quot; name=&quot;genres&quot;/&gt; &lt;field column=&quot;countries&quot; name=&quot;countries&quot;/&gt; &lt;field column=&quot;rating&quot; name=&quot;rating&quot;/&gt; &lt;field column=&quot;casts&quot; name=&quot;casts&quot;/&gt; &lt;field column=&quot;title&quot; name=&quot;title&quot;/&gt; &lt;field column=&quot;commentCount&quot; name=&quot;commentCount&quot;/&gt; &lt;field column=&quot;pubDate&quot; name=&quot;pubDate&quot;/&gt; &lt;/entity&gt; &lt;/document&gt;&lt;/dataConfig&gt; 重启tomcat，可以看到dataimport功能有了，按照以上配置，进入dataimport界面，然后点击Execute，再点击Refresh Status,状态显示绿色表明成功了。 solrj的使用pom.xml 123456&lt;!-- solr 全文检索 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.solr&lt;/groupId&gt; &lt;artifactId&gt;solr-solrj&lt;/artifactId&gt; &lt;version&gt;5.5.5&lt;/version&gt;&lt;/dependency&gt; solrj的应用代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172public class SolrJTest &#123; //指定solr服务器的地址 private final static String SOLR_URL = &quot;http://localhost:8080/solr/new_core&quot;; /** * 创建SolrServer对象 * * 该对象有两个可以使用，都是线程安全的 * 1、CommonsHttpSolrServer：启动web服务器使用的，通过http请求的 * 2、 EmbeddedSolrServer：内嵌式的，导入solr的jar包就可以使用了 * 3、solr 4.0之后好像添加了不少东西，其中CommonsHttpSolrServer这个类改名为HttpSolrClient * * @return */ public HttpSolrClient createSolrServer()&#123; HttpSolrClient solr = null; solr = new HttpSolrClient(SOLR_URL); return solr; &#125; /** * 往索引库添加文档 * @throws IOException * @throws SolrServerException */ public void addDoc() throws SolrServerException, IOException&#123; //构造一篇文档 SolrInputDocument document = new SolrInputDocument(); //往doc中添加字段,在客户端这边添加的字段必须在服务端中有过定义 document.addField(&quot;id&quot;, &quot;8&quot;); document.addField(&quot;name&quot;, &quot;周新星&quot;); document.addField(&quot;description&quot;, &quot;一个灰常牛逼的军事家&quot;); //获得一个solr服务端的请求，去提交 ,选择具体的某一个solr core HttpSolrClient solr = new HttpSolrClient(SOLR_URL); solr.add(document); solr.commit(); solr.close(); &#125; /** * 根据id从索引库删除文档 */ public void deleteDocumentById() throws Exception &#123; //选择具体的某一个solr core HttpSolrClient server = new HttpSolrClient(SOLR_URL); //删除文档 server.deleteById(&quot;8&quot;); //删除所有的索引 //solr.deleteByQuery(&quot;*:*&quot;); //提交修改 server.commit(); server.close(); &#125; /** * 查询 * @throws Exception */ public void querySolr() throws Exception&#123; HttpSolrClient solrServer = new HttpSolrClient(SOLR_URL); SolrQuery query = new SolrQuery(); String key = &quot;中国你好&quot;; //下面设置solr查询参数 //query.set(&quot;q&quot;, &quot;*:*&quot;);// 参数q 查询所有 query.set(&quot;q&quot;,&quot;keywords:&quot;+key);//相关查询，比如某条数据某个字段含有周、星、驰三个字 将会查询出来 ，这个作用适用于联想查询 //参数fq, 给query增加过滤查询条件// query.addFilterQuery(&quot;id:[0 TO 9]&quot;);//id为0-4 //给query增加布尔过滤条件 query.addFilterQuery(&quot;year:&quot;+&quot;2015&quot;); //description字段中含有“演员”两字的数据 query.addFilterQuery(&quot;genres:&quot;+&quot;动作&quot;); //description字段中含有“演员”两字的数据 query.addFilterQuery(&quot;countries:&quot;+&quot;美国&quot;); //description字段中含有“演员”两字的数据 //参数df,给query设置默认搜索域// query.set(&quot;df&quot;, &quot;name&quot;); //参数sort,设置返回结果的排序规则 query.setSort(&quot;rating&quot;,SolrQuery.ORDER.desc);// query.setSort(&quot;pubDate&quot;,SolrQuery.ORDER.desc);// query.setSort(&quot;commentCount&quot;,SolrQuery.ORDER.desc); //设置分页参数 query.setStart(0); query.setRows(10);//每一页多少值 //参数hl,设置高亮 query.setHighlight(true); //设置高亮的字段 query.addHighlightField(&quot;title&quot;); //设置高亮的样式 query.setHighlightSimplePre(&quot;&lt;font color=&apos;red&apos;&gt;&quot;); query.setHighlightSimplePost(&quot;&lt;/font&gt;&quot;); //获取查询结果 QueryResponse response = solrServer.query(query); //两种结果获取：得到文档集合或者实体对象 //查询得到文档的集合 SolrDocumentList solrDocumentList = response.getResults(); System.out.println(&quot;通过文档集合获取查询的结果&quot;); System.out.println(&quot;查询结果的总数量：&quot; + solrDocumentList.getNumFound()); //遍历列表 for (SolrDocument doc : solrDocumentList) &#123; System.out.println(&quot;id:&quot;+doc.get(&quot;id&quot;)+&quot; title:&quot;+doc.get(&quot;title&quot;)+&quot; casts:&quot;+doc.get(&quot;casts&quot;) +&quot; pubDate:&quot;+doc.get(&quot;pubDate&quot;)); &#125; //得到实体对象 List&lt;Subject&gt; tmpLists = (List&lt;Subject&gt;) toBeanList(solrDocumentList,Subject.class); if(tmpLists!=null &amp;&amp; tmpLists.size()&gt;0)&#123; System.out.println(&quot;通过文档集合获取查询的结果&quot;); for(Subject subject:tmpLists)&#123; System.out.println(subject.toString()); &#125; &#125; &#125; /** * 将SolrDocument转换成Bean * @param record * @param clazz * @return */ public static Object toBean(SolrDocument record, Class clazz)&#123; Object obj = null; try &#123; obj = clazz.newInstance(); Field[] fields = clazz.getDeclaredFields(); for(Field field:fields)&#123; Object value = record.get(field.getName()); if(value != null)&#123; BeanUtils.setProperty(obj, field.getName(), value); &#125; &#125; &#125; catch (InstantiationException e1) &#123; e1.printStackTrace(); &#125; catch (IllegalAccessException e1) &#123; e1.printStackTrace(); &#125; catch (InvocationTargetException e) &#123; e.printStackTrace(); &#125; return obj; &#125; /** * 将SolrDocumentList转换成BeanList * @param records * @param clazz * @return */ public static Object toBeanList(SolrDocumentList records, Class clazz)&#123; List list = new ArrayList(); for(SolrDocument record : records)&#123; list.add(toBean(record,clazz)); &#125; return list; &#125; public static void main(String[] args) throws Exception &#123; SolrJTest solr = new SolrJTest(); //solr.createSolrServer();// solr.addDoc();// solr.deleteDocumentById(); solr.querySolr(); &#125;&#125; 最后，查询涉及到的参数查询稍微复杂一点，但是与solr管理界面的条件一致 这里先给出一些查询的说明，建议查看这篇文章，个人感觉还是不错的http://blog.csdn.net/gufengshanyin/article/details/21098879 q - 查询字符串，如果查询所有: (id:1) fq - （filter query）过虑查询，过滤条件，基于查询出来的结果 fl - 指定返回那些字段内容，用逗号或空格分隔多个。 start - 分页开始 rows - 分页查询数据 sort - 排序，格式：sort=+[,+]… 。示例：（score desc, price asc）表示先 “score” 降序, 再 “price” 升序，默认是相关性降序。 wt - (writer type)指定输出格式，可以有 xml, json, php, phps。 fl表示索引显示那些field( *表示所有field,如果想查询指定字段用逗号或空格隔开（如：Name,SKU,ShortDescription或Name SKU ShortDescription【注：字段是严格区分大小写的】）) q.op 表示q 中 查询语句的 各条件的逻辑操作 AND(与) OR(或) hl 是否高亮 ,如hl=true hl.fl 高亮field ,hl.fl=Name,SKU hl.snippets :默认是1,这里设置为3个片段 hl.simple.pre 高亮前面的格式 hl.simple.post 高亮后面的格式 facet 是否启动统计 facet.field 统计field “:” 指定字段查指定值，如返回所有值: “?” 表示单个任意字符的通配 “” 表示多个任意字符的通配（不能在检索的项开始使用或者?符号） “~” 表示模糊检索，如检索拼写类似于”roam”的项这样写：roam~将找到形如foam和roams的单词；roam~0.8，检索返回相似度在0.8以上的记录。 邻近检索，如检索相隔10个单词的”apache”和”jakarta”，”jakarta apache”~10 “^” 控制相关度检索，如检索jakarta apache，同时希望去让”jakarta”的相关度更加好，那么在其后加上”^”符号和增量值，即jakarta^4 apache 布尔操作符AND、|| 布尔操作符OR、&amp;&amp; 布尔操作符NOT、!、- （排除操作符不能单独与项使用构成查询） “+” 存在操作符，要求符号”+”后的项必须在文档相应的域中存在 ( ) 用于构成子查询 [] 包含范围检索，如检索某时间段记录，包含头尾，date:[200707 TO 200710] 本篇参考学习solr教程 - 朱小杰 - 博客园]]></content>
      <categories>
        <category>搜索引擎</category>
      </categories>
      <tags>
        <tag>solr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Storm集成kafka应用]]></title>
    <url>%2F2018%2F08%2F10%2FStorm%E9%9B%86%E6%88%90kafka%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[摘要: Storm集成kafka应用 Storm集成kafka应用我们知道storm的作用主要是进行流式计算，对于源源不断的均匀数据流流入处理是非常有效的，而现实生活中大部分场景并不是均匀的数据流，而是时而多时而少的数据流入，这种情况下显然用批量处理是不合适的，如果使用storm做实时计算的话可能因为数据拥堵而导致服务器挂掉，应对这种情况，使用kafka作为消息队列是非常合适的选择，kafka可以将不均匀的数据转换成均匀的消息流，从而和storm比较完善的结合，这样才可以实现稳定的流式计算，那么我们接下来开发一个简单的案例来实现storm和kafka的结合。 storm和kafka结合，实质上无非是之前我们说过的计算模式结合起来，就是数据先进入kafka生产者，然后storm作为消费者进行消费，最后将消费后的数据输出或者保存到文件、数据库、分布式存储等等，具体框图如下： 之前的文章都起到了storm、kafka的介绍和应用，当然这2者运行都需要依赖于zookeeper，因此首先启动zookeeper正常启动后，再启动kafka、storm。具体的命令也就不再重复写了，需要的话可以早之前写文章。 再执行下面的代码时，需要在zookeeper、storm做一些提前的准备。首先确保 kafka订阅的topic配置在zookeeper的节点目录(在过程中没搞懂这折腾了半个小时，关键还是没深入了解zookeeper。)这里topic配置在zookeeper的’/kafka’的节点目录，代码中zookeeper的节点目录是用’/‘根目录。kafka对应的 执行命令kafka服务在zookeeper节点目录’/kafka’创建一个topic 一个备份、一个分区.\bin\windows\kafka-topic.bat –create –zookeeper localhost:2181/kafka –replication-factor 1 –partitions 1 –topic topic生产者发送topic的消息.\bin\windows\kafka-console-producer.bat –broker-list localhost:9092/kafka –topic test note：创建zookeeper’/kafka’节点目录代码123456789101112131415161718192021public class ZookeeperDemo &#123; private static final int SESSION_TIMEOUT = 3000; public static void main(String[] args) &#123; try &#123; ZooKeeper zooKeeper = new ZooKeeper(&quot;127.0.0.1:2181&quot;, SESSION_TIMEOUT, new Watcher() &#123; @Override public void process(WatchedEvent event) &#123; System.out.println(&quot;触发事件：&quot; + event.getType()); &#125; &#125;); zooKeeper.create(&quot;/kafka&quot;, &quot;test&quot;.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); System.out.println(new String(zooKeeper.getData(&quot;/kafka&quot;, true, null))); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;kafkastorm&lt;/groupId&gt; &lt;artifactId&gt;kafkastorm&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;kafkastorm&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.storm&lt;/groupId&gt; &lt;artifactId&gt;storm-core&lt;/artifactId&gt; &lt;version&gt;0.9.6&lt;/version&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka_2.9.2&lt;/artifactId&gt; &lt;version&gt;0.8.2.2&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.storm&lt;/groupId&gt; &lt;artifactId&gt;storm-kafka&lt;/artifactId&gt; &lt;version&gt;0.9.6&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; MessageScheme.java123456789101112131415161718192021public class MessageScheme implements Scheme &#123; @Override public List&lt;Object&gt; deserialize(byte[] bytes) &#123; try &#123; String msg = new String(bytes, &quot;UTF-8&quot;); return new Values(msg); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; return null; &#125; @Override public Fields getOutputFields() &#123; return new Fields(&quot;msg&quot;); &#125;&#125; SenqueceBolt.java123456789101112131415161718192021222324252627282930313233public class SenqueceBolt extends BaseBasicBolt &#123; @Override public void execute(Tuple tuple, BasicOutputCollector basicOutputCollector) &#123; String word = (String) tuple.getValue(0); String out = &quot;output:&quot; + word; System.out.println(out); DataOutputStream outputStream = null; try &#123; outputStream = new DataOutputStream(new FileOutputStream(&quot;kafkastorm.out&quot;)); outputStream.writeUTF(out); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; outputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; basicOutputCollector.emit(new Values(out)); &#125; @Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) &#123; outputFieldsDeclarer.declare(new Fields(&quot;message&quot;)); &#125;&#125; StormKafkaTopo.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class StormKafkaTopo &#123; public static void main(String[] args) &#123; // 配置Zookeeper地址 BrokerHosts brokerHosts = new ZkHosts(&quot;127.0.0.1:2181&quot;); // 配置Kafka订阅的Topic，以及zookeeper中数据节点目录和名字 SpoutConfig spoutConfig = new SpoutConfig(brokerHosts,&quot;topic&quot;,&quot;&quot;,&quot;kafkaspout&quot;); // 配置KafkaBolt中的kafka.broker.properties Config config = new Config(); Map&lt;String,String&gt; map = new HashMap&lt;String, String&gt;(); // 配置Kafka broker地址 map.put(&quot;metadata.broker.list&quot;, &quot;127.0.0.1:9092&quot;); // serializer.class为消息的序列化类 map.put(&quot;serializer.class&quot;, &quot;kafka.serializer.StringEncoder&quot;); config.put(&quot;kafka.broker.properties&quot;, map); config.put(&quot;topic&quot;, &quot;topic2&quot;); spoutConfig.scheme = new SchemeAsMultiScheme(new MessageScheme()); TopologyBuilder builder = new TopologyBuilder(); builder.setSpout(&quot;spout&quot;, new KafkaSpout(spoutConfig)); builder.setBolt(&quot;bolt&quot;, new SenqueceBolt()).shuffleGrouping(&quot;spout&quot;); builder.setBolt(&quot;kafkabolt&quot;, new KafkaBolt&lt;String, Integer&gt;()).shuffleGrouping(&quot;bolt&quot;); if(args != null &amp;&amp; args.length &gt; 0)&#123; //提交到集群运行 try&#123; StormSubmitter.submitTopology(args[0], config, builder.createTopology()); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; else &#123; // 本地模式运行 LocalCluster localCluster = new LocalCluster(); localCluster.submitTopology(&quot;Topotest1121&quot;, config, builder.createTopology()); Utils.sleep(1000000); localCluster.killTopology(&quot;Topotest1121&quot;); localCluster.shutdown(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>消息中间件</category>
      </categories>
      <tags>
        <tag>storm-kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[storm入门学习]]></title>
    <url>%2F2018%2F08%2F09%2Fstorm%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[摘要: storm入门学习 Storm 基础知识Storm 是一个分布式的，可靠的，容错的数据流处理系统。它会把工作任务委托给不同类型的组件，每个组件负责处理一项简单特定的任务。Storm 集群的输入流由一个被称作 spout 的组件管理，spout 把数据传递给 bolt， bolt 要么把数据保存到某种存储器，要么把数据传递给其它的 bolt。你可以想象一下，一个 Storm 集群就是在一连串的 bolt 之间转换 spout 传过来的数据。 这里用一个简单的例子来说明这个概念。昨晚我在新闻节目里看到主持人在谈论政治人物和他们对于各种政治话题的立场。他们一直重复着不同的名字，而我开始考虑这些名字是否被提到了相同的次数，以及不同次数之间的偏差。 在 Storm 集群中，有两类节点：主节点 master node 和工作节点 worker nodes。主节点运行着一个叫做 Nimbus 的守护进程。这个守护进程负责在集群中分发代码，为工作节点分配任务，并监控故障。Supervisor守护进程作为拓扑的一部分运行在工作节点上。一个 Storm 拓扑结构在不同的机器上运行着众多的工作节点。 Storm 的特性 简化编程：如果你曾试着从零开始实现实时处理，你应该明白这是一件多么痛苦的事情。使用 Storm，复杂性被大大降低了。 使用一门基于 JVM 的语言开发会更容易，但是你可以借助一个小的中间件，在 Storm 上使用任何语言开发。有现成的中间件可供选择，当然也可以自己开发中间件。 容错：Storm 集群会关注工作节点状态，如果宕机了必要的时候会重新分配任务。 可扩展：所有你需要为扩展集群所做的工作就是增加机器。Storm 会在新机器就绪时向它们分配任务。 可靠的：所有消息都可保证至少处理一次。如果出错了，消息可能处理不只一次，不过你永远不会丢失消息。 快速：速度是驱动 Storm 设计的一个关键因素。 事务性：You can get exactly once messaging semantics for pretty much any computation. 你可以为几乎任何计算得到恰好一次消息语义。 便于理解的demo这个demo使用版本为0.6.0的storm。 从works.txt文本中获取单词，将获取出来的单词进行数量的统计。spout (WorkReader) 负责将单词从 works.txt文本中获取出来，获取的方式：文本每次获取一行，就将单词数量统计的任务往下分发。这里创建2个bolt (WordNormalizer、WordCounter) ，一个负责格式化每个从spout获取到一行的单词，将一行的单词去掉前后空格，分解为一个个独立的单词，后分发给另外一个bolt，这个bolt用来做统计单词的数量。启动项 TopologyMain pom.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.hdh&lt;/groupId&gt; &lt;artifactId&gt;storm&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;storm Maven Webapp&lt;/name&gt; &lt;!-- FIXME change it to the project&apos;s website --&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Storm Dependency --&gt; &lt;dependency&gt; &lt;groupId&gt;storm&lt;/groupId&gt; &lt;artifactId&gt;storm&lt;/artifactId&gt; &lt;version&gt;0.6.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;storm&lt;/finalName&gt; &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/plugin&gt; &lt;!-- see http://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_war_packaging --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.6&lt;/source&gt; &lt;target&gt;1.6&lt;/target&gt; &lt;compilerVersion&gt;1.6&lt;/compilerVersion&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt; WorkReader1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class WorkReader implements IRichSpout &#123; private SpoutOutputCollector collector; private FileReader fileReader; private boolean computed = false; private TopologyContext context; @Override public boolean isDistributed() &#123; return false; &#125; @Override public void open(Map map, TopologyContext topologyContext, SpoutOutputCollector spoutOutputCollector) &#123; this.context = topologyContext; this.collector = spoutOutputCollector; try &#123; this.fileReader = new FileReader(map.get(&quot;wordsFile&quot;).toString()); &#125; catch (FileNotFoundException e) &#123; throw new RuntimeException(&quot;Error reading file [&quot;+map.get(&quot;wordFile&quot;)+&quot;]&quot;); &#125; &#125; @Override public void close() &#123;&#125; /** * 这个方法做的惟一一件事情就是分发文件中的文本行 */ @Override public void nextTuple() &#123; /** * 这个方法会不断的被调用，直到整个文件都读完了，我们将等待并返回。 */ if (computed)&#123; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return; &#125; String str; BufferedReader bufferedReader = new BufferedReader(fileReader); try&#123; while((str = bufferedReader.readLine()) != null)&#123; /** * 按行发布一个新值 */ this.collector.emit(new Values(str)); &#125; &#125;catch (Exception e)&#123; throw new RuntimeException(&quot;Error reading tuple&quot;,e); &#125;finally &#123; computed = true; &#125; &#125; @Override public void ack(Object msgId) &#123; System.out.println(&quot;OK:&quot; + msgId); &#125; @Override public void fail(Object msgId) &#123; System.out.println(&quot;FAIL:&quot; + msgId); &#125; /** * 声明输入域&quot;word&quot; */ @Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) &#123; outputFieldsDeclarer.declare(new Fields(&quot;line&quot;)); &#125;&#125; WordNormalizer12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class WordNormalizer implements IRichBolt &#123; private OutputCollector collector; @Override public void prepare(Map map, TopologyContext topologyContext, OutputCollector outputCollector) &#123; this.collector = outputCollector; &#125; /** * *bolt*从单词文件接收到文本行，并标准化它。 * 文本行会全部转化成小写，并切分它，从中得到所有单词。 */ @Override public void execute(Tuple tuple) &#123; String sentence = tuple.getString(0); String [] words = sentence.split(&quot; &quot;); for (String word: words) &#123; word = word.trim(); if(!word.isEmpty())&#123; //发布这个单词 word = word.toLowerCase(); /** * 调用中发布0~N元组 * 如果这个方法在一次调用中接收到句子 “This is the Storm book”，它将会发布五个元组。 */ collector.emit(new Values(word)); &#125; &#125; /** * 收到 spout的分配的任务 * 对元组做出应答 */ collector.ack(tuple); &#125; @Override public void cleanup() &#123; &#125; @Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) &#123; // 声明输出域 outputFieldsDeclarer.declare(new Fields(&quot;word&quot;)); &#125;&#125; WordCounter12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class WordCounter implements IRichBolt &#123; Integer id; String name; Map&lt;String,Integer&gt; counters; private OutputCollector collector; private static final String SIGNALS = &quot;signals&quot;; private static final String ACTION = &quot;refreshCache&quot;; @Override public void prepare(Map map, TopologyContext topologyContext, OutputCollector outputCollector) &#123; this.counters = new HashMap&lt;String, Integer&gt;(); this.name = topologyContext.getThisComponentId(); this.id = topologyContext.getThisTaskId(); this.collector = outputCollector; &#125; @Override public void execute(Tuple tuple) &#123; String str = null; try&#123; str = tuple.getStringByField(&quot;word&quot;); &#125;catch (IllegalArgumentException e) &#123; //Do nothing &#125; if(str != null)&#123; if(!this.counters.containsKey(str))&#123; counters.put(str,1); &#125;else&#123; Integer c = counters.get(str); counters.put(str,c + 1); &#125; &#125; // 全部数据流组 清理计算器操作// else &#123;//// if((SIGNALS).equals(tuple.getSourceGlobalStreamid().get_streamId()))&#123;// str = tuple.getStringByField(&quot;action&quot;);// if(ACTION.equals(str))&#123;// counters.clear();// &#125;// &#125;//// &#125; //对元组作为应答 collector.ack(tuple); &#125; /** * 通常情况下，当拓扑关闭时，你应当使用 cleanup() 方法关闭活动的连接和其它资源。 */ @Override public void cleanup() &#123; System.out.println(&quot;-- 单词数 【&quot; + name + &quot;-&quot; + id +&quot;】 --&quot;); for(Map.Entry&lt;String,Integer&gt; entry : counters.entrySet())&#123; System.out.println(entry.getKey() + &quot;: &quot; + entry.getValue()); &#125; &#125; @Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) &#123; &#125;&#125; ## TopologyMain 拓扑启动项 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class TopologyMain &#123; public static void main(String[] args) throws InterruptedException &#123; // 定义拓扑 TopologyBuilder builder = new TopologyBuilder(); builder.setSpout(&quot;word-reader&quot;,new WorkReader()); // 全部数据流组 builder.setSpout(&quot;signals-spout&quot;, new SignalsSpout()); /** 随机数据流组指定数据源 * shuffleGrouping 随机消费 来自 word-reader的数据 * * note: 每个 InputDeclarer 可以有一个以上的数据源，而且每个数据源可以分到不同的组。 */ builder.setBolt(&quot;word-normalizer&quot;,new WordNormalizer()) // 自定义数据流组 .customGrouping(&quot;word-reader&quot; , new ModuleGrouping());// .shuffleGrouping(&quot;word-reader&quot;); /** 域数据流组 * 域数据流组允许你基于元组的一个或多个域控制如何把元组发送给 com.storm1.banktransactions。 * 单词计数器的例子，如果你用 word 域为数据流分组， * word-normalizer bolt 将只会把相同单词的元组发送给同一个 word-counterbolt 实例。 * fieldsGrouping 声明了 &quot;word&quot;的控制域 */ builder.setBolt(&quot;word-counter&quot;,new WordCounter(),2) .fieldsGrouping(&quot;word-normalizer&quot;,new Fields(&quot;word&quot;)); // 全部数据流组// .allGrouping(&quot;signals-spout&quot; , &quot;signals&quot;);// builder.setBolt(&quot;word-counter&quot;,new WordCounter(),2).shuffleGrouping(&quot;word-normalizer&quot;); //配置 Config config = new Config();// config.put(&quot;wordsFile&quot;,args[0]); config.put(&quot;wordsFile&quot;,&quot;src/main/resources/words.txt&quot;); config.setDebug(false); //运行拓扑 config.put(Config.TOPOLOGY_MAX_SPOUT_PENDING, 1); LocalCluster cluster = new LocalCluster(); cluster.submitTopology(&quot;Getting-started-Topologie&quot;, config, builder.createTopology()); Thread.sleep(2000); cluster.shutdown(); &#125;&#125; Storm知识点Storm 拓扑数据流组设计一个拓扑时，你要做的最重要的事情之一就是定义如何在各组件之间交换数据（数据流是如何被 bolts 消费的）。一个据数流组指定了每个 bolt 会消费哪些数据流，以及如何消费它们。 NOTE：一个节点能够发布一个以上的数据流，一个数据流组允许我们选择接收哪个。 12builder.setBolt(&quot;word-normalizer&quot;, new WordNormalizer()) .shuffleGrouping(&quot;word-reader&quot;); 在前面的代码块里，一个 bolt 由 TopologyBuilder 对象设定， 然后使用随机数据流组指定数据源。数据流组通常将数据源组件的 ID 作为参数，取决于数据流组的类型不同还有其它可选参数。 NOTE：每个 InputDeclarer 可以有一个以上的数据源，而且每个数据源可以分到不同的组。 随机数据流组 (shuffleGrouping)随机流组是最常用的数据流组。它只有一个参数（数据源组件），并且数据源会向随机选择的 bolt 发送元组，保证每个消费者收到近似数量的元组。随机数据流组用于数学计算这样的原子操作。然而，如果操作不能被随机分配，就像第二章为单词计数的例子，你就要考虑其它分组方式了。 域数据流组 (fieldsGrouping)域数据流组允许你基于元组的一个或多个域控制如何把元组发送给 bolts。 它保证拥有相同域组合的值集发送给同一个 bolt。 回到单词计数器的例子，如果你用 word 域为数据流分组，word-normalizer bolt 将只会把相同单词的元组发送给同一个 word-counterbolt 实例。 12345678TopologyMain:builder.setBolt(&quot;word-counter&quot;, new WordCounter(),2) .fieldsGrouping(&quot;word-normalizer&quot;, new Fields(&quot;word&quot;)); WordNormalizer:// 声明输出域 outputFieldsDeclarer.declare(new Fields(&quot;word&quot;)); NOTE: 在域数据流组中的所有域集合必须存在于数据源的域声明中。 全部数据流组 (allGrouping)全部数据流组，为每个接收数据的实例复制一份元组副本。这种分组方式用于向 bolts 发送信号。比如，你要刷新缓存，你可以向所有的 bolts 发送一个刷新缓存信号。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364SignalsSpout implements IRichSpout...@Overridepublic void nextTuple() &#123; collector.emit(&quot;signals&quot;,new Values(&quot;refreshCache&quot;)); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123;&#125;&#125;@Overridepublic void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) &#123; outputFieldsDeclarer.declareStream(&quot;signals&quot;,new Fields(&quot;action&quot;));&#125;...WordCounter@Overridepublic void execute(Tuple tuple) &#123; String str = null; try&#123; str = tuple.getStringByField(&quot;word&quot;); &#125;catch (IllegalArgumentException e) &#123; //Do nothing &#125; if(str != null)&#123; if(!this.counters.containsKey(str))&#123; counters.put(str,1); &#125;else&#123; Integer c = counters.get(str); counters.put(str,c + 1); &#125; &#125; // 全部数据流组 清理计算器操作 else &#123; if((SIGNALS).equals(tuple.getSourceGlobalStreamid().get_streamId()))&#123; str = tuple.getStringByField(&quot;action&quot;); if(ACTION.equals(str))&#123; counters.clear(); &#125; &#125; &#125; //对元组作为应答 collector.ack(tuple);&#125;TopologyMainbuilder.setBolt(&quot;word-counter&quot;, new WordCounter(),2) .fieldsGroupint(&quot;word-normalizer&quot;,new Fields(&quot;word&quot;)) .allGrouping(&quot;signals-spout&quot;,&quot;signals&quot;); 自定义数据流组你可以通过实现 backtype.storm.grouping.CustormStreamGrouping 接口创建自定义数据流组，让你自己决定哪些 bolt 接收哪些元组。 修改单词计数器示例，使首字母相同的单词由同一个 bolt 接收。 123456789101112131415161718192021222324252627public class ModuleGrouping implements CustomStreamGrouping, Serializable &#123; int numTasks = 0; @Override public void prepare(int i) &#123; this.numTasks = i; &#125; @Override public List&lt;Integer&gt; taskIndices(Tuple tuple) &#123; List&lt;Integer&gt; boltIds = new ArrayList&lt;Integer&gt;(); List&lt;Object&gt; values = tuple.getValues(); if(values.size()&gt;0)&#123; String str = values.get(0).toString(); if(str.isEmpty())&#123; boltIds.add(0); &#125;else&#123; boltIds.add(str.charAt(0) % numTasks); &#125; &#125; return boltIds; &#125;&#125; 这是一个 CustomStreamGrouping 的简单实现，在这里我们采用单词首字母字符的整数值与任务数的余数，决定接收元组的 bolt。按下述方式 word-normalizer 修改即可使用这个自定义数据流组。 12builder.setBolt(&quot;word-normalizer&quot;, new WordNormalizer()) .customGrouping(&quot;word-reader&quot;, new ModuleGrouping()); 直接数据流组这是一个特殊的数据流组，数据源可以用它决定哪个组件接收元组。与前面的例子类似，数据源将根据单词首字母决定由哪个 bolt 接收元组。要使用直接数据流组，在 WordNormalizer bolt 中，使用 emitDirect 方法代替 emit。 全局数据流组全局数据流组把所有数据源创建的元组发送给单一目标实例（即拥有最低 ID 的任务）。 Storm Spouts可靠的消息 VS 不可靠的消息 在设计拓扑结构时，始终在头脑中记着的一件重要事情就是消息的可靠性。当有无法处理的消息时，你就要决定该怎么办，以及作为一个整体的拓扑结构该做些什么。举个例子，在处理银行存款时，不要丢失任何事务报文就是很重要的事情。但是如果你要统计分析数以百万的 tweeter 消息，即使有一条丢失了，仍然可以认为你的结果是准确的。 对于 Storm 来说，根据每个拓扑的需要担保消息的可靠性是开发者的责任。这就涉及到消息可靠性和资源消耗之间的权衡。高可靠性的拓扑必须管理丢失的消息，必然消耗更多资源；可靠性较低的拓扑可能会丢失一些消息，占用的资源也相应更少。不论选择什么样的可靠性策略，Storm 都提供了不同的工具来实现它。 要在 spout 中管理可靠性，你可以在分发时包含一个元组的消息 ID（collector.emit(new Values(…),tupleId)）。在一个元组被正确的处理时调用 ack 方法，而在失败时调用 fail 方法。当一个元组被所有的靶 bolt 和锚 bolt 处理过，即可判定元组处理成功（你将在第5章学到更多锚 bolt 知识）。 发生下列情况之一时为元组处理失败： 提供数据的 spout 调用 collector.fail(tuple) 处理时间超过配置的超时时间 让我们来看一个例子。想象你正在处理银行事务，需求如下： 如果事务失败了，重新发送消息 如果失败了太多次，终结拓扑运行 pom.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.hdh&lt;/groupId&gt; &lt;artifactId&gt;storm1&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;storm1 Maven Webapp&lt;/name&gt; &lt;!-- FIXME change it to the project&apos;s website --&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- Storm Dependency --&gt; &lt;dependency&gt; &lt;groupId&gt;storm&lt;/groupId&gt; &lt;artifactId&gt;storm&lt;/artifactId&gt; &lt;version&gt;0.7.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-http&lt;/groupId&gt; &lt;artifactId&gt;commons-http&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;storm1&lt;/finalName&gt; &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.6&lt;/source&gt; &lt;target&gt;1.6&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt; TransactionsSpouts.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public class TransactionsSpouts extends BaseRichSpout &#123; static Logger LOG = Logger.getLogger(TransactionsSpouts.class); // 同个元组最大错误次数 private static final Integer MAX_FAILS = 2; // 存放所有消息元组 Map&lt;Integer,String&gt; messages; // 存放每个元组消息发送错误的次数 Map&lt;Integer,Integer&gt; transactionFailureCount; // 待发送消息的元组 Map&lt;Integer,String&gt; toSend; private SpoutOutputCollector collector; @Override public void open(Map map, TopologyContext topologyContext, SpoutOutputCollector spoutOutputCollector) &#123; Random random = new Random(); this.messages = new HashMap&lt;Integer, String&gt;(); this.transactionFailureCount = new HashMap&lt;Integer, Integer&gt;(); this.toSend = new HashMap&lt;Integer, String&gt;(); for(int i = 0; i&lt; 100; i++)&#123; messages.put(i, &quot;transaction_&quot;+random.nextInt()); transactionFailureCount.put(i, 0); &#125; toSend.putAll(messages); this.collector = spoutOutputCollector; &#125; @Override public void close() &#123; &#125; @Override public void nextTuple() &#123; if(!toSend.isEmpty())&#123; for (Map.Entry&lt;Integer,String&gt; transactionEntry : toSend.entrySet())&#123; Integer transactionId = transactionEntry.getKey(); String transactionMessage = transactionEntry.getValue(); collector.emit(new Values(transactionMessage),transactionId); &#125; toSend.clear(); &#125; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; /** * spout发送消息 得到应答 * 在存放消息元组中 删除对应应答的消息msgId */ @Override public void ack(Object msgId) &#123; messages.remove(msgId); LOG.info(&quot;Message fully processed [&quot;+msgId+&quot;]&quot;); &#125; /** * spout发送消息 得到失败 * 如果同一个消息元组发送失败次数2次 即停止storm * 将发送失败的消息元组重新发送，从message中获取对应数据 存放于toSend中，等待重新发送 */ @Override public void fail(Object msgId) &#123; if(!transactionFailureCount.containsKey(msgId))&#123; throw new RuntimeException(&quot;Error, transaction id not found [&quot;+msgId+&quot;]&quot;); &#125; Integer transactionId = (Integer) msgId; //Get the transactions fail Integer failures = transactionFailureCount.get(transactionId) + 1; if(failures &gt;= MAX_FAILS)&#123; throw new RuntimeException(&quot;Error, transaction id [&quot;+transactionId+&quot;] has had many errors [&quot;+failures+&quot;]&quot;); &#125; transactionFailureCount.put(transactionId, failures); toSend.put(transactionId,messages.get(transactionId)); LOG.info(&quot;Re-sending message [&quot;+msgId+&quot;]&quot;); &#125; @Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) &#123; outputFieldsDeclarer.declare(new Fields(&quot;transactionMessage&quot;)); &#125;&#125; RandomFailureBolt.java123456789101112131415161718192021222324252627282930public class RandomFailureBolt extends BaseRichBolt &#123; private static final Integer MAX_PERCENT_FAIL = 80; Random random = new Random (); private OutputCollector collector; @Override public void prepare(Map map, TopologyContext topologyContext, OutputCollector outputCollector) &#123; this.collector = outputCollector; &#125; @Override public void execute(Tuple input) &#123; // 模拟 百分之80的 消息发送元组发送失败 // 百分之20的消息元组发送成功 Integer r = random.nextInt(100); if(r &gt; MAX_PERCENT_FAIL)&#123; collector.ack(input); &#125;else&#123; collector.fail(input); &#125; &#125; @Override public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) &#123; &#125;&#125; TopologyMain.java123456789101112131415161718192021public class TopologyMain &#123; public static void main(String[] args) throws InterruptedException &#123; TopologyBuilder topologyBuilder = new TopologyBuilder(); topologyBuilder.setSpout(&quot;transactions-spout&quot;,new TransactionsSpouts()); topologyBuilder.setBolt(&quot;random-failure-bolt&quot;,new RandomFailureBolt()) .shuffleGrouping(&quot;transactions-spout&quot;); LocalCluster cluster = new LocalCluster(); Config config = new Config(); config.setDebug(true); cluster.submitTopology(&quot;transactions-test&quot;,config,topologyBuilder.createTopology()); while (true)&#123; //Will wait for a fail Thread.sleep(1000); &#125; &#125; &#125; Storm Bolts Bolt 生命周期Bolt 是这样一种组件，它把元组作为输入，然后产生新的元组作为输出。实现一个 bolt 时，通常需要实现 IRichBolt 接口。Bolts 对象由客户端机器创建，序列化为拓扑，并提交给集群中的主机。然后集群启动工人进程反序列化 bolt，调用 prepare**，最后开始处理元组。 NOTE:要创建一个 bolt 对象，它通过构造器参数初始化成员属性，bolt 被提交到集群时，这些属性值会随着一起序列化。 Bolt 结构 declareOutputFields(OutputFieldsDeclarer declarer) 为bolt声明输出模式 prepare(java.util.Map stormConf, TopologyContext context, OutputCollector collector) 仅在bolt开始处理元组之前调用 execute(Tuple input) 处理输入的单个元组 cleanup() 在bolt即将关闭时调用 多数据流一个 bolt 可以使用 emit(streamId, tuple) 把元组分发到多个流，其中参数 streamId 是一个用来标识流的字符串。然后，你可以在 TopologyBuilder 决定由哪个流订阅它。 多锚定为了用 bolt 连接或聚合数据流，你需要借助内存缓冲元组。为了在这一场景下确保消息完成，你不得不把流锚定到多个元组上。可以向 emit 方法传入一个元组列表来达成目的。 使用 IBasicBolt 自动确认你可能已经注意到了，在许多情况下都需要消息确认。简单起见，Storm 提供了另一个用来实现bolt 的接口，IBasicBolt。对于该接口的实现类的对象，会在执行 execute 方法之后自动调用 ack 方法。 Storm学习入门到此为止，本次学习引用了w3cschool-Storm 入门教程]]></content>
      <categories>
        <category>消息中间件</category>
      </categories>
      <tags>
        <tag>storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka安装及使用]]></title>
    <url>%2F2018%2F08%2F08%2Fkafka%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[摘要: kafka安装及使用 kafka介绍 关键功能 发布和订阅消息（流），在这方面，它类似于一个消息队列或企业消息系统。 以容错的方式记录消息流，kafka以文件的方式来存储消息流。 在消息流发生时处理它们。 什么是kafka的优势？ 构建实时的流数据管道，可靠地获取系统和应用程序之间的数据。 构建实时流的应用程序，对数据流进行转换或反应。 首先几个重要的概念 kafka作为一个集群运行在一个或多个服务器上。 kafka集群存储的消息是以topic为类别记录的。 每个消息（也叫记录record，我习惯叫消息）是由一个key，一个value和时间戳构成。 kafka有四个核心API 应用程序使用 Producer API 发布消息到1个或多个topic（主题）。 应用程序使用 **Consumer API 来订阅一个或多个topic，并处理产生的消息。 应用程序使用 Streams API 充当一个流处理器，从1个或多个topic消费输入流，并生产一个输出流到1个或多个输出topic，有效地将输入流转换到输出流。 Connector API允许构建或运行可重复使用的生产者或消费者，将topic连接到现有的应用程序或数据系统。例如，一个关系数据库的连接器可捕获每一个变化。 Client和Server之间的通讯，是通过一条简单、高性能并且和开发语言无关的TCP协议。并且该协议保持与老版本的兼容。Kafka提供了Java Client（客户端）。除了Java Client外，还有非常多的其它编程语言的Client。 note：需要学习查看更多kafka相关概念介绍，跳转官网。 或者 [OrcHome，作者：半兽人][http://orchome.com/5] kafka安装 这次学习kafka的地方在公司，因此本次安装的系统是windows。 下载kafka官网 http://kafka.apache.org/downloads 下载对应的版本，我这次学习使用的是1.0.0的版本。 安装kafka启动需要先启动zookeeper，新版的kafka已经内置了一个zookeeper环境，由于本地已经配置zookeeper-3.4.10，因此这次就使用本地的zookeeper。zookeeper的配置就不多说了。 配置在kafka解压目录下下有一个config的文件夹，里面放置的是我们的配置文件 consumer.properites 消费者配置，没有特殊需求无须修改。 producer.properties 生产者配置，没有特殊需求无须修改。 server.properties kafka服务器的配置，此配置文件用来配置kafka服务器，目前仅介绍几个最基础的配置 * broker.id 申明当前kafka服务器在集群中的唯一ID，需配置为integer,并且集群中的每一个kafka服务器的id都应是唯一的，我们这里采用默认配置即可 * listeners 申明此kafka服务器需要监听的端口号，如果是在本机上跑虚拟机运行可以不用配置本项，默认会使用localhost的地址，如果是在远程服务器上运行则必须配置，例如： listeners=PLAINTEXT:// 192.168.180.128:9092。并确保服务器的9092端口能够访问 * zookeeper.connect 申明kafka所连接的zookeeper的地址 ，需配置为zookeeper的地址，由于本次使用的是kafka高版本中自带zookeeper，使用默认配置即可 zookeeper.connect=localhost:2181 在kafka_2.12-1.0.0文件夹下，创建logs文件夹。 再在server.properties中配置 log.dirs=E:\\kafka\\kafka_2.12-1.0.0\\logs 启动 123456先启动本地zookeeper服务，再启动kafka服务，对应的命令cd 到kafka解压的目录下 // windows .\bin\windows\kafka-server-start.bat .\config\server.properties // mac || linxu bin/zookeeper-server-start.sh config/zookeeper.properties 简单的使用 创建一个topic，只有一个分区和一个备份 bin/windows/kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test 查看已创建的topic信息 bin/windows/kafka-topics.bat --list --zookeeper localhost:2181 对topic为test发送消息 123bin/windows/kafka-console-producer.bat --broker-list localhost:9092 --topic test&gt; This is a message&gt; This is another message 消费topic为test消息 123bin/windows/kafka-console-consumer.bat --zookeeper localhost:2181 --topic test --from-beginningThis is a messageThis is another message 实战demodemo场景是： 本地服务启动三个不同的broker集群。同样是需要提前启动好zookeeper即可。 config/server.properties: broker.id=0 listeners=PLAINTEXT://:9092 log.dir=E:/kafka/kafka_2.12-1.0.0/logs config/server-1.properties: broker.id=1 listeners=PLAINTEXT://:9093 log.dirE:/kafka/kafka_2.12-1.0.0/logs-1 config/server-2.properties: broker.id=2 listeners=PLAINTEXT://:9094 log.dir=E:/kafka/kafka_2.12-1.0.0/logs-2 分别启动这三台kafka服务器即可，上面已经提到命令这就不写了。 创建一个topic，有二个分区和三个备份(三个备份，就需要三台不同broker的集群kafka服务)。2个生产者，2个消费者note：同组消费者的数量不可高于 topic分区数(partitionCount)，会导致同组中多余出来的消费者，会一直接收不到消息。默认消费策略是同组消费者平均消费同一个topic。 pom.xml123456789101112131415161718192021222324252627&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka_2.12&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.4&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; AdminClient 在代码中实现，创建一个topic，有二个分区和三个备份。 123456789101112131415Properties props = new Properties();props.put(&quot;bootstrap.servers&quot;, &quot;192.168.180.128:9092&quot;);AdminClient adminClient = AdminClient.create(props);ArrayList&lt;NewTopic&gt; topics = new ArrayList&lt;NewTopic&gt;();NewTopic newTopic = new NewTopic(&quot;topic-test&quot;, 2, (short) 3);topics.add(newTopic);CreateTopicsResult result = adminClient.createTopics(topics);try &#123; result.all().get();&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; catch (ExecutionException e) &#123; e.printStackTrace();&#125; MyKafkaConsumer1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class MyKafkaConsumer &#123; private final KafkaConsumer&lt;String, String&gt; consumer; private MyKafkaConsumer() &#123; Properties props = new Properties(); // zookeeper 配置 props.put(&quot;bootstrap.servers&quot;, &quot;127.0.0.1:9092&quot;); /** group 代表一个消费组 * 一个发布在Topic上消息被分发给此 消费者组 中的一个消费者。 * 假如所有的消费者都在一个组中，那么这就变成了queue模型。 * 假如所有的消费者都在不同的组中，那么就完全变成了发布-订阅模型。 * * Topic分区中消息只能由消费者组中的唯一一个消费者处理，所以消息肯定是按照先后顺序进行处理的。 * 但是它也仅仅是保证Topic的一个分区顺序处理，不能保证跨分区的消息先后处理顺序。 所以，如果你想要顺序的处理Topic的所有消息，那就只提供一个分区。 */ props.put(&quot;group.id&quot;, &quot;test-group-1&quot;); // 自动提交 props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;); props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); // latest, earliest, none// props.put(&quot;auto.offset.reset&quot;, &quot;none&quot;); // zk props.put(&quot;zookeeper.connect&quot;, &quot;127.0.0.1:2181&quot;); // zk连接超时 props.put(&quot;zookeeper.session.timeout.ms&quot;, &quot;4000&quot;); props.put(&quot;zookeeper.sync.time.ms&quot;, &quot;200&quot;); props.put(&quot;rebalance.max.retries&quot;, &quot;5&quot;); props.put(&quot;rebalance.backoff.ms&quot;, &quot;1200&quot;); // 序列化类 props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); consumer = new KafkaConsumer&lt;String,String&gt;(props); &#125; void consume() &#123; consumer.subscribe(Arrays.asList(MyKafkaProducer.TOPIC),new ConsumerRebalanceListener() &#123; @Override public void onPartitionsRevoked(Collection&lt;TopicPartition&gt; collection) &#123; &#125; @Override public void onPartitionsAssigned(Collection&lt;TopicPartition&gt; collection) &#123; // 将偏移设置到最开始 消息获取 从开始读取消息 consumer.seekToBeginning(collection); // 将偏移设置到最后 消息获取 从上次消息的最末尾开始读取// consumer.seekToEnd(collection); &#125; &#125;); while (true) &#123; /** 消息模型可以分为两种，队列和发布-订阅式。 * 队列的处理方式是 一组消费者从服务器读取消息，一条消息只有其中的一个消费者来处理。 * 发布-订阅模型的方式是 消息被广播给所有的消费者，接收到消息的消费者都可以处理此消息。 */ ConsumerRecords&lt;String, String&gt; records = consumer.poll(100); for (ConsumerRecord&lt;String, String&gt; record : records) &#123; System.out.printf(&quot;partition = %d offset = %d, key = %s, value = %s%n&quot;, record.partition(), record.offset(), record.key(), record.value()); &#125; &#125; &#125; public static void main(String[] args) &#123; new MyKafkaConsumer().consume(); &#125;&#125; MyKafkaProducer1234567891011121314151617181920212223242526272829303132333435363738394041424344public class MyKafkaProducer &#123; /** * 写入到kafka的数据将写到磁盘并复制到集群中保证容错性。并允许生产者等待消息应答，直到消息完全写入。 */ private final Producer&lt;String, String&gt; producer; public final static String TOPIC = &quot;my-replicated-topic&quot;; private MyKafkaProducer() &#123; Properties props = new Properties(); // 此处配置的是kafka的端口 props.put(&quot;bootstrap.servers&quot;, &quot;127.0.0.1:9092&quot;); props.put(&quot;zk.connect&quot;, &quot;127.0.0.1:2181&quot;); // 配置value的序列化类 props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); // 配置key的序列化类 props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(&quot;acks&quot;, &quot;all&quot;); producer = new KafkaProducer&lt;String, String&gt;(props); &#125; void produce() &#123; int messageNo = 100; final int COUNT = 200; while (messageNo &lt; COUNT) &#123; String key = String.valueOf(messageNo); String data = &quot;hello kafka message &quot; + key; // 生产者 发送topic 可以配置 topic主题、partition分区、key键、data值 、 timestamp 时间、 headers 头部 producer.send(new ProducerRecord&lt;String, String&gt;(TOPIC, key, data)); System.out.println(data); messageNo++; &#125; producer.close(); &#125; public static void main(String[] args) &#123; new MyKafkaProducer().produce(); &#125;&#125; 简单入门到此为止。接下来学习storm，再将kafka结合storm的demo。]]></content>
      <categories>
        <category>消息中间件</category>
      </categories>
      <tags>
        <tag>kafka安装及使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[粗略模范hibernate功能]]></title>
    <url>%2F2018%2F08%2F07%2F%E7%B2%97%E7%95%A5%E6%A8%A1%E8%8C%83hibernate%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[摘要: 使用反射机制 粗略模范hibernate功能 粗略模范hibernate功能 自定义2个注解：Table value 类上的表名注解Column value 类中的属性 对应 数据库的字段名 思路： 执行增删改查方法，参入类的实例，通过反射机制自动形成对应的sql语句。 note： 类的属性不为空，且未配置 @Column注解 默认使用属性名为 数据库字段名。 Column自定义注解12345678910/** * 数据库表中 字段 的注解映射 */@Target(&#123;ElementType.FIELD&#125;)//作用域是类或者接口@Retention(RetentionPolicy.RUNTIME)//注解类型：运行时注解public @interface Column &#123; String value();//注解只有一个变量时 变量名必须为value&#125; Table自定义注解12345678910/** * 数据库名 @Table 映射注解 */@Target(&#123;ElementType.TYPE&#125;)//作用域是类或者接口@Retention(RetentionPolicy.RUNTIME)//注解类型：运行时注解public @interface Table &#123; String value();//注解只有一个变量时 变量名必须为value&#125; User类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687@Table(value = &quot;t_my_user&quot;)public class User &#123; @Column(&quot;id&quot;) private Integer id; @Column(&quot;user_name&quot;) private String userName; @Column(&quot;nick_name&quot;) private String nickName; @Column(&quot;age&quot;) private Integer age; @Column(&quot;city&quot;) private String city; @Column(&quot;email&quot;) private String email; @Column(&quot;mobile&quot;) private String mobile; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public String getNickName() &#123; return nickName; &#125; public void setNickName(String nickName) &#123; this.nickName = nickName; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getCity() &#123; return city; &#125; public void setCity(String city) &#123; this.city = city; &#125; public String getEmail() &#123; return email; &#125; public void setEmail(String email) &#123; this.email = email; &#125; public String getMobile() &#123; return mobile; &#125; public void setMobile(String mobile) &#123; this.mobile = mobile; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;id=&quot; + id + &quot;, userName=&apos;&quot; + userName + &apos;\&apos;&apos; + &quot;, nickName=&apos;&quot; + nickName + &apos;\&apos;&apos; + &quot;, age=&quot; + age + &quot;, city=&apos;&quot; + city + &apos;\&apos;&apos; + &quot;, email=&apos;&quot; + email + &apos;\&apos;&apos; + &quot;, mobile=&apos;&quot; + mobile + &apos;\&apos;&apos; + &apos;&#125;&apos;; &#125;&#125; MyDemo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260public class MyDemo &#123; public static void main(String[] args) throws SQLException &#123; User u = new User(); u.setId(2); u.setNickName(&quot;nickName&quot;); u.setUserName(&quot;userNmae&quot;); u.setAge(20); u.setEmail(&quot;5asda@qq.com&quot;); u.setCity(&quot;厦门&quot;); u.setMobile(&quot;01234567890&quot;); new MyDemo().excuteSQL(&quot;insert&quot;,u);// new MyDemo().excuteSQL(&quot;select&quot;,u); &#125; public void excuteSQL(String sqlType,User u) throws SQLException &#123; //声明Connection对象 Connection coon = null; //驱动程序名 String driver = &quot;com.mysql.jdbc.Driver&quot;; //URL指向要访问的数据库名mydata String url = &quot;jdbc:mysql://10.104.50.25:3306/test?useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;zeroDateTimeBehavior=convertToNull&quot;; //MySQL配置时的用户名 String user = &quot;uc_db&quot;; //MySQL配置时的密码 String password = &quot;uc_dbtest&quot;; try &#123; //加载驱动程序 Class.forName(driver); //1.getConnection()方法，连接MySQL数据库！！ coon = DriverManager.getConnection(url,user,password); if(!coon.isClosed()) System.out.println(&quot;Succeeded connecting to the Database!&quot;); //2.创建statement类对象，用来执行SQL语句！！ Statement statement = coon.createStatement(); //要执行的SQL语句和总数 String sql = null; if(sqlType.equals(&quot;insert&quot;))&#123; sql = insertSQL(u); System.out.println(sql); PreparedStatement p = null; p = coon.prepareStatement(sql); //表示执行PreparedStatement 中封装的sql语句 int result = p.executeUpdate(); if(result != 0)&#123; System.out.println(result + &quot;条插入 sql 执行成功!&quot;); &#125; &#125;else if(sqlType.equals(&quot;select&quot;))&#123; sql = querySQL(u); System.out.println(sql); ResultSet rs = statement.executeQuery(sql); List&lt;User&gt; list = Lists.newArrayList(); while(rs.next())&#123; User serviceTestModel = new User(); serviceTestModel.setId(Integer.valueOf(rs.getString(&quot;id&quot;))); serviceTestModel.setNickName(rs.getString(&quot;nick_name&quot;)); serviceTestModel.setUserName(rs.getString(&quot;user_name&quot;)); serviceTestModel.setAge(Integer.valueOf(rs.getString(&quot;age&quot;))); serviceTestModel.setCity(rs.getString(&quot;city&quot;)); serviceTestModel.setEmail(rs.getString(&quot;email&quot;)); serviceTestModel.setMobile(rs.getString(&quot;mobile&quot;)); list.add(serviceTestModel); &#125; System.out.println(&quot;输出查询结果：\r\n&quot;); for (User item: list) &#123; System.out.println(item); &#125; &#125; &#125; catch(ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch(SQLException e) &#123; //数据库连接失败异常处理 e.printStackTrace(); &#125;catch (Exception e) &#123; e.printStackTrace(); &#125;finally&#123; coon.close(); &#125; &#125; private static String querySQL(User user) throws Exception &#123; Class&lt;?&gt; entity = user.getClass(); // 获取该的 table注解值 Table filed = entity.getAnnotation(Table.class); String tableName = filed.value(); StringBuilder stringBuilder = new StringBuilder(&quot;select * from &quot;); stringBuilder.append(tableName + &quot; where 1 = 1 &quot;); if(entity!=null)&#123; Field[] fields = entity.getDeclaredFields(); Method [] methods = entity.getDeclaredMethods(); for(Field f : fields)&#123; String fieldName = f.getName(); Class&lt;?&gt; fieldType = f.getType(); Column column = f.getAnnotation(Column.class); String columnSQL = column.value(); // 如果类型是String if (f.getGenericType().toString().equals( &quot;class java.lang.String&quot;)) &#123; // 如果type是类类型，则前面包含&quot;class &quot;，后面跟类名 // 拿到该属性的gettet方法 Method m = (Method) entity.getMethod( &quot;get&quot; + getMethodName(fieldName)); String strValue = (String) m.invoke(user);// 调用getter方法获取属性值 if(strValue != null &amp;&amp; !strValue.equals(&quot;&quot;))&#123; if(columnSQL == null || columnSQL.equals(&quot;&quot;))&#123; stringBuilder.append(&quot; and &quot;+fieldName + &quot; = &quot; + &quot; \&apos;&quot; + strValue + &quot;\&apos; &quot;); &#125;else&#123; stringBuilder.append(&quot; and &quot;+columnSQL + &quot; = &quot; + &quot; \&apos;&quot; + strValue + &quot;\&apos; &quot;); &#125; &#125; &#125; // 如果类型是Integer if (f.getGenericType().toString().equals( &quot;class java.lang.Integer&quot;)) &#123; Method m = (Method) entity.getMethod( &quot;get&quot; + getMethodName(f.getName())); Integer intValue = (Integer) m.invoke(user); if(intValue != null)&#123; if(columnSQL == null || columnSQL.equals(&quot;&quot;))&#123; stringBuilder.append(&quot; and &quot;+fieldName + &quot; = &quot; + intValue + &quot; &quot;); &#125;else&#123; stringBuilder.append(&quot; and &quot;+columnSQL + &quot; = &quot; + intValue + &quot; &quot;); &#125; &#125; &#125; &#125; &#125; return stringBuilder.toString(); &#125; public static String insertSQL(User user) throws Exception &#123; Class&lt;?&gt; entity = user.getClass(); Table filed = entity.getAnnotation(Table.class); String tableName = filed.value(); StringBuilder stringBuilder = new StringBuilder(&quot;insert &quot;); StringBuilder stringBuilderValue = new StringBuilder(&quot;value (&quot;); stringBuilder.append(tableName + &quot; (&quot;); if(entity!=null)&#123; /**返回类中所有字段，包括公共、保护、默认（包）访问和私有字段，但不包括继承的字段 * entity.getFields();只返回对象所表示的类或接口的所有可访问公共字段 * 在class中getDeclared**()方法返回的都是所有访问权限的字段、方法等； * 可看API * */ Field[] fields = entity.getDeclaredFields(); for(Field f : fields)&#123; String fieldName = f.getName(); Class&lt;?&gt; fieldType = f.getType(); // 由于private变量，所以需要调用// f.setAccessible(true); // 如果类型是String if (f.getGenericType().toString().equals( &quot;class java.lang.String&quot;)) &#123; // 如果type是类类型，则前面包含&quot;class &quot;，后面跟类名 // 拿到该属性的gettet方法 Method m = (Method) entity.getMethod( &quot;get&quot; + getMethodName(fieldName)); String strValue = (String) m.invoke(user);// 调用getter方法获取属性值 stringBuilderValue.append(&quot;\&apos;&quot;+strValue+&quot;\&apos;&quot; + &quot;,&quot;); &#125; // 如果类型是Integer if (f.getGenericType().toString().equals( &quot;class java.lang.Integer&quot;)) &#123; Method m = (Method) entity.getMethod( &quot;get&quot; + getMethodName(f.getName())); Integer intValue = (Integer) m.invoke(user); stringBuilderValue.append(intValue + &quot;,&quot;); &#125; Column column = f.getAnnotation(Column.class); String columnSQL = column.value(); stringBuilder.append(columnSQL + &quot;,&quot;); &#125; //返回对象所表示的类或接口的所有可访问公共方法// Method[] methods = entity.getMethods();//// for(Method m:methods)&#123;// FieldMeta meta = m.getAnnotation(FieldMeta.class);// if(meta!=null)&#123;// SortableField sf = new SortableField(meta,m.getName(),m.getReturnType());// list.add(sf);// &#125;// &#125;// //这种方法是新建FieldSortCom类实现Comparator接口，来重写compare方法实现排序//// Collections.sort(list, new FieldSortCom());// Collections.sort(list, new Comparator&lt;SortableField&gt;() &#123;// @Override// public int compare(SortableField s1,SortableField s2) &#123;// return s1.getMeta().order()-s2.getMeta().order();//// return s1.getName().compareTo(s2.getName());//也可以用compare来比较// &#125;//// &#125;); &#125; String sql1 = stringBuilder.toString().substring(0,stringBuilder.toString().length()-1); String sql2 = stringBuilderValue.toString().substring(0,stringBuilderValue.toString().length()-1); return sql1 + &quot;) &quot; + sql2 + &quot;);&quot;; &#125; private static String getMethodName(String fildeName) throws Exception&#123; byte[] items = fildeName.getBytes(); items[0] = (byte) ((char) items[0] - &apos;a&apos; + &apos;A&apos;); return new String(items); &#125;&#125;]]></content>
      <categories>
        <category>hibernate</category>
      </categories>
      <tags>
        <tag>反射机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程应用_消费者与生产者]]></title>
    <url>%2F2018%2F08%2F06%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%BA%94%E7%94%A8_%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%8E%E7%94%9F%E4%BA%A7%E8%80%85%2F</url>
    <content type="text"><![CDATA[摘要: 多线程应用_消费者与生产者 多消费者与多生产者 简单的例子就不多些，多消费与多生产者，一个篮子之前也写过不少，但是参考偏多，此次纯手撸的代码。 最开始的思路： 很简单的做法，只有一个篮子，而且篮子只有存放一个物品，并且同时只能一个人操作。 依据这个思路，写出来的代码就是不管生产者、还是消费者在操作前都需要获取锁的操作。 思路一Consumer12345678910111213141516171819202122232425262728293031323334public class Consumer extends Thread &#123; private Queue&lt;String&gt; goods = null; private int count = 50; public Consumer(Queue&lt;String&gt; goods) &#123; this.goods = goods; &#125; @Override public void run() &#123; while (true) &#123; synchronized (goods)&#123; String good = null; if (count == 0) &#123; break; &#125; if (goods.size() != 0) &#123; good = this.goods.poll(); count--; System.out.println(this.currentThread().getName() + &quot; 消费了 &quot; + good + &quot;...&quot;); &#125; &#125; &#125; &#125;&#125; Producer123456789101112131415161718192021222324252627282930313233343536public class Producer extends Thread &#123; private Queue&lt;String&gt; goods = null; private Integer count = 1; public Producer(Queue&lt;String&gt; queue) &#123; this.goods = queue; &#125; @Override public void run() &#123; while (count &lt; 51) &#123; synchronized (goods) &#123; if (goods.size() &lt; 1) &#123; goods.offer(&quot;第&quot; + count + &quot;个 &quot; +this.currentThread().getName() + &quot;商品&quot;); try &#123; this.currentThread().sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;生产者 生产了第&quot; + count++ + &quot;个 &quot; +this.currentThread().getName() + &quot;商品...&quot;); &#125; &#125; &#125; &#125;&#125; ThreadTest12345678910111213141516public class ThreadTest &#123; public static void main(String[] args) &#123; Queue&lt;String&gt; queue = new LinkedList&lt;String&gt;(); new Thread(new Producer(queue), &quot;A类型&quot;).start(); new Thread(new Producer(queue), &quot;B类型&quot;).start(); new Thread(new Consumer(queue), &quot;消费者a&quot;).start(); new Thread(new Consumer(queue), &quot;消费者b&quot;).start(); &#125;&#125; 优化思路(运用安全集合)优化思路： 场景还是多个生产者，多个消费者，一个产品传递管道。 只要保证产品传递管道线程安全，消费者和生产者都只负责做自己的事情即可。 Consumer1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.daily_learning.demo;import java.util.concurrent.LinkedBlockingQueue;/** * @Description //TODO * by 华仔 创建. **/public class Consumer extends Thread &#123; private LinkedBlockingQueue&lt;String&gt; goods = null; private int count = 50; public Consumer(LinkedBlockingQueue&lt;String&gt; goods) &#123; this.goods = goods; &#125; @Override public void run() &#123; while (true) &#123; String good = null; if (count == 0) &#123; break; &#125; if (goods.size() != 0) &#123; try &#123; good = this.goods.take(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; count--; System.out.println(this.currentThread().getName() + &quot; 消费了 &quot; + good + &quot;...&quot;); &#125; &#125; &#125;&#125; Producer123456789101112131415161718192021222324252627282930313233343536373839404142package com.daily_learning.demo;import java.util.concurrent.LinkedBlockingQueue;/** * @Description //TODO * by 华仔 创建. **/public class Producer extends Thread &#123; private LinkedBlockingQueue&lt;String&gt; goods = null; private Integer count = 1; public Producer(LinkedBlockingQueue&lt;String&gt; goods) &#123; this.goods = goods; &#125; @Override public void run() &#123; while (count &lt; 51) &#123; if (goods.size() &lt; 1) &#123; try &#123; goods.put(&quot;第&quot; + count + &quot;个 &quot; +this.currentThread().getName() + &quot;商品&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; this.currentThread().sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;生产者 生产了第&quot; + count++ + &quot;个 &quot; +this.currentThread().getName() + &quot;商品...&quot;); &#125; &#125; &#125;&#125; ThreadTestpackage com.daily_learning.demo; import java.util.concurrent.LinkedBlockingQueue; /** * @Description //TODO * by 华仔 创建. **/ public class ThreadTest { public static void main(String[] args) { LinkedBlockingQueue&lt;String&gt; goods = new LinkedBlockingQueue&lt;String&gt;(); new Thread(new Producer(goods), &quot;A类型&quot;).start(); new Thread(new Producer(goods), &quot;B类型&quot;).start(); new Thread(new Consumer(goods), &quot;消费者a&quot;).start(); new Thread(new Consumer(goods), &quot;消费者b&quot;).start(); } }]]></content>
      <categories>
        <category>JavaSE</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详细学习Log4j]]></title>
    <url>%2F2018%2F04%2F22%2FLog4J%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[摘要: 此次详细学习一次Log4j,好记性不如烂笔头。 Log4J的配置 Log4J的配置文件(Configuration File)就是用来设置记录器的级别、存放器和布局的，它可接key=value格式的设置或xml格式的设置信息。通过配置，可以创建出Log4J的运行环境。 配置文件(基本格式)123456789101112log4j.rootLogger = [level] appenderName1, appenderName2, appenderName3log4j.appenderName1 = org.apache.log4j.xxxAppender;log4j.appender.appenderName1.layout = org.apache.log4j.xxxLayout; ;...log4j.appenderName1.options = options;log4j.appenderName2 = org.apache.log4j.xxxAppender;log4j.appender.appenderName1.layout = org.apache.log4j.xxxLayout;...log4j.appenderName2.options = options; level等级划分12345FATAL 0 ERROR 3 WARN 4 INFO 6 DEBUG 7 Log4j提供appender方式Appender 为日志输出目的地，Log4j提供的==appender== 123456789org.apache.log4j.ConsoleAppender（控制台）， org.apache.log4j.FileAppender（文件）， org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）， org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件）， org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） Log4j提供的layout方式==layout==日志输出格式，Log4j提供的layout有以下几种 1234567org.apache.log4j.HTMLLayout（以HTML表格形式布局）， org.apache.log4j.PatternLayout（可以灵活地指定布局模式）， org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）， org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息） layout.ConversionPattern打印参数1234567891011121314151617**打印参数: Log4J采用类似C语言中的printf函数的打印格式格式化日志信息** %m 输出代码中指定的消息 %p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL %r 输出自应用启动到输出该log信息耗费的毫秒数 %c 输出所属的类目，通常就是所在类的全名 %t 输出产生该日志事件的线程名 %n 输出一个回车换行符，Windows平台为“/r/n”，Unix平台为“/n” %d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d&#123;yyy MMM dd HH:mm:ss , SSS&#125;，输出类似：2002年10月18日 22 ： 10 ： 28 ， 921 %l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main(TestLog4.java: 10 ) 在代码中初始化Logger12345671. 在程序中调用BasicConfigurator.configure()方法：给根记录器增加一个ConsoleAppender，输出格式通过PatternLayout设为&quot;%-4r [%t] %-5p %c %x - %m%n&quot;，还有根记录器的默认级别是Level.DEBUG. 2. 配置放在文件里，通过命令行参数传递文件名字，通过PropertyConfigurator.configure(args[x])解析并配置3. 配置放在文件里，通过环境变量传递文件名等信息，利用log4j默认的初始化过程解析并配置4. 配置放在文件里，通过应用服务器配置传递文件名等信息，利用一个特殊的servlet来完成配置 为不同的 Appender 设置日志输出级别当调试系统时，我们往往注意的只是异常级别的日志输出，但是通常所有级别的输出都是放在一个文件里的，如果日志输出的级别是BUG！？那就慢慢去找吧。这时我们也许会想要是能把异常信息单独输出到一个文件里该多好啊。当然可以，Log4j已经提供了这样的功能，我们只需要在配置中修改Appender的==Threshold== 就能实现,比如下面的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# log4j set levellog4j.rootLogger = info, Console, debugFile,infoFile,errorFile,fatalFile #Consolelog4j.appender.Console = org.apache.log4j.ConsoleAppender# PatternLayout 指定布局模式log4j.appender.Console.layout = org.apache.log4j.PatternLayoutlog4j.appender.Console.layout.ConversionPattern = %d [%t] %-5p [%c] - %m%nlog4j.logger.com.landicorp=DEBUG#debugFile# 每天产生一个日志文件log4j.appender.debugFile = org.apache.log4j.DailyRollingFileAppender# 日志指定输出目录log4j.appender.debugFile.File = ../logs/merchant/debug.log# 输出DEBUG级别以上的日志log4j.appender.debugFile.Threshold =debug# PatternLayout 指定布局模式log4j.appender.debugFile.layout = org.apache.log4j.PatternLayoutlog4j.appender.debugFile.layout.ConversionPattern = %d [%t] %-5p [%c] - %m%n#infoFile# 每天产生一个日志文件log4j.appender.infoFile = org.apache.log4j.DailyRollingFileAppender# 日志指定输出目录log4j.appender.infoFile.File = ../logs/merchant/info.log# 输出info级别以上的日志log4j.appender.infoFile.Threshold =info# PatternLayout 指定布局模式log4j.appender.infoFile.layout = org.apache.log4j.PatternLayoutlog4j.appender.infoFile.layout.ConversionPattern =%d [%t] %-5p [%c] - %m%n#errorFilelog4j.appender.errorFile = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.errorFile.File = ../logs/merchant/error.loglog4j.appender.errorFile.Threshold =errorlog4j.appender.errorFile.layout = org.apache.log4j.PatternLayoutlog4j.appender.errorFile.layout.ConversionPattern =%d [%t] %-5p [%c] - %m%n#fatalFilelog4j.appender.fatalFile = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.fatalFile.File = ../logs/merchant/fatal.loglog4j.appender.fatalFile.Threshold =fatallog4j.appender.fatalFile.layout = org.apache.log4j.PatternLayoutlog4j.appender.fatalFile.layout.ConversionPattern =%d [%t] %-5p [%c] - %m%n log4j其他额外的参数1234567891011121314151617181920212223242526272829ImmediateFlush=true;默认值是true,意谓着所有的消息都会被立即输出。Target=System.err;默认情况下是：System.out,指定输出控制台Append=false;默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。MaxFileSize=100KB;后缀可以是KB, MB 或者是 GB. 在日志文件到达该大小时，将会自动滚动，即将原来的内容移到mylog.log.1文件。MaxBackupIndex=2;指定可以产生的滚动文件的最大数。日志信息格式中几个符号所代表的含义： -X号: X信息输出时左对齐； %p: 输出日志信息优先级，即DEBUG，INFO，WARN，ERROR，FATAL, %d: 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d&#123;yyy MMM dd HH:mm:ss,SSS&#125;，输出类似：2002年10月18日 22：10：28，921 %r: 输出自应用启动到输出该log信息耗费的毫秒数 %c: 输出日志信息所属的类目，通常就是所在类的全名 %t: 输出产生该日志事件的线程名 %l: 输出日志事件的发生位置，相当于%C.%M(%F:%L)的组合,包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main (TestLog4.java:10) %x: 输出和当前线程相关联的NDC(嵌套诊断环境),尤其用到像java servlets这样的多客户多线程的应用中。 %%: 输出一个&quot;%&quot;字符 %F: 输出日志消息产生时所在的文件名称 %L: 输出代码中的行号 %m: 输出代码中指定的消息,产生的日志具体信息 %n: 输出一个回车换行符，Windows平台为&quot;/r/n&quot;，Unix平台为&quot;/n&quot;输出日志信息换行 可以在%与模式字符之间加上修饰符来控制其最小宽度、最大宽度、和文本的对齐方式。如： 1)%20c：指定输出category的名称，最小的宽度是20，如果category的名称小于20的话，默认的情况下右对齐。 2)%-20c:指定输出category的名称，最小的宽度是20，如果category的名称小于20的话，&quot;-&quot;号指定左对齐。 3)%.30c:指定输出category的名称，最大的宽度是30，如果category的名称大于30的话，就会将左边多出的字符截掉，但小于30的话也不会有空格。 4)%20.30c:如果category的名称小于20就补空格，并且右对齐，如果其名称长于30字符，就从左边较远输出的字符截掉。 参考网址配置Log4j(很详细)]]></content>
      <categories>
        <category>Log4j</category>
      </categories>
      <tags>
        <tag>Log4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下SVN的使用]]></title>
    <url>%2F2018%2F03%2F14%2FMac%E4%B8%8BSVN%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[摘要: Mac环境下SVN的配置及使用 在Windows环境中，我们一般使用TortoiseSVN来搭建svn环境。而Mac环境下，由于Mac自带了svn的服务端和客户端，所以不用借助第三方助手，可以直接使用，稍微做些简单的配置即可。 配置 在/User/apple/下 创建svn文件夹，再在svn文件下创建mycode文件夹。 打开终端输入以下语句 svnadmin /User/apple/svn/mycode 在终端输入该命令后mycode的文件夹(原本为空的)，会出现：conf、db、format、hooks、locks、README.txt svn主要配置的文件在config文件下 配置svn的用户权限 打开svnserver.conf将一下 #和空格 去掉 # anon-access = read # auth-access = write # password-db = passwd # authz-db = authz anon-access = read代表匿名访问的时候是只读的，若改为anon-access = none代表禁止匿名访问，需要帐号密码才能访问 既然开启了用户权限，就要添加账号和密码 打开passwd，在 [user] 下面添加账号和密码，比如： [user] root=root 账号为root 密码为root 配置用户或者组权限 打开authz，配置用户或者组的权限 我们可以将passwd里添加的用户添加角色，或者将这些用户加入到某个组(group)，再对这个组进行授权，这样依附于这些组的用户都有了这些权限，修改如下： [groups] togroup=root,admin //root、admin都是账号 [/] //[/]svn服务器中的所有资源 @togroup=rw //给togroup该组 添加读写的权限 //当然也可以直接给用户添加权限 [/] root=rw //不需要添加@ 启动关闭svn 终端方式输入，输入后没有任何提示就说明启动成功了 svnserve -d -r /Users/apple/svn 或者 svnserve -d -r /Users/apple/svn/mycode 关闭svn 打开实用工具里面的“活动监视器”，搜索svn，然后选择关闭进程即可。 使用svn 本地导入代码到服务器(第一次初始化) 在终端输入 svn import /Users/apple/Documents/eclipse_workspace/project svn://localhost/mycode/project –username=root –password=root -m “初始化导入” 将 /Users/apple/Documents/eclipse_workspace/project的项目导入 svn://localhost/mycode/project服务器mycode仓库的project目录下，简要的信息”初始化导入” 从服务器端下载代码到客户端本地 在终端输入 在终端中输入svn checkout svn://localhost/mycode –username=root –password=root /Users/apple/Documents/code 提交更改过的代码到服务器 在终端输入 打开终端，先定位到/Users/apple/Documents/code目录，输入：cd/Users/apple/Documents/code 输入提交指令：svn commit -m “修改了main.m文件” 这个指令会将/Users/apple/Documents/code下的所有修改都同步到服务器端，假如这次我只修改了main.文件 可以看到终端的打印信息： Sending code/project/main.m Transmitting file data . Committed revision 2. 更新服务器端的代码到客户端 这个应该是最简单的指令了，在终端中定位到客户端代码目录后，比如上面的/Users/apple/Documents/code目录，然后再输入指令：svn update 至于svn的其他用法，可以在终端输入：svn help 当然也有很多缩写的方式 引用]]></content>
      <categories>
        <category>svn</category>
      </categories>
      <tags>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongoDB学习记录]]></title>
    <url>%2F2018%2F03%2F13%2FmongoDB%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[摘要: mongoDB学习记录 引用：MongoDB教程 什么是NoSQL?NoSQL，指的是非关系型的数据库。NoSQL有时也称作Not Only SQL的缩写，是对不同于传统的关系型数据库的数据库管理系统的统称。 NoSQL用于超大规模数据的存储。（例如谷歌或Facebook每天为他们的用户收集万亿比特的数据）。这些类型的数据存储不需要固定的模式，无需多余操作就可以横向扩展。 为什么使用NoSQL ?今天我们可以通过第三方平台（如：Google,Facebook等）可以很容易的访问和抓取数据。用户的个人信息，社交网络，地理位置，用户生成的数据和用户操作日志已经成倍的增加。我们如果要对这些用户数据进行挖掘，那SQL数据库已经不适合这些应用了, NoSQL数据库的发展也却能很好的处理这些大的数据。 RDBMS vs NoSQLRDBMS 高度组织化结构化数据 结构化查询语言（SQL） (SQL) 数据和关系都存储在单独的表中。 数据操纵语言，数据定义语言 严格的一致性 基础事务 NoSQL 代表着不仅仅是SQL 没有声明性查询语言 没有预定义的模式 键 - 值对存储，列存储，文档存储，图形数据库 最终一致性，而非ACID属性 非结构化和不可预知的数据 CAP定理 高性能，高可用性和可伸缩性 mongoDB的基础命令 mongo (默认进入mongo) show dbs (展示所有数据列表[默认存在的数据库有3个 admin、config、local]) db.auth(username,password); mongo默认不登录连接，使用数据库时需要认证 db.system.users.find(); 查询数据库当前的用户信息 创建用户及角色 db.createUser( { user: &quot;adminUser&quot;, pwd: &quot;adminPass&quot;, roles: [ { role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; } ] }) db.createUser( { user: &quot;simpleUser&quot;, pwd: &quot;simplePass&quot;, roles: [ { role: &quot;readWrite&quot;, db: &quot;foo&quot; }, { role: &quot;read&quot;, db: &quot;bar&quot; } ] }) 作者：kimoCHG链接：https://www.jianshu.com/p/79caa1cc49a5來源：简书著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 在命令行登录的方式有2种 mongo –port 27017 use admin db.auth(“adminUser”, “adminPass”) mongo –port 27017 -u “adminUser” -p “adminPass” –authenticationDatabase “admin” use DATABASE_NAME (如果数据库不存在，则创建数据库，否则切换到指定数据库。) 获取该文档(行)创建时间可以直接使用 var newObject = ObjectId()newObject.getTimestamp()由于 ObjectId 中保存了创建的时间戳，所以你不需要为你的文档保存时间戳字段，你可以通过 getTimestamp 函数来获取文档的创建时间 mongodb://[username:password@]host1[:port1][,host2[:port2],…[,hostN[:portN]]][/[database][?options]] (mongodb连接方式) 查看更多连接参数 db.dropDatabase() (删除数据库) db.collection.drop() (删除集合) db.createCollection(name, options) （创建集合、name:创建集合的名字,options:更多可选参数） show collections (use database_name后，展示所有的集合) db.collection.insertOne() 向指定集合中插入一条文档数据 db.collection.insertMany() 向指定集合中插入多条文档数据 db.COLLECTION_NAME.insert(document) 1234567db.col.insert(&#123;title: 'MongoDB 教程', description: 'MongoDB 是一个 Nosql 数据库', by: '菜鸟教程', url: 'http://www.runoob.com', tags: ['mongodb', 'database', 'NoSQL'], likes: 100&#125;) db.collection.find() 查询该集合所有文档 更新文档操作 123456789101112131415161718192021222324252627282930db.collection.update( &lt;query&gt;, &lt;update&gt;, &#123; upsert: &lt;boolean&gt;, multi: &lt;boolean&gt;, writeConcern: &lt;document&gt; &#125;)例子：&gt; db.col.update(&#123;'title':'MongoDB 教程'&#125;,&#123;$set:&#123;'title':'MongoDB'&#125;&#125;,&#123;multi:true&#125;)&gt; db.col.update(&#123;'title':'MongoDB 教程'&#125;,&#123;$set:&#123;'title':'MongoDB'&#125;&#125;)WriteResult(&#123; "nMatched" : 1, "nUpserted" : 0, "nModified" : 1 &#125;) # 输出信息&gt; db.col.find().pretty()&#123; "_id" : ObjectId("56064f89ade2f21f36b03136"), "title" : "MongoDB", "description" : "MongoDB 是一个 Nosql 数据库", "by" : "菜鸟教程", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100&#125; 参数说明： query : update的查询条件，类似sql update查询内where后面的。 update : update的对象和一些更新的操作符（如$,$inc…）等，也可以理解为sql update查询内set后面的 upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。 multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。 writeConcern :可选，抛出异常的级别。 db.collcetion.find().pretty() 集合查询并且格式化数据 db.collection.colletion.save() 集合保存方法 1234567891011121314151617181920db.collection.save( &lt;document&gt;, //文档数据 &#123; writeConcern: &lt;document&gt; //可选，抛出异常的级别。 &#125;)实例&gt; db.col.save(&#123; "_id" : ObjectId("56064f89ade2f21f36b03136"), "title" : "MongoDB", "description" : "MongoDB 是一个 Nosql 数据库", "by" : "Runoob", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "NoSQL" ], "likes" : 110&#125;) MongoDB 删除文档 12345678910db.collection.remove( &lt;query&gt;, //条件 &#123; justOne: &lt;boolean&gt;, //设为true/1，只删一个文档 writeConcern: &lt;document&gt; //抛出异常级别 &#125;)实例&gt; db.col.remove(&#123;'title':'MongoDB 教程'&#125;)WriteResult(&#123; "nRemoved" : 2 &#125;) //删除了两条数据 remove() 方法已经过时了，现在官方推荐使用 deleteOne() 和 deleteMany() 方法。如删除集合下全部文档： 1234567db.inventory.deleteMany(&#123;&#125;)删除 status 等于 A 的全部文档：db.inventory.deleteMany(&#123; status : "A" &#125;)删除 status 等于 D 的一个文档：db.inventory.deleteOne( &#123; status: "D" &#125; ) 查询文档 12345678910111213141516171819202122232425262728293031323334353637383940414243// projection 可选，使用投影操作符指定返回的键。db.collection.find(query, projection) db.collection.findOne(query, projection) //即常规 SQL 的 AND 条件。db.collection.find(&#123;key1:value1, key2:value2&#125;).pretty() //MongoDB OR 条件语句使用了关键字 $or&gt;db.collection.find( &#123; $or: [ &#123;key1: value1&#125;, &#123;key2:value2&#125; ] &#125;).pretty()//AND 和 OR 联合使用，类似常规 SQL 语句为： 'where likes&gt;50 AND (by = '菜鸟教程' OR title = 'MongoDB 教程')'&gt; db.col.find(&#123;"likes": &#123;$gt:50&#125;, $or: [&#123;"by": "菜鸟教程"&#125;,&#123;"title": "MongoDB 教程"&#125;]&#125;).pretty()&#123; "_id" : ObjectId("56063f17ade2f21f36b03133"), "title" : "MongoDB 教程", "description" : "MongoDB 是一个 Nosql 数据库", "by" : "菜鸟教程", "url" : "http://www.runoob.com", "tags" : [ "mongodb", "database", "NoSQL" ], "likes" : 100&#125;// 若不指定 projection，则默认返回所有键，指定 projection 格式如下，有两种模式db.collection.find(query, &#123;title: 1, by: 1&#125;) // inclusion模式 指定返回的键，不返回其他键db.collection.find(query, &#123;title: 0, by: 0&#125;) // exclusion模式 指定不返回的键,返回其他键//需要注意的地方 _id 键默认返回，需要主动指定 _id:0 才会隐藏两种模式不可混用（因为这样的话无法推断其他键是否应返回）db.collection.find(query, &#123;title: 1, by: 0&#125;) // 错误只能全1或全0，除了在inclusion模式时可以指定_id为0db.collection.find(query, &#123;_id:0, title: 1, by: 1&#125;) // 正确 MongoDB中条件操作符有： (&gt;) 大于 - $gt greater than (&lt;) 小于 - $lt lower than (&gt;=) 大于等于 - $gte greater than and equal (&lt;= ) 小于等于 - $lte lower than and equal (!=) 不等于 - $ne not equal to 12345db.col.find(&#123;"likes" : &#123;$gt : 100&#125;&#125;) // 上面2种sql类似Select * from col where likes &gt; 100;db.col.find(&#123;likes : &#123;$gte : 100&#125;&#125;)Select * from col where likes &gt;=100; db.COLLECTION_NAME.find().limit(NUMBER) //limit()方法基本语法 db.col.find({},{“title”:1,_id:0}).limit(2){ “title” : “PHP 教程” }{ “title” : “Java 教程” } db.COLLECTION_NAME.find().limit(NUMBER).skip(NUMBER) //只会显示第二条文档数据 补充说明skip和limit方法只适合小数据量分页，如果是百万级效率就会非常低，因为skip方法是一条条数据数过去的，建议使用where_limit不要轻易使用Skip来做查询，否则数据量大了就会导致性能急剧下降，这是因为Skip是一条一条的数过来的，多了自然就慢了。这么说Skip就要避免使用了，那么如何避免呢？首先来回顾SQL分页的后一种时间戳分页方案，这种利用字段的有序性质，利用查询来取数据的方式，可以直接避免掉了大量的数数。也就是说，如果能附带上这样的条件那查询效率就会提高，事实上是这样的么？我们来验证一下： 这里我们假设查询第100001条数据，这条数据的Amount值是：2399927，我们来写两条语句分别如下： 12db.test.sort(&#123;"amount":1&#125;).skip(100000).limit(10) //183msdb.test.find(&#123;amount:&#123;$gt:2399927&#125;&#125;).sort(&#123;"amount":1&#125;).limit(10) //53ms MongoDB sort()方法 db.COLLECTION_NAME.find().sort({KEY:1}) // 1是正序 db.col.find({},{“title”:1,_id:0}).sort({“likes”:-1}) // -1是逆序 需要注意的地方 skip(), limilt(), sort()三个放在一起执行的时候，执行的顺序是先 sort(), 然后是 skip()，最后是显示的 limit()。 创建索引 db.COLLECTION_NAME.ensureIndex({KEY:1}) 实例 db.col.ensureIndex({“title”:1}) db.col.ensureIndex({“title”:1,”description”:-1}) db.values.ensureIndex({open: 1, close: 1}, {background: true}) 还有几个可选参数 MongoDB 聚合 db.COLLECTION_NAME.aggregate(AGGREGATE_OPERATION) db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$sum : “$likes”}}}]) //计算总和db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$avg : “$likes”}}}]) //计算平均值db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$min : “$likes”}}}]) //获取集合中所有文档对应值得最小值 MongoDB 复制（副本集）MongoDB复制是将数据同步在多个服务器的过程。复制提供了数据的冗余备份，并在多个服务器上存储数据副本，提高了数据的可用性， 并可以保证数据的安全性。复制还允许您从硬件故障和服务中断中恢复数据。 MongoDB复制原理mongodb的复制至少需要两个节点。其中一个是主节点，负责处理客户端请求，其余的都是从节点，负责复制主节点上的数据。 mongodb各个节点常见的搭配方式为：一主一从、一主多从。 主节点记录在其上的所有操作oplog，从节点定期轮询主节点获取这些操作，然后对自己的数据副本执行这些操作，从而保证从节点的数据与主节点一致。 12345678910111213141516171819//关闭正在运行的MongoDB服务器后。//现在我们通过指定 --replSet 选项来启动mongoDBmongod --port "PORT" --dbpath "YOUR_DB_DATA_PATH" --replSet "REPLICA_SET_INSTANCE_NAME"实例mongod --port 27017 --dbpath "D:\set up\mongodb\data" --replSet rs0/*以上实例会启动一个名为rs0的MongoDB实例，其端口号为27017。启动后打开命令提示框并连接上mongoDB服务。在Mongo客户端使用命令rs.initiate()来启动一个新的副本集。我们可以使用rs.conf()来查看副本集的配置查看副本集状态使用 rs.status() 命令*/副本集添加成员&gt; rs.add(HOST_NAME:PORT)&gt; rs.add("mongod1.net:27017")]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法知识点]]></title>
    <url>%2F2018%2F03%2F10%2F%E9%9C%80%E8%A6%81%E8%AE%B0%E5%BE%97%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[摘要: 需要记得算法知识点 小易邀请你玩一个数字游戏，小易给你一系列的整数。你们俩使用这些整数玩游戏。每次小易会任意说一个数字出来，然后你需要从这一系列数字中选取一部分出来让它们的和等于小易所说的数字。 例如： 如果{2,1,2,7}是你有的一系列数，小易说的数字是11.你可以得到方案2+2+7=11.如果顽皮的小易想坑你，他说的数字是6，那么你没有办法拼凑出和为6 现在小易给你n个数，让你找出无法从n个数中选取部分求和的数字中的最小数。 输入第一行为数字个数n (n ≤ 20)第二行为n个数xi (1 ≤ xi ≤ 100000) 输出描述:输出最小不能由n个数选取求和组成的数 示例1 输入35 1 2 输出4 - 优解: 主要核心思路 1 2 4 由于 max(1,2) + 1 == 4 一定满足 1 ~ max = sum(1,2,4) 都可以取到该范围的任意一个数 1 2 4 8 由于 max(1,2,4) + 1 == 8 因此 成立 1 ～ max(1,2,4,8) 都可以取到该范围的任意一个数 由此可得出 前k-1项 n1,n2,n3...nk-1 如果 max(n1,n2,n3...nk-1) + 1 == nk 则 1 ~ max(n1,n2...nk) 都可以取到该范围的任意一个数 - 链接：https://www.nowcoder.com/questionTerminal/876e3c5fcfa5469f8376370d5de87c06 来源：牛客网 12345678910111213141516171819202122232425262728293031323334/** Sort后，查看有序数组的前 n 项和是否与当前项连续，* 如果不连续说明存在一个空档无法通过求和得到* */ import java.util.Arrays;import java.util.Scanner;public class Main &#123; private static int check(int[] X, int n)&#123; if (X[0]&gt;1) return 1; else if (n == 1) return X[0]+1; else &#123; int sum = X[0]; for (int i = 1; i &lt; n; i++) &#123; if (X[i]-sum&gt;1) break; else sum += X[i]; &#125; return sum+1; &#125; &#125; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); while (in.hasNext()) &#123; int n = in.nextInt(); int[] X = new int[n]; for (int i = 0; i &lt; n; i++) &#123; X[i] = in.nextInt(); &#125; Arrays.sort(X); System.out.println(check(X, n)); &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>arithmetic_learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划记录]]></title>
    <url>%2F2018%2F03%2F10%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[摘要: 动态规划解题思路 青蛙跳n个阶梯有几种方式：每次只能跳 1 、 2 F(n) = F(n-1) + F(n-2) , n &gt; 2; F(n) = n , n == 1 || n == 2; 当n&gt;3的时候，只有2个点可以直接跳到终点(跳1或者2步)， 因此计算跳到该终点的方式= 跳到n-1处的方案 + 跳到n-2处的方案 依此类推，即可得到 F(n) = F(n-1) + F(n-2) F(n-1) = F(n-2) + F(n-3) F(n-2) = F(n-3) + F(n-4) ... 青蛙跳n个阶梯（加强版）一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 1 1 2 2 3 4 通过上面方式的类比，由于可以跳n级台阶，可推出 F(n) = F(n-1) + F(n-2) + F(n-3) + ... + F(1) + F(0)/1; XY网格走法有一个X*Y的网格，小团要在此网格上从左上角到右下角，只能走格点且只能向右或向下走。请设计一个算法，计算小团有多少种走法。给定两个正整数int x,int y，请返回小团的走法数目。 1 1 2 1 2 3 2 2 2 2 3 10 1 2 1 3 1 4 1 1 1 1 1 1 1 1 1 1 无论xy的数据为多少，到达终点的前一个点只有2个钟可能，因此只要加到达该2点的走法相加即是总的走法。 F(x,y) = F(x-1,y) + F(x,y-1); 拼凑面额给你六种面额1、5、10、20、50、100元的纸币，假设每种币值的数量都足够多，编写程序求组成N员（N为0-10000的非负整数）的不同组合的个数。 解决问题的思路，使用动态规划，dp[7][N+1] 行： 代表coins 0 1 5 10 20 50 100 越往后使用到的硬币就更多 列： 代表N有几种组合方式 从1～N的原因，dp[row][column] = dp[row-1][column] + dp[row-1][column - coins[row]] 第一行 coins：无 第二行 只使用coins：1时， 从1～N 每个分别有几种组合的方式 第三行 只使用coins：1 5时，由于第一行已经得出只使用coins 1的方式，使用只需要在此基础上加入coins 5即可 从1～N 每个分别有几种组合的方式 ... 依此类推 得出以上解决方案 现在对该方案进行优化，将dp[7][N+1] 优化成 dp[N+1] 思路相同 dp[column] = dp[column] + dp[column - coins[row]]]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>arthmetic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP的实现原理]]></title>
    <url>%2F2018%2F01%2F22%2FSpring%20AOP%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[摘要: Spring AOP的实现原理 Spring AOP的实现原理ps：IntelliJ IDEA 查看源码需要用到的快捷键(mac): ⌘⌥B 接口对应实现的类及方法 ⌘U 该类的方法所实现某个接口的类或方法 ⌘⌥← Back前一个高亮处 ⌘⌥→ ForWard后一个高亮处 首先Spring提供两种方式来生成代理对象：JDKProxy和Cglib，具体使用哪个一个方式生成由AopProxyFactory根据AdvisedSupport对象配置来决定。默认使用的目标类是接口或是proxyJdkDynamicAopProxy进行代理，否则使用ObjenesisCglibAopProxy]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三种工厂设计模式对比]]></title>
    <url>%2F2018%2F01%2F20%2F%E4%B8%89%E7%A7%8D%E5%B7%A5%E5%8E%82%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[摘要: 三种工厂设计模式对比 简单工厂模式 你传入一个参数，根据参数来返回你需要的实例。 个人理解：专业生产产品(比如该工厂只生产各种鼠标， 一个工厂完成各种生产，压力大；代码上实现简单) 工厂方法模式 创建一个工厂接口，其他具体的工厂类去实现这个接口， 需要的的时候就直接去new这个工厂的实例，然后调用创建方法。 个人理解：同样是专业生产产品(只生产各种鼠标方式， 但是不同于简单工厂，专业的工厂生产该产品；工厂方法；代码上实现上相对简单工厂比较麻烦) 抽象工厂模式 首先要有一个工厂接口，再有若干个实现类去实现这个接口， 然后子类去继承这个生产线去实现具体生产什么。 个人理解：生产多种类型的产品(特定的工厂生产该厂对应的多种产品；代码实现起来比工厂模式比较复杂，多个产品需要维护。如果抽象工厂模式只有一个产品就变成了工厂模式了) 参考大佬的总结]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>工厂设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[double初学者注意点]]></title>
    <url>%2F2018%2F01%2F11%2Fdouble%E5%88%9D%E5%AD%A6%E8%80%85%E6%B3%A8%E6%84%8F%E7%82%B9%2F</url>
    <content type="text"><![CDATA[摘要: double初学者注意点,尤其是精度问题 遇到问题及解决##double 缺失精度 场景： 将double类型的数据保留2位小数，需要四舍五入 第一种错误的思路： 将double类型*100强制转化为int 1234public static int fromYuanToFen(final double yuan)&#123; return (int) (yuan*100);&#125; 输入33.33d 输出3333 看似应该很正常，但是遇到下面情况问题就来了输入19.9d 输出==1989== 这个写法有3个问题： double转化int存在数据溢出的问题 (使用==BigDecimal==替代) 这样转化违背了四舍五入 (BigDecimal的==setScale==方法) 这样转化如果遇到特殊情况会导致精度缺失，在商场项目中是每批少了一分钱的情况 此时开始探索解决方案第二种错误的思路： 12345double d = 35.9d;//出现问题的原因在这，直接将 d 赋值 精度仍然缺失BigDecimal b1 = new BigDecimal(d);d = b.setScale(2,BigDecimal.ROUND_HALF_UP).doubleValue();System.out.println(d); 该效果仍然是缺失精度。 最终方案： 123456789//double d = 12353.424139d;double d = 12.9;// 将 Double.toString(d) 赋给 BigDecimal 保证double不缺少精度BigDecimal bigDecimal = new BigDecimal(Double.toString(d));System.out.println(bigDecimal.doubleValue());System.out.println(bigDecimal.setScale(2,BigDecimal.ROUND_HALF_UP)); 最终输出的结果为 12.912.90 这答案真是预期想要的结果 BigDecimal. //四舍五入 ROUND_HALF_UP //后面的精度舍去 ROUND_HALF_DOWN //如果舍去为的最左边第一个数是奇数则采用ROUND_HALF_UP，偶数则ROUND_HALF_DOWN ROUND_HALF_EVEN //如果 BigDecimal 是正的，则做 ROUND_UP 操作；如果为负，则做 ROUND_DOWN 操作。 ROUND_CEILING]]></content>
      <categories>
        <category>JavaSE</category>
      </categories>
      <tags>
        <tag>double</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程问题及总体解决方案和对应的原理]]></title>
    <url>%2F2017%2F12%2F23%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E9%97%AE%E9%A2%98%E5%8F%8A%E6%80%BB%E4%BD%93%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E5%92%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[摘要: 多线程问题、如何解决多线程的问题及遇到部分对应问题时该选择哪种集合或接口 单线程的问题报错的提示： 12345678910Exception in thread &quot;main&quot; java.util.ConcurrentModificationExceptionat java.util.AbstractList$Itr.checkForComodification(Unknown Source)at java.util.AbstractList$Itr.next(Unknown Source)报错对应的代码位置：final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; 出现该错误时，就需要分析出现的问题了 错误代码重现 123456789101112131415161718192021222324252627//这个错误方式是从网上找到的public class Test &#123; public static void main(String[] args) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); list.add(2); Iterator&lt;Integer&gt; iterator = list.iterator(); while(iterator.hasNext())&#123; Integer integer = iterator.next(); if(integer==2) list.remove(integer); &#125; &#125;&#125;//这种方式是本人体验过的错误public class Test &#123; public static void main(String[] args) &#123; ArrayList&lt;Integer&gt; integers = new ArrayList&lt;Integer&gt;(); integers.add(2); for (Integer integer: integers) &#123; if(integer == 2)&#123; integers.remove(integer); &#125; &#125; &#125;&#125; 2个报错的提示是一样的，原因是 foreach的实现原理就是对集合遍历迭代器。 导致报错的原因从 实现类ArrayList&lt;E&gt; 中找出问题 首先将ArrayList转化为Iterator的实现代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public ListIterator&lt;E&gt; listIterator(int index) &#123; if (index &lt; 0 || index &gt; size) throw new IndexOutOfBoundsException(&quot;Index: &quot;+index); return new ListItr(index); &#125;//继承了Itrprivate class ListItr extends Itr implements ListIterator&lt;E&gt; &#123;//Itr 是 ArrayList中的成员内部类private class Itr implements Iterator&lt;E&gt; &#123; //访问下一个元素的索引 int cursor; // index of next element to return //访问上一个元素的索引 int lastRet = -1; // index of last element returned; -1 if no such //对ArrayList修改的期望值，初始化值为ArrayList修改操作值(modCount) int expectedModCount = modCount; public boolean hasNext() &#123; return cursor != size; &#125; @SuppressWarnings(&quot;unchecked&quot;) public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; //调用ArrayList自身的remove的方法 //值为lastRet的原因是在循环中获取当前值的方式是next()，取完值后lastRet等于取出的值对应的下表 //后面会提到ArrayListremove的原理 ArrayList.this.remove(lastRet); //ArrayList底层实现是数组，所以删除一个元素，后面的元素向前移动一位 cursor = lastRet; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; @Override @SuppressWarnings(&quot;unchecked&quot;) public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123; Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) &#123; return; &#125; final Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) &#123; throw new ConcurrentModificationException(); &#125; while (i != size &amp;&amp; modCount == expectedModCount) &#123; consumer.accept((E) elementData[i++]); &#125; // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125; ArrayList实现move方式 1234567891011121314151617181920212223public E remove(int index) &#123; //判断index是否越界 rangeCheck(index); //ArrayList操作数+1 modCount++; E oldValue = elementData(index); //获取删除后需要移动元素 int numMoved = size - index - 1; if (numMoved &gt; 0) //将要删除的下表元素直接覆盖掉，后面的元素直接向前移动一位 System.arraycopy(elementData, index+1, elementData, index, numMoved); //赋值为null 为了GC可以处理回收 elementData[--size] = null; // clear to let GC do its work return oldValue;&#125;private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125; 到这应该可以看出报错的原因出现在哪了 遍历的方式使用的是迭代器(Itr)的方式，但是对于ArrayList的操作就确实在ArrayList，这就导致了对应ArrayList操作，但是new Itr的迭代器不知道这个操作，从而出现了expectedModCount 为0，而modCount为1，在迭代一个元素(对应的方法next())报错了。 针对此问题的处理方案很简单： 12345678910111213public class Test &#123; public static void main(String[] args) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); list.add(2); Iterator&lt;Integer&gt; iterator = list.iterator(); while(iterator.hasNext())&#123; Integer integer = iterator.next(); if(integer==2) // list.remove(integer); error iterator.remove(); true &#125; &#125;&#125; 当然还有其他的解决方案： 建一个集合，记录需要删除的元素，之后统一删除 1234List&lt;Integer&gt; tempList = new ArrayList&lt;Integet&gt;();遍历tempList，tempList.add(需要的删除的数据);在原本的集合list操作： list.removeAll(tempList); 使用线程安全CopyOnWriteArrayList进行删除操作 1234567891011121314151617List&lt;string&gt; myList = new CopyOnWriteArrayList&lt;string&gt;();myList.add( &quot;1&quot;);myList.add( &quot;2&quot;);myList.add( &quot;3&quot;);myList.add( &quot;4&quot;);myList.add( &quot;5&quot;); Iterator&lt;string&gt; it = myList.iterator(); while (it.hasNext()) &#123; String value = it.next(); if (value.equals( &quot;3&quot;)) &#123; myList.remove( &quot;4&quot;); myList.add( &quot;6&quot;); myList.add( &quot;7&quot;); &#125;&#125; 不使用Iterator进行遍历，需要注意的是自己保证索引正常 12345678for ( int i = 0; i &lt; myList.size(); i++) &#123; String value = myList.get(i); System. out.println( &quot;List Value:&quot; + value); if (value.equals( &quot;3&quot;)) &#123; myList.remove(value); // ok i--; // 因为位置发生改变，所以必须修改i的位置 &#125;&#125; 以上都是针对==单线程==的可行处理方案 多线程的相同的问题及处理在多线程出现相同的问题时，解决的方案只能使用单线程的第3个方案(不使用Iterator进行遍历，需要注意的是自己保证索引正常) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546List&lt;string&gt; myList = new CopyOnWriteArrayList&lt;string&gt;(); myList.add( &quot;1&quot;); myList.add( &quot;2&quot;); myList.add( &quot;3&quot;); myList.add( &quot;4&quot;); myList.add( &quot;5&quot;); new Thread(new Runnable() &#123; @Override public void run() &#123; for (String string : myList) &#123; System.out.println(&quot;遍历集合 value = &quot; + string); try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; myList.size(); i++) &#123; String value = myList.get(i); System.out.println(&quot;删除元素 value = &quot; + value); if (value.equals( &quot;3&quot;)) &#123; myList.remove(value); i--; // 注意 &#125; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;).start(); 针对多线程出现该问题的其他方案： 在所有遍历增删地方都加上synchronized或者使用Collections.synchronizedList，虽然能解决问题但是并不推荐，因为增删造成的同步锁可能会阻塞遍历操作。 推荐使用ConcurrentHashMap或者CopyOnWriteArrayList。 使用CopyOnWriteArrayList需要注意： CopyOnWriteArrayList不能使用Iterator.remove()进行删除。 CopyOnWriteArrayList使用Iterator且使用List.remove(Object);会出现如下异常： java.lang.UnsupportedOperationException: Unsupported operation remove at java.util.concurrent.CopyOnWriteArrayList$ListIteratorImpl.remove(CopyOnWriteArrayList.java:804) 虽然CopyOnWriteArrayList可以解决开发工作中的多线程的并发问题，但是不能保证数据的实时一致性。所以如果想马上写入的数据马上就可以读到，就不能使用CopyOnWrite。 既然提到 CopyOnWriteArrayList 这里就稍微分析下实现CopyOnWriteArrayList所有的构造函数都会创建一个Object的数组 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; private static final long serialVersionUID = 8673264195747942595L; /** The lock protecting all mutators */ final transient ReentrantLock lock = new ReentrantLock(); /** The array, accessed only via getArray/setArray. */ private transient volatile Object[] array; final Object[] getArray() &#123; return array; &#125; /** * Sets the array. */ final void setArray(Object[] a) &#123; array = a; &#125; ... public CopyOnWriteArrayList() &#123; setArray(new Object[0]); &#125; public CopyOnWriteArrayList(Collection&lt;? extends E&gt; c) &#123; Object[] elements; if (c.getClass() == CopyOnWriteArrayList.class) elements = ((CopyOnWriteArrayList&lt;?&gt;)c).getArray(); else &#123; elements = c.toArray(); // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elements.getClass() != Object[].class) elements = Arrays.copyOf(elements, elements.length, Object[].class); &#125; setArray(elements); &#125; public CopyOnWriteArrayList(E[] toCopyIn) &#123; setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class)); &#125; CopyOnWriteArrayList的add/remove的实现方式基本都是一个结构 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125;public E remove(int index) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; E oldValue = get(elements, index); int numMoved = len - index - 1; if (numMoved == 0) setArray(Arrays.copyOf(elements, len - 1)); else &#123; Object[] newElements = new Object[len - 1]; System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index + 1, newElements, index, numMoved); setArray(newElements); &#125; return oldValue; &#125; finally &#123; lock.unlock(); &#125;&#125;方法: final ReentrantLock lock = this.lock; lock.lock(); try &#123; ... 获取当前线程数组，然后对应数组进行操作 不管add还是remove都是用到Arrays.copyOf add: Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); remove: int numMoved = len - index - 1; if (numMoved == 0) setArray(Arrays.copyOf(elements, len - 1)); else &#123; Object[] newElements = new Object[len - 1]; System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index + 1, newElements, index, numMoved); setArray(newElements); &#125; ... &#125; finally &#123; lock.unlock(); &#125; 最后CopyOnWriteArrayList的优点和缺点(应用场景可参考): 优点 解决的开发工作中的多线程的并发问题。 缺点 内存占有问题:很明显，两个数组同时驻扎在内存中，如果实际应用中，数据比较多，而且比较大的情况下，占用内存会比较大，针对这个其实可以用ConcurrentHashMap来代替。 数据一致性:CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器 既然提到 ConcurrentHashMap 这里就稍微分析下实现(待续)由于要部分看懂需要大致明白一些关键字 volatile： 真正意义在于产生内存屏障，禁止指令重排序。volatile只能保证可见性，不能保证原子性(所以不能保证线程安全) transient： 一个对象只要实现了==Serilizable==接口，这个对象就可以被序列化，transient提供了把不需要序列化的属性前加上transient即可(换句话说，该类的属性仅存在于调用者的内存中而不会写到磁盘里持久化) Synchronized Synchronized进过编译，会在同步块的前后分别形成monitorenter和monitorexit这个两个字节码指令。在执行monitorenter指令时，首先要尝试获取对象锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象锁，把锁的计算器加1，相应的，在执行monitorexit指令时会将锁计算器就减1，当计算器为0时，锁就被释放了。如果获取对象锁失败，那当前线程就要阻塞，直到对象锁被另一个线程释放为止。 ReentrantLock 由于ReentrantLock是java.util.concurrent包下提供的一套互斥锁，相比Synchronized，ReentrantLock类提供了一些高级功能，主要有以下3项： 等待可中断，持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待，这相当于Synchronized来说可以避免出现死锁的情况。 公平锁，多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁，但公平锁表现的性能不是很好。 锁绑定多个条件，一个ReentrantLock对象可以同时绑定对个对象。 引用Java ConcurrentModificationException 异常分析与解决方案CopyOnWriteArrayList的原理和使用方法java的两种同步方式， Synchronized与ReentrantLock的区别]]></content>
      <categories>
        <category>JavaSE</category>
      </categories>
      <tags>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springMVC文件上传下载及图片显示]]></title>
    <url>%2F2017%2F12%2F17%2FspringMVC%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E4%B8%8B%E8%BD%BD%E5%8F%8A%E5%9B%BE%E7%89%87%E6%98%BE%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[摘要: springMVC文件上传下载及图片显示 文件上传前端 12345&lt;form id=&quot;form1&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot; action=&quot;$&#123;pageContext.request.contextPath&#125;/shop/addShop.do&quot; &gt; 商家图片上传&lt;input type=&quot;file&quot; id=&quot;shopImage&quot; name=&quot;shopImage&quot; /&gt;&lt;br/&gt; 商家名称&lt;input type=&quot;text&quot; id=&quot;shopName&quot; name=&quot;shopName&quot; value=&quot;test123&quot; /&gt;&lt;/form&gt;&lt;br/&gt; ShopController.java 1234567891011121314@RequestMapping(&quot;/addShop.do&quot;)public String addShop(MultipartFile shopImage,Shop shop, HttpServletRequest request)&#123; User user = (User) request.getSession().getAttribute(&quot;loginUser&quot;); if(user == null)&#123; logger.error(&quot;用户未登录&quot;); &#125; shop.setShopUserId(user.getUserId()); int result = shopService.addShop(shopImage,shop); return &quot;redirect:goShopRedirect.do?result=&quot;+result;&#125; ShopService.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081@Overridepublic int addShop(MultipartFile shopImage, Shop shop) &#123; if(shop == null || shopImage.isEmpty())&#123; return 0; &#125; //获取shop图片保存路径 String originalFilename = shopImage.getOriginalFilename(); String shopImagePath = PropertiesUtil.getString(&quot;shop.image.path&quot;); //文件名： long时间+&quot;-&quot;+源文件名 String fileName = (new Date()).getTime()/1000 + &quot;-&quot; +originalFilename; File folder = new File(shopImagePath); if (!folder.exists()) &#123; folder.mkdirs(); &#125; //将上传的图片保存到指定路径 File image = new File(shopImagePath,fileName); try &#123; shopImage.transferTo(image); shop.setShopLogoPath(fileName); &#125; catch (IOException e) &#123; logger.error(&quot;商家上传图片失败&quot;); logger.error(e.toString()); e.printStackTrace(); throw new RuntimeException(); &#125; shop.setCreateTime(new Date()); return shopMapper.insertSelective(shop);&#125;@Overridepublic int updateShop(MultipartFile shopImage, Shop shop) &#123; if(shop == null || StringUtils.isNullOrBlank(shop.getShopId()))&#123; return 0; &#125; //如果图片为空就不上传 不替代之前的图片 //如果不为空 替代之前的图片 并且删除之前的图片 if(shopImage != null &amp;&amp; !shopImage.isEmpty())&#123; String originalFilename = shopImage.getOriginalFilename(); String shopImagePath = PropertiesUtil.getString(&quot;shop.image.path&quot;); String fileName = (new Date()).getTime()/1000 + &quot;-&quot; +originalFilename; File image = new File(shopImagePath,fileName); try &#123; shopImage.transferTo(image); shop.setShopLogoPath(fileName); //获取修改之前的shop信息 Shop tmpShop = this.getShopByShopId(shop); //删除之前的图片 deleteOldImage(tmpShop.getShopLogoPath()); &#125; catch (IOException e) &#123; logger.error(&quot;商家上传图片失败&quot;); logger.error(e.toString()); throw new RuntimeException(); &#125; &#125; return shopMapper.updateByPrimaryKeySelective(shop);&#125;//删除旧的图片private void deleteOldImage(String shopLogoPath)&#123; String shopImagePath = PropertiesUtil.getString(&quot;shop.image.path&quot;); String filePath = shopImagePath + &quot;/&quot; + shopLogoPath; File file = new File(filePath); try &#123; FileUtils.forceDelete(file); &#125; catch (IOException e) &#123; logger.error(&quot;图片删除失败&quot;); e.printStackTrace(); &#125;&#125; 文件下载1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 下载对应的文件名 * * @param fileName * @param fileType * @param request * @param response * @throws Exception */@RequestMapping(value = &quot;/downloadFile.do&quot;)@ResponseBodypublic void downloadFile(String fileName, String fileType, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // 通过 文件名和文件类型 获取对应的目标文件 File targetFile = getTargetFile(fileType, fileName); if (targetFile == null) &#123; logger.error(fileName + &quot;该文件不存在，无法下载&quot;); return; &#125; response.setContentType(&quot;application/octet-stream&quot;); response.setHeader(&quot;Content-Disposition&quot;, &quot;inline;filename=&quot; + new String(targetFile.getName().getBytes(&quot;gb2312&quot;), &quot;ISO-8859-1&quot;)); // 读取要下载的文件，保存到文件输入流 FileInputStream in = new FileInputStream(targetFile); // 创建输出流 OutputStream out = response.getOutputStream(); // 创建缓冲区 byte buffer[] = new byte[1024]; int len = 0; // 循环将输入流中的内容读取到缓冲区当中 while ((len = in.read(buffer)) &gt; 0) &#123; // 输出缓冲区的内容到浏览器，实现文件下载 out.write(buffer, 0, len); &#125; // 关闭文件输入流 in.close(); // 关闭输出流 out.close();&#125; 图片显示前端 123&lt;p&gt;商家图片&lt;/p&gt;&lt;img src=&quot;$&#123;pageContext.request.contextPath&#125;/shop/loadImage.do?type=shop&amp;shopLogoPath=1513499222-avatar.jpg&quot; height=&quot;200&quot; width=&quot;200&quot;&gt; ShopController.java 1234567891011121314151617181920212223242526272829303132333435@RequestMapping(&quot;/loadImage.do&quot;)public void loadImage(String shopLogoPath,String type,HttpServletResponse response)&#123; String shopImagePath = &quot;&quot;; if(&quot;goods&quot;.equals(type))&#123; shopImagePath = PropertiesUtil.getString(&quot;goods.image.path&quot;); &#125;else if(&quot;shop&quot;.equals(type))&#123; shopImagePath = PropertiesUtil.getString(&quot;shop.image.path&quot;); &#125; File file = new File(shopImagePath+&quot;/&quot;+shopLogoPath); if(!file.isFile() || !file.exists())&#123; logger.error(&quot;不是文件或者文件不存在&quot;); &#125; OutputStream outputStream = null; try &#123; outputStream = response.getOutputStream(); FileUtils.copyFile(file,outputStream); outputStream.flush(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; if(outputStream != null)&#123; try &#123; outputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 额外对文件的操作对文件版本进行排序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151// 获取 fileType的客户端 从 client 文件夹中获取所有文件private List&lt;ClientFile&gt; queryClientFile(String fileType) &#123; List&lt;ClientFile&gt; list = new ArrayList&lt;ClientFile&gt;(); String path = &quot;&quot;; if (CLIENTTYPE.equals(fileType)) &#123; path = resourceDir; &#125; else &#123; path = resourceDir + &quot;module/&quot; + fileType + &quot;/&quot;; &#125; File folder = new File(path); if (!folder.exists()) &#123; folder.mkdirs(); &#125; // 获取当前文件夹下 所有文件 List&lt;File&gt; files = getcurrentDirAllFiles(fileType, folder); ClientFile clientFile = null; for (File file : files) &#123; clientFile = new ClientFile(); clientFile.setClientFileName(file.getName()); // 获取文件版本 1.2.3 clientFile.setClientFileVersion(getFileVersion(file.getName())); // 获取文件 上传时间 将long类型转为String类型 clientFile.setUploadTime(LongToDate(file.lastModified())); list.add(clientFile); &#125; return list;&#125;// 获取当前文件夹下 所有文件 按文件版本大小private List&lt;File&gt; getcurrentDirAllFiles(String fileType, File f) &#123; File fa[] = f.listFiles(); List&lt;File&gt; files = new ArrayList&lt;File&gt;(); if(fa != null &amp;&amp; fa.length &gt; 0) &#123; // 客户上传文件 存储dll文件 需要压缩完.rar或者.zip提交给后台 // 客户下载文件dll类型文件 服务器 .rar或者.zip后缀文件发送给客户 if (!fileType.equals(&quot;exe&quot;)) &#123; for (int i = 0; i &lt; fa.length; i++) &#123; File fs = fa[i]; if (!fs.isDirectory() &amp;&amp; (fs.getName().indexOf(&quot;.zip&quot;) &gt; -1)) &#123; files.add(fs); &#125; &#125; &#125; // 客户上传文件 存储exe文件 .exe后缀文件 提交给后台 // 客户下载文件exe类型文件 服务器 后缀文件发送给客户 if (fileType.equals(&quot;exe&quot;)) &#123; for (int i = 0; i &lt; fa.length; i++) &#123; File fs = fa[i]; if (!fs.isDirectory() &amp;&amp; fs.getName().indexOf(&quot;.exe&quot;) &gt; -1) &#123; files.add(fs); &#125; &#125; &#125; &#125; // 进行文件名排序 排序的内容比较为 1.2.3 小于 1.3.4 Collections.sort(files, new FileVersionComparator()); return files;&#125;// 截取文件版本 通过正则表达式截取成 -v1.2.3.exe 再截取为 1.2.3进行比较private String getFileVersion(String fileName) &#123; String version = &quot;&quot;; // 正则表示 只截取 开头为-v后缀为(.exe|.rar|.zip)// String pattern = &quot;-v.+(.exe|.rar|.zip)$&quot;; String pattern = &quot;-v.+(.exe|.zip)$&quot;; Pattern r = Pattern.compile(pattern); Matcher m = r.matcher(fileName); if (m.find()) &#123; version = m.group(); if (version.indexOf(&quot;.exe&quot;) &gt; -1) &#123; int index = version.indexOf(&quot;.exe&quot;); version = version.substring(2, index); &#125; if (version.indexOf(&quot;.zip&quot;) &gt; -1) &#123; int index = version.indexOf(&quot;.zip&quot;); version = version.substring(2, index); &#125; &#125; return version;&#125;public int versionStrToInt(String str) &#123; // 将文件名xxx-assistant-beta-v1.2.3.exe 切割成 1.2.3 str = getFileVersion(str); // 1.2.3 转换为 020230 // 2.3.12 转换为 020312 String[] tmpArr = str.split(&quot;\\.&quot;); int total = 0; try &#123; int length = tmpArr.length - 1; for (int i = 0; i &lt;= length; i++) &#123; int k = Integer.valueOf(tmpArr[i]); total += (int) (k * Math.pow(100, (length - i))); &#125; &#125; catch (Exception e) &#123; logger.error(&quot;文件版本转换出错&quot;); // e.printStackTrace(); &#125; return total;&#125;/** * * 文件版本进行比较 1.2.3 &lt; 2.3.10 */class FileVersionComparator implements Comparator&lt;File&gt; &#123; @Override public int compare(File file1, File file2) &#123; String o1 = file1.getName(); String o2 = file2.getName(); // o1为空返回1 o2为空返回-1 // 不为空 将版本转化为 整数 1.2.3 010203 进行比较 if (StringUtils.isNotNullAndBlank(o1) &amp;&amp; StringUtils.isNotNullAndBlank(o2)) &#123; int i1 = versionStrToInt(o1); int i2 = versionStrToInt(o2); if (i2 &gt; i1) &#123; return 1; &#125; else if (i2 &lt; i1) &#123; return -1; &#125; else &#123; return 0; &#125; &#125; else if (StringUtils.isNotNullAndBlank(o1)) &#123; return 1; &#125; else if (StringUtils.isNotNullAndBlank(o2)) &#123; return -1; &#125; else &#123; return 0; &#125; &#125;&#125; 按照时间 返回文件12345678910111213141516// 按照时间 返回最新的客户端文件 /* * private File getNewestFile(String fileType, File f) &#123; long max = 0; int * result = -1; File fa[] = f.listFiles(); * * if (fileType.equals(&quot;dll&quot;)) &#123; for (int i = 0; i &lt; fa.length; i++) &#123; File fs = * fa[i]; if (!fs.isDirectory() &amp;&amp; (fs.getName().indexOf(&quot;.zip&quot;) &gt; -1 || * fs.getName().indexOf(&quot;.rar&quot;) &gt; -1)) &#123; if (max &lt; fs.lastModified()) &#123; max = * fs.lastModified(); result = i; &#125; &#125; &#125; &#125; if (fileType.equals(&quot;exe&quot;)) &#123; for (int * i = 0; i &lt; fa.length; i++) &#123; File fs = fa[i]; if (!fs.isDirectory() &amp;&amp; * fs.getName().indexOf(&quot;.exe&quot;) &gt; -1) &#123; if (max &lt; fs.lastModified()) &#123; max = * fs.lastModified(); result = i; &#125; &#125; &#125; &#125; * * return result == -1?null:fa[result]; &#125; */]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>springMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[接口文档]]></title>
    <url>%2F2017%2F12%2F16%2F%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[摘要: 接口文档 接口文档注意12345678910111213141516AjaxResult 返回的数据&#123; &quot;statusCode&quot;: 200, &quot;message&quot;: &quot;操作成功&quot;, &quot;causeBy&quot;: null, &quot;callBackTypes&quot;: null, &quot;method&quot;: null, &quot;needTranslate&quot;: false, &quot;type&quot;: &quot;__custom&quot;, &quot;data&quot;: null, //如果需要data的时候可以在此处获取 &quot;translateBodys&quot;: null, &quot;callbackType&quot;: null&#125;所有属性中的 createTime 和 lastModifyTime 都由后台解决即可 用户登录 用户登录 异步Ajax url： /onlineShopping/login.do 参数：{&quot;userId&quot;:&quot;数据&quot;} response: ajaxResult 用户退出 异步Ajax url： /onlineShopping/logout.do 参数：{User:属性} //页面重定向(后续对应修改) 也可以改成异步方式 response: &quot;redirect:login.jsp&quot;; 获取当前已经登录的用户信息 异步Ajax url： /onlineShopping/getCurrentLoginUser.do 参数：{无} response: User对象的信息 用户user 通过userId获取user信息 异步Ajax url： /onlineShopping/user/loadUser.do 参数：{&quot;userId&quot;:&quot;数据&quot;} response: user对象 增user 异步Ajax url： /onlineShopping/user/addUser.do 参数：{User:属性} response: ajaxResult(data中存放用户信息) 删user 异步Ajax url： /onlineShopping/user/deleteUser.do 参数：{&quot;userId&quot;:&quot;数据&quot;} response: ajaxResult 改user 表单Form url： /onlineShopping/user/updateUser.do 参数：{User:属性} response: ajaxResult 校验userCode是否存在 异步Ajax url： /onlineShopping/user/checkUserCode.do 参数：{&quot;userCode&quot;:&quot;值&quot;} response: 整型(0:表示不存在) 商家shop 通过shopId获取shop信息 异步Ajax url： /onlineShopping/shop/loadShop.do 参数：{&quot;shopId&quot;:&quot;数据&quot;} response: shop对象 增shop 表单Form url： /onlineShopping/shop/addShop.do 参数：Shop的属性和图片 参数接收名 shopImage response: ajaxResult 注意：未传图片也默认添加失败 删shop 异步Ajax url： /onlineShopping/shop/deleteShop.do 参数：{&quot;shopId&quot;:&quot;数据&quot;} response: ajaxResult 改shop 表单Form url： /onlineShopping/shop/updateShop.do 参数：Shop的属性和图片 参数接收名 shopImage response: ajaxResult 注意：图片可以不传 默认使用之前的，如果上传图片代替以前的 获取所有的商家数据 进行分页 异步Ajax url： /onlineShopping/shop/queryShopPage.do 参数：{&quot;pageNum&quot;:数值,&quot;pageSize&quot;:数值} 参数说明：第几页,一页几个(前端不传，后台默认0,10) response: PageInfo&lt;Shop&gt; shop分页数据 加载图片 &lt;img src=&quot;url?参数&quot; url： /onlineShopping/shop/loadImage.do 参数：shopLogoPath=shop.shopLogoPath&amp;type=shop 注意：type就传2种值 goods/shop response: 图片的二进制数据 校验shopName是否存在 异步Ajax url： /onlineShopping/shop/checkShopName.do 参数：{&quot;shopName&quot;:&quot;值&quot;} response: 整型(0:表示不存在) 商品goods 通过goodsId获取goods信息 异步Ajax url： /onlineShopping/goods/loadGoods.do 参数：{&quot;goodsId&quot;:&quot;数据&quot;} response: goods对象 增goods 表单Form url： /onlineShopping/goods/addGoods.do 参数：goods的属性和图片 参数接收名 goodsImage response: ajaxResult 注意：未传图片也默认添加失败 删goods 异步Ajax url： /onlineShopping/goods/deleteGoods.do 参数：{&quot;goodsId&quot;:&quot;数据&quot;} response: ajaxResult 改goods 表单Form url： /onlineShopping/goods/updateGoods.do 参数：goods的属性和图片 参数接收名 goodsImage response: ajaxResult 注意：图片可以不传 默认使用之前的，如果上传图片代替以前的 获取当前商家对应商家的商品 进行分页 异步Ajax url： /onlineShopping/goods/getGoodsByUserId.do 参数：{&quot;pageNum&quot;:数值,&quot;pageSize&quot;:数值} 参数说明：第几页,一页几个(前端不传，后台默认0,10) response: PageInfo&lt;Goods&gt; 分页的数据(包含原需要展示的数据) 获取选中的商家展示对应的商品 进行分页 异步Ajax url： /onlineShopping/goods/getGoodsByShopId.do 参数：{&quot;pageNum&quot;:数值,&quot;pageSize&quot;:数值,&quot;shopId&quot;:&quot;值&quot;} 参数说明：第几页,一页几个(前端不传，后台默认0,10) response: PageInfo&lt;Goods&gt; 分页的数据(包含原需要展示的数据) 首页遍历商品 可选择类型 搜索 分页 异步Ajax url： /onlineShopping/goods/queryGoodsHomePage.do 参数：{&quot;pageNum&quot;:数值,&quot;pageSize&quot;:数值,&quot;goodsName&quot;:&quot;&quot;,&quot;goodsType&quot;:&quot;&quot;} 参数说明：第几页,一页几个(前端不传，后台默认0,10)，后面2个参数可不传 response: PageInfo&lt;Goods&gt; 分页的数据(包含原需要展示的数据) 订单order 通过orderId获取order信息 异步Ajax url： /onlineShopping/order/loadOrder.do 参数：{&quot;orderId&quot;:&quot;数据&quot;} response: ajaxResult 增order 异步Ajax url： /onlineShopping/order/addOrder.do 参数：{Order:属性} response: order对象 删order 异步Ajax url： /onlineShopping/order/deleteOrder.do 参数：{&quot;orderId&quot;:&quot;数据&quot;} response: ajaxResult 改order 异步Ajax url： /onlineShopping/order/updateOrder.do 参数：{Order:属性} response: ajaxResult 添加临时订单 异步Ajax url： /onlineShopping/order/addTempOrder.do 参数：{Order:属性} response: List&lt;Order&gt; 添加后order的数组 删除临时订单 异步Ajax url： /onlineShopping/order/deleteTempOrder.do 参数：{orderId:&quot;值&quot;} response: List&lt;Order&gt; 删除后order的数组 展示临时订单 异步Ajax url： /onlineShopping/order/getTempOrder.do 参数：{无} response: List&lt;Order&gt; order的数组 获取该用户的订单信息 进行分页 异步Ajax url： /onlineShopping/order/getOrderByUserId.do 参数：{&quot;pageNum&quot;:数值,&quot;pageSize&quot;:数值} 参数说明：第几页,一页几个(前端不传，后台默认0,10) response: PageInfo&lt;Order&gt; 分页的数据(包含原需要展示的数据) 当前用户确认订单买家商家都可以 异步Ajax url： /onlineShopping/order/confirmOrder.do 参数：{&quot;orderId&quot;:&quot;值&quot;} response: AjaxResult 当前用户取消订单买家商家都可以 异步Ajax url： /onlineShopping/order/cancelOrder.do 参数：{&quot;orderId&quot;:&quot;值&quot;} response: AjaxResult 反馈feedBack 通过feedBackId获取feedBack信息 异步Ajax url： /onlineShopping/feedBack/loadFeedBack.do 参数：{&quot;feedBackId&quot;:&quot;数据&quot;} response: feedBack对象 增feedBack 异步Ajax url： /onlineShopping/feedBack/addFeedBack.do 参数：{FeedBack:属性} response: ajaxResult 删feedBack 异步Ajax url： /onlineShopping/feedBack/deleteFeedBack.do 参数：{&quot;feedBackId&quot;:&quot;数据&quot;} response: ajaxResult 改feedBack 异步Ajax url： /onlineShopping/feedBack/updateFeedBack.do 参数：{FeedBack:属性} response: ajaxResult 判断 当前用户是否已经评论该商品 异步Ajax url： /onlineShopping/feedBack/checkUserIsFeedBack.do 参数：{&quot;goodsId&quot;:&quot;值&quot;} response: 整型 (评论过1 未评论为0) 商家 回复买家的评论 异步Ajax url： /onlineShopping/feedBack/revertFeedBack.do 参数：{&quot;feedBackId&quot;:&quot;反馈编码&quot;,&quot;shopRevert&quot;:&quot;商家回复信息&quot;} response: 整型 (评论过1 未评论为0)]]></content>
      <categories>
        <category>接口文档</category>
      </categories>
      <tags>
        <tag>接口文档</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跨域问题]]></title>
    <url>%2F2017%2F12%2F03%2F%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[摘要: 跨域问题的解决方案 跨域问题2种解决方案 127.0.0.1 向 外网发送一个请求 前端会报错(Response to preflight request doesn’t pass access control check: No ‘Access-Control-Allow-Origin’ header is prese…) 第一种也是比较简单的就是从后台发送跨域请求1234567891011121314151617181920212223242526272829303132@RequestMapping(&quot;/load.do&quot;) @ResponseBody public String load(int id)&#123; String result = null; JobGroup jobGroup = jobGroupDao.load(id); if(jobGroup != null) &#123; List&lt;String&gt; registryList = null; if (jobGroup.getAddressType() == 0) &#123; registryList = JobRegistryMonitorHelper.discover(RegistryConfig.RegistType.EXECUTOR.name(), jobGroup.getAppName()); &#125; else &#123; if (StringUtils.isNotBlank(jobGroup.getAddressList())) &#123; registryList = Arrays.asList(jobGroup.getAddressList().split(&quot;,&quot;)); &#125; &#125; jobGroup.setRegistryList(registryList); &#125; try &#123; byte[] bytes = HttpClientUtil.postRequest(&quot;http://&quot;+jobGroup.getRegistryList().get(0)+&quot;/getAllHandlers.do&quot;, null); result = new String(bytes,&quot;UTF-8&quot;); //如果返回结果是 4com.bosssoft.xxx 说明访问失败 //或者 null 说明注册成功 但是无@Hander if(result.indexOf(&quot;4com&quot;) &gt; -1 || result.indexOf(&quot;null&quot;) &gt; -1) &#123; result = &quot;&quot;; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return result; &#125; 另外一种方式就在前端发送(jsonp)后续补上…]]></content>
      <categories>
        <category>J2EE</category>
      </categories>
      <tags>
        <tag>跨域问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssm引入tk-mybatis]]></title>
    <url>%2F2017%2F12%2F03%2Fssm%E5%BC%95%E5%85%A5tk-mybatis%2F</url>
    <content type="text"><![CDATA[摘要: ssm引入tk-mybatis tk-mybatis引入搭建好ssm项目pom.xml 123456789101112131415&lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt;&lt;!-- tk.mybatis 对应的分页插件 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;$&#123;pagehelper.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 通用的mybatisMapper类 --&gt;&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt;&lt;/dependency&gt; applicationContext-dao.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:c=&quot;http://www.springframework.org/schema/c&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.3.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.3.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.3.xsd&quot;&gt; &lt;!-- 开启spring注解方式 --&gt; &lt;context:annotation-config&gt;&lt;/context:annotation-config&gt; &lt;!-- 加载db.properties文件内容，文件的内容key需要特殊命名化 --&gt; &lt;context:property-placeholder location=&quot;classpath:jdbc.properties&quot;/&gt; &lt;bean id=&quot;log-filter&quot; class=&quot;com.alibaba.druid.filter.logging.Log4jFilter&quot;&gt; &lt;property name=&quot;resultSetLogEnabled&quot; value=&quot;true&quot; /&gt; &lt;/bean&gt; &lt;!-- 配置数据源 --&gt; &lt;bean name=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;jdbc.driverClassName&#125;&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url&#125;&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot; /&gt; &lt;property name=&quot;initialSize&quot; value=&quot;$&#123;jdbc.initialSize&#125;&quot; /&gt; &lt;property name=&quot;minIdle&quot; value=&quot;$&#123;jdbc.minIdle&#125;&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;$&#123;jdbc.maxActive&#125;&quot; /&gt; &lt;property name=&quot;maxWait&quot; value=&quot;$&#123;jdbc.maxWait&#125;&quot; /&gt; &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;$&#123;jdbc.timeBetweenEvictionRunsMillis&#125;&quot; /&gt; &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;$&#123;jdbc.minEvictableIdleTimeMillis&#125;&quot; /&gt; &lt;property name=&quot;validationQuery&quot; value=&quot;$&#123;jdbc.validationQuery&#125;&quot; /&gt; &lt;property name=&quot;testWhileIdle&quot; value=&quot;$&#123;jdbc.testWhileIdle&#125;&quot; /&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;$&#123;jdbc.testOnBorrow&#125;&quot; /&gt; &lt;property name=&quot;testOnReturn&quot; value=&quot;$&#123;jdbc.testOnReturn&#125;&quot; /&gt; &lt;property name=&quot;removeAbandoned&quot; value=&quot;$&#123;jdbc.removeAbandoned&#125;&quot; /&gt; &lt;property name=&quot;removeAbandonedTimeout&quot; value=&quot;$&#123;jdbc.removeAbandonedTimeout&#125;&quot; /&gt; &lt;!-- &lt;property name=&quot;logAbandoned&quot; value=&quot;$&#123;jdbc.logAbandoned&#125;&quot; /&gt; --&gt; &lt;property name=&quot;filters&quot; value=&quot;$&#123;jdbc.filters&#125;&quot; /&gt; &lt;!-- 关闭abanded连接时输出错误日志 --&gt; &lt;property name=&quot;logAbandoned&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;proxyFilters&quot;&gt; &lt;list&gt; &lt;ref bean=&quot;log-filter&quot;/&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 监控数据库 --&gt; &lt;!-- &lt;property name=&quot;filters&quot; value=&quot;stat&quot; /&gt; --&gt; &lt;!-- &lt;property name=&quot;filters&quot; value=&quot;mergeStat&quot; /&gt;--&gt; &lt;/bean&gt; &lt;!-- sqlSessionFactory --&gt; &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;!-- 数据库连接池 --&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt; &lt;property name=&quot;mapperLocations&quot;&gt; &lt;array&gt; &lt;value&gt;classpath:mapper/*.xml&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;com.ssm.pojo&quot;/&gt; &lt;property name=&quot;plugins&quot;&gt; &lt;array&gt; &lt;bean class=&quot;com.github.pagehelper.PageInterceptor&quot;&gt; &lt;!-- 这里的几个配置主要演示如何使用，如果不理解，一定要去掉下面的配置 --&gt; &lt;property name=&quot;properties&quot;&gt; &lt;value&gt; &lt;!-- 分页插件使用哪种方言 --&gt; helperDialect=mysql &lt;!--reasonable=true--&gt; &lt;!--supportMethodsArguments=true--&gt; &lt;!--params=count=countSql--&gt; &lt;!-- 允许在运行时根据多数据源自动识别对应方言的分页 （不支持自动选择sqlserver2012，只能使用sqlserver） --&gt; autoRuntimeDialect=true &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- org.mybatis的方式 --&gt; &lt;!--&lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt;--&gt; &lt;!--&amp;lt;!&amp;ndash; 扫描包路径，如果需要扫描多个包的位置，需要用,分开半月逗号分隔开 &amp;ndash;&amp;gt;--&gt; &lt;!--&lt;property name=&quot;basePackage&quot; value=&quot;com.ssm.mapper&quot;&gt;&lt;/property&gt;--&gt; &lt;!--&amp;lt;!&amp;ndash; 注意这里是value 而不是ref &amp;ndash;&amp;gt;--&gt; &lt;!--&lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;&gt;&lt;/property&gt;--&gt; &lt;!--&lt;/bean&gt;--&gt; &lt;!-- tk.mybatis的方式 --&gt; &lt;bean class=&quot;tk.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.ssm.mapper&quot;/&gt; &lt;!-- 通用Mapper通过属性注入进行配置，默认不配置时会注册Mapper&lt;T&gt;接口 &lt;property name=&quot;properties&quot;&gt; &lt;value&gt; mappers=tk.mybatis.mapper.common.Mapper &lt;/value&gt; &lt;/property&gt; --&gt; &lt;/bean&gt; &lt;!-- mybatis 测试时使用 spring注入 --&gt; &lt;!--&lt;bean id=&quot;sqlSession&quot; class=&quot;org.mybatis.spring.SqlSessionTemplate&quot; scope=&quot;prototype&quot;&gt;--&gt; &lt;!--&lt;constructor-arg index=&quot;0&quot; ref=&quot;sqlSessionFactory&quot;/&gt;--&gt; &lt;!--&lt;/bean&gt;--&gt;&lt;/beans&gt; 此时tk-mybatis已经整入项目中，再使用上分页插件pagehelper 使用例子： UserMapper.java 123public interface UserMapper extends Mapper&lt;User&gt;&#123;&#125; UserServiceImpl.java 12345678910111213141516171819202122232425262728293031@Service(&quot;userService&quot;)//@Transactional(rollbackFor=java.lang.Exception.class) service配置回滚 在配置文件中配置public class UserServiceImpl implements UserService &#123; @Autowired private UserMapper userMapper;public Map&lt;String, Object&gt; queryUserPage(UserVo userVo) throws Exception &#123; Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); List&lt;User&gt; users = null; int total = 0; PageHelper.offsetPage(userVo.getStart(),userVo.getLength()); //使用该方式需要在User配置 //@Table(name = &quot;sys_user&quot;) //@Id Example example = new Example(User.class); example.createCriteria().andLike(&quot;username&quot;,userVo.getUsername()); users = userMapper.selectByExample(example); total = userMapper.selectCountByExample(example); map.put(&quot;recordsFiltered&quot;, total); map.put(&quot;data&quot;, users); map.put(&quot;recordsTotal&quot;, total); return map; &#125; &#125; 整合过程中出现的问题及解决方案 tk.mybatis.mapper.MapperException: java.lang.IllegalStateException: No typehandler found for property menus 报错的位置锁定在 UserMapper.xml 报错的原因是 12345678910111213141516171819202122232425262728293031User.java private String id; private String usercode; private String username; private String password; private String salt; private int locked; //用户菜单 private List&lt;SysPermission&gt; menus = new ArrayList&lt;SysPermission&gt;(); //用户权限 private List&lt;SysPermission&gt; permissions = new ArrayList&lt;SysPermission&gt;(); UserMapper.xml &lt;resultMap type=&quot;com.ssm.pojo.User&quot; id=&quot;userResultMap&quot;&gt; &lt;result column=&quot;id&quot; property=&quot;id&quot;/&gt; &lt;result column=&quot;usercode&quot; property=&quot;usercode&quot;/&gt; &lt;result column=&quot;username&quot; property=&quot;username&quot;/&gt; &lt;result column=&quot;password&quot; property=&quot;password&quot;/&gt; &lt;result column=&quot;salt&quot; property=&quot;salt&quot;/&gt; &lt;result column=&quot;locked&quot; property=&quot;locked&quot;/&gt; &lt;/resultMap&gt; ``` menus 和 permissions的数据都不是从sys_user中获取的，但是UserMapper.xml中&lt;ResultMap&gt; 标签必须写上所有的映射 否则就会报以上的错误，但是配置上 &lt;result column=&quot;menus&quot; property=&quot;menus&quot;/&gt; 还是不行，No typehandler 最终的解决方案 public class SystemUser extends User implements Serializable { //用户菜单 private List&lt;SysPermission&gt; menus = new ArrayList&lt;SysPermission&gt;(); //用户权限 private List&lt;SysPermission&gt; permissions = new ArrayList&lt;SysPermission&gt;(); ```]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>tk-mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web中间件]]></title>
    <url>%2F2017%2F11%2F29%2Fweb%E4%B8%AD%E9%97%B4%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[摘要: web中间件 前言一般本地开发的话建议使用tomcat。linux系统建议使用jetty或apache hpptd大型的项目就用JBOSS或webloigc小项目，或者是个人开发tomcat 大项目或者商业项目一般采用：weblgoic/webshere其他的还有jboss、glasshfish等一些示例项目或者小项目常采用jettytomcat , jboss, weblogic, websphere 一般项目tomcat就可以了Tomcat是Sun的JSWDK(JavaServer Web Development Kit)中Servlet的运行环境(servlet容器)。Tomcat是Apache Jakarta软件组织的一个子项目，Tomcat是一个JSP/Servlet容器，它是在SUN公司的JSWDK（Java Server Web Development Kit）基础上发展起来的一个JSP和Servlet规范的标准实现，使用Tomcat可以体验JSP和Servlet的最新规范。经过多年的发展，Tomcat不仅是JSP和Servlet规范的标准实现，而且具备了很多商业Java Servlet容器的特性，并被一些企业用于商业用途。JBoss是一个运行EJB的J2EE应用服务器。它是开放源代码的项目，遵循最新的J2EE规范。从JBoss项目开始至今，它已经从一个EJB容器发展成为一个基于的J2EE的一个web 操作系统（operating system for web），它体现了J2EE规范中最新的技术WebLogic服务器是企业级的应用服务器，支持EJB, 集群以及 ERP（企业资源计划）的连通性 ，开发公司：BEA。WebSphere产品系列是IBM公司一套典型的电子商务应用开发工具及运行环境 tomcatweblogic]]></content>
      <categories>
        <category>J2EE</category>
      </categories>
      <tags>
        <tag>web中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ztree进阶学习记录]]></title>
    <url>%2F2017%2F11%2F03%2Fztree%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[摘要: ztree进阶学习记录 ztree异步加载 由于ztree的数据量增大，通过直接将所有的ztree的节点都全部加载的方式，就会变得越来越慢的，所以为了解决这个问题。 解决的方案： 每次点击parent节点时才去加载此下的子节点挂于此节点下，点击树节点，table/grid回显示对应的数据，同时得注意： 此parent节点下异步加载的子节点需要判断是否是父节点，否则无法显示是否parent也就是无打开节点的按钮。 由于需要判断是否是父节点，所以需要后台传递值给前端带有isParent(true|false)。 如果没有isParent这个字段也会影响，zTreeObj.addNodes这个方法无法有效果。 同时为了实现增删改节点时，保持原本节点打开状态，而不是重新加载并且完全闭合。 12345678910111213141516171819202122在ztree处开启 isAsync=&quot;true&quot; 开启异步加载&lt;Tree id=&quot;functiontree&quot; layoutHeight=&quot;0&quot; width=&quot;100%&quot; hasRoot=&quot;true&quot; idField=&quot;treeId&quot; rootId=&quot;&quot; isAsync=&quot;true&quot;parentField=&quot;treeParentId&quot; nameField=&quot;treeText&quot; rootName=&quot;应用功能列表&quot; hasQry=&quot;true&quot; fit=&quot;true&quot;searchUrl=&quot;platform/appframe/function/afaappfunction/getAppFunctionTreeByName.do&quot; loadUrl=&quot;platform/appframe/function/afaappfunction/getAppFunctionTree.do&quot;/&gt;//设置树异步加载参数$A(&quot;#functiontree&quot;).setting.async.otherParam = &#123;&quot;isDisableType&quot;:&quot;NO&quot;&#125;; //设置异步加载时自动提交父节点属性的参数$A(&quot;#functiontree&quot;).setting.async.autoParam = [&quot;treeId&quot;]; 对应ztreeAPI： var setting = &#123; ..., async : &#123; autoParam:[], otherParam:[], url:&quot;&quot;, type:&quot;&quot;, dataType:&quot;text&quot; &#125; &#125; update前端提交修改保存完controller后，返回成功的信息，ajax的callback方法中对ztree中修改的节点信息修改 12345678910111213141516171819202122$a.messager.correct(&quot;操作成功&quot;);//当前选中的节点var currentObj = _self.copyObject;//获取ztree所有的节点var nodes = $A(&apos;#functiontree&apos;).getNodes();//获取提交表单的所有数据var data = $A(&quot;#afaappfunctionPage_forms_show&quot;).getSumbitData(); if (nodes.length&gt;0) &#123; currentObj.treeData.funcName = data.data.funcName; currentObj.treeText = currentObj.treeId+&quot; &quot;+currentObj.treeData.funcName; currentObj.treeData.funcType = data.data.funcType; currentObj.treeData.funcUrl = data.data.funcUrl; currentObj.treeData.isMenu = data.data.isMenu; currentObj.treeData.isAuthorize = data.data.isAuthorize; currentObj.treeData.isDisable = data.data.isDisable; currentObj.treeData.funcDesc = data.data.funcDesc; //将对应的ztree的节点进行更新 $A(&apos;#functiontree&apos;).updateNode(currentObj);&#125;``` add前端提交新增保存完controller后，返回对应的新增的节点(json)，ajax的callback方法中对前端的ztree新增显示节点 123456789101112131415161718192021222324252627var flag=false;//获取ztree选中的节点var selectedNode = AfaAppFunctionDlg.getInstance().treeObj.getSelectedNodes()[0];var selectedTreeCode = selectedNode.treeId;// 如果treeId 为空情况下使用treeData.appId 进行获取treeId进行识别if(selectedTreeCode==&quot;&quot;||selectedTreeCode==undefined||selectedTreeCode==null)&#123; selectedTreeCode = selectedNode.treeData.appId; flag=true;&#125;$A(&apos;#afaappfunctionPage_form&apos;).sumbitAllComp(&#123;...//获取ztree所有的节点var treeObj = AfaAppFunctionDlg.getInstance().treeObj;var parentNode = null;if(flag)&#123; //获取节点中有treeId为‘selectedTreeCode’的节点 parentNode = treeObj.getNodeByParam(&quot;treeId&quot;, selectedTreeCode, null);&#125;else&#123; //获取节点中有treeId为‘selectedTreeCode’的节点 parentNode = treeObj.getNodeByParam(&quot;treeId&quot;, selectedTreeCode, null);&#125;parentNode.isLeaf= &quot;0&quot;;parentNode.isParent=true;treeObj.updateNode(parentNode);treeObj.addNodes(parentNode, json); $a.messager.correct(&quot;操作成功&quot;); delete前端提交批量删除保存完controller后，返回操作成功提示，ajax的callback方法中对前端的ztree进行批量删除 1234567891011121314151617181920var treeObj = $A(&quot;#lefttree&quot;);var treeNode = treeObj.getSelectedNodes()[0];var parentNode = treeNode.getParentNode();//rowList 删除节点的数组 for(var attr in rowList)&#123; var menuId = rowList[attr][&quot;menuId&quot;] //获取存在 node.menu和node.treeData.menuId是&apos;menuId&apos;的树节点 var node = treeObj.getNodesByFilter(function(node)&#123;return (node.menu &amp;&amp; node.treeData.menuId == menuId)&#125;,true); //将该节点从树中移除 treeObj.removeNode(node);&#125; treeNode = treeObj.getSelectedNodes()[0]; if(treeNode)&#123; //需要对修改的树节点的父节点进行判断是否存在子节点 treeNode.isParent = treeNode.children.length == 0?false:true; treeObj.updateNode(treeNode);&#125;parentNode.isParent = parentNode.children.length == 0?false:true;treeObj.updateNode(parentNode); move树节点进行移动. 123456前端需要使用的到的代码//被移开的节点treeObj.removeNode(node);//被移动到的节点treeObj.updateNode(parentNode);treeObj.addNodes(parentNode, json);]]></content>
      <categories>
        <category>ztree</category>
      </categories>
      <tags>
        <tag>ztree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dynamic Web Module Cannot Transform]]></title>
    <url>%2F2017%2F11%2F02%2FDynamic%20Web%20Module%20Cannot%20Transform%2F</url>
    <content type="text"><![CDATA[摘要: Dynamic Web Module Cannot Transform 解决方案 web项目出现Dynamic Web Module 无法从2.3转化为2.5的版本。 解决方案： 首先出现问题的原因在于你的==web.xml==： 1234 &lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:web=&quot;http://java.sun.com/xml/ns/javaee&quot;xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot;id=&quot;WebApp_ID&quot; version=&quot;2.5&quot;&gt; 项目还是2.3的，而使用的version=2.5的，项目会报错（大致的意思就是无法转化），可以通过在本地项目中.setting文件中进行手动改变为2.5。（mac正常情况下是查看到.setting文件 可以通过 **shift+command+.**）]]></content>
      <categories>
        <category>J2EE</category>
      </categories>
      <tags>
        <tag>Dynamic Web Module</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven常用命令]]></title>
    <url>%2F2017%2F11%2F02%2Fmaven%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要: maven常用命令 maven常用命令maven install 将项目根据pom.xml（packaging）的类型进行打包，同时清除项目中target之前打包。 场景1： web项目需要引用parent的项目[存在私服中]，欲将web项目应用引用 本地parent的项目[需要从私服下载到本地,然后执行下面的命令]。 把parent项目中所有的引用项目进行打包，便于本地进行修改测试 场景2： 引用的项目来自gitlab上，gitlab所引用的项目已经在gitlab上已经更新的，但是在maven repository中的还未改变。 解决方案：可以通过将gitlab上的项目下载下来，然后进行install 生成新的jar包或者其他的包。 12345其中用到的操作：git initgit clone gitLab地址cd 对应的项目（项目的上下文）中mvn clean install 生成最新的jar包或其他包 123456//相当于 maven clean install//不想用mvn clean又想保证jar包最新mvn install -Djar.forceCreationmaven clean install//maven的debugg信息非常完备，需要查看debug信息只要在命令后面添加 -X 参数即可mvn clean install -X maven package 将项目快速进行打包pom.xml（packaging）的类型进行打包,同时清除项目中target之前打包。 场景：将parent中的某个模块修改代码完，打包发给他人临时(为了临时测试使用) 12mvn clean packagemvn package -Djar.forceCreation //上面maven install提到过 mvn dependency:tree 使用mvn查看项目jar之间的依赖关系 123cd appframe mvn dependency:tree --&gt; tree.txttree.txt 文件在当前目录下 显示]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BS任务调度学习记录]]></title>
    <url>%2F2017%2F11%2F02%2FBS%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[摘要: BS任务调度quartz学习记录]]></content>
      <categories>
        <category>quartz</category>
      </categories>
      <tags>
        <tag>任务调度quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用spring-annotation]]></title>
    <url>%2F2017%2F10%2F29%2F%E4%BD%BF%E7%94%A8spring-annotation%2F</url>
    <content type="text"><![CDATA[摘要: 使用及扫描spring-annotation 自定义spring-annotation使用和扫描@Target注解：用于描述注解的使用范围，超出范围时编译失败。 取值类型（ElementType）： 1.CONSTRUCTOR:用于描述构造器 2.FIELD:用于描述域（成员变量） 3.LOCAL_VARIABLE:用于描述局部变量 4.METHOD:用于描述方法 5.PACKAGE:用于描述包 6.PARAMETER:用于描述参数 7.TYPE:用于描述类、接口(包括注解类型) 或enum声明 @Retention：描述注解的生命周期，即注解的生效范围。 取值范围（RetentionPolicy）： 1.SOURCE：在源文件中生效，仅存在java文件中，class文件将会去除注解。 2.CLASS：在class文件中生效，仅保留在class文件中，运行时无法获取注解。 3.RUNTIME:在运行时生效，保留在class文件中且运行时可通过反射机制获取。 @Documented：用于指定javac生成API时显示该注解信息。 @Inherited：标明该注解可以由子类继承，及子类可以继承父类的注解。而默认情况下，子类是不继承父类注解的。 自定义spring-annotation JobHander.java 123456789101112131415161718import java.lang.annotation.ElementType;import java.lang.annotation.Inherited;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;//用于描述类、接口(包括注解类型) 或enum声明@Target(&#123;ElementType.TYPE&#125;)//在运行时生效，保留在class文件中且运行时可通过反射机制获取。@Retention(RetentionPolicy.RUNTIME)//标明该注解可以由子类继承，及子类可以继承父类的注解。而默认情况下，子类是不继承父类注解的。@Inheritedpublic @interface JobHander &#123; String name() default &quot;&quot;; String value() default &quot;&quot;; &#125; 自定义抽象类 JobHandler.java 12345678910111213import com.bosssoft.platform.job.core.biz.model.JobResult;public abstract class JobHandler &#123; /** * job handler * @param params * @return * @throws Exception */ public abstract JobResult&lt;String&gt; execute(String... params) throws Exception; &#125; MyDemoJobHandler.java 继承==JobHandler==并且使用==JobHander==注解 12345678910111213141516171819202122232425import java.util.concurrent.TimeUnit;import org.springframework.stereotype.Service;import com.bosssoft.platform.job.core.biz.model.JobResult;import com.bosssoft.platform.job.core.handler.JobHandler;import com.bosssoft.platform.job.core.handler.annotation.JobHander;import com.bosssoft.platform.job.core.log.JobLogger;@JobHander(name=&quot;我的测试执行器任务&quot;,value=&quot;myDemoJobHandler&quot;)@Servicepublic class MyDemoJobHandler extends JobHandler&#123; @Override public JobResult&lt;String&gt; execute(String... arg0) throws Exception &#123; JobLogger.log(&quot;myJob, test.&quot;); for (int i = 5; i &lt; 10; i++) &#123; JobLogger.log(&quot;beat at:&quot; + i); TimeUnit.SECONDS.sleep(2); &#125; return JobResult.SUCCESS; &#125;&#125; 通过spring的applicationContext方法getBeansWithAnnotation获取使用了JobHander注解的类(定义的name、value、class) 部分源码： 12345678910111213141516171819202122232425262728293031// Class&lt;? extends Annotation&gt; 表示为 annotationType 为 继承Annotation的类public Map&lt;String, Object&gt; getBeansWithAnnotation(Class&lt;? extends Annotation&gt; annotationType) &#123; Map&lt;String, Object&gt; results = new LinkedHashMap&lt;String, Object&gt;(); for (String beanName : getBeanDefinitionNames()) &#123; BeanDefinition beanDefinition = getBeanDefinition(beanName); if (!beanDefinition.isAbstract() &amp;&amp; findAnnotationOnBean(beanName, annotationType) != null) &#123; results.put(beanName, getBean(beanName)); &#125; &#125; for (String beanName : getSingletonNames()) &#123; if (!results.containsKey(beanName) &amp;&amp; findAnnotationOnBean(beanName, annotationType) != null) &#123; results.put(beanName, getBean(beanName)); &#125; &#125; return results; &#125; final Map&lt;Class&lt;? extends Annotation&gt;, Annotation&gt; annotations;public &lt;A extends Annotation&gt; A getAnnotation(Class&lt;A&gt; annotationClass) &#123; Objects.requireNonNull(annotationClass); //通过类得到对应的annotation注解 return (A) annotationData().annotations.get(annotationClass);&#125;public static &lt;T&gt; T requireNonNull(T obj) &#123; if (obj == null) throw new NullPointerException(); return obj;&#125; 123456789101112131415161718192021222324252627282930313233public class QueryAllHandler implements ApplicationContextAware &#123; private static ApplicationContext applicationContext = null; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; // init job handler action Map&lt;String, Object&gt; serviceBeanMap = this.applicationContext.getBeansWithAnnotation(JobHander.class); System.out.println(&quot;&lt;--------------------start--------------------&gt;&quot;); if (serviceBeanMap!=null &amp;&amp; serviceBeanMap.size()&gt;0) &#123; for (Object serviceBean : serviceBeanMap.values()) &#123; if (serviceBean instanceof JobHandler)&#123; String value = serviceBean.getClass().getAnnotation(JobHander.class).value(); String name = serviceBean.getClass().getAnnotation(JobHander.class).name(); JobHandler handler = (JobHandler) serviceBean; System.out.println(handler); System.out.println(name); System.out.println(value); list.add(name); &#125; &#125; &#125; System.out.println(&quot;&lt;--------------------end--------------------&gt;&quot;); System.out.println(list.toArray().toString()); &#125;&#125; 最后需要注意的地方： spring需要扫描到才可以得到该类 &lt;context:component-scan base-package=&quot;com.ssm.spring.*&quot; /&gt; 实际开发需要考虑的问题 实现方式通过以上方式，但是在实际项目中，不可能使用一次application就实现一次 ==ApplicationContextAware==，所以在项目中已经有实现了ApplicationContextAware的 类(RuntimeApplicationContext.java)。 平台已经存在了一个RuntimeApplicationContext.java，其他项目小组使用平台时， 有可能习惯使用直接小组封装的实现ApplicationContextAware的类(xxxxxxApplicationContext.java)， 这时就需要实现考虑 可动态调用已实现ApplicationContextAware的工具类SpringContextUtil.java， 实现的方式就是通过在xxx.properties 配置已经实现的ApplicationContextAware类的完全路径， 然后通过反射机制使用动态调用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144import java.util.Map;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.BeansException;import org.springframework.beans.factory.config.ConfigurableListableBeanFactory;import org.springframework.beans.factory.support.BeanDefinitionRegistry;import org.springframework.beans.factory.support.BeanDefinitionRegistryPostProcessor;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;public class RuntimeApplicationContext implements BeanDefinitionRegistryPostProcessor, ApplicationContextAware &#123; /** * logger */ private static Logger logger = LoggerFactory.getLogger(RuntimeApplicationContext.class); /** * 系统中的context对象 */ private static ApplicationContext context = null; /** * * 获取Spring上下文ApplicationContext对象 * * @return ApplicationContext对象 */ public static ApplicationContext getContext() &#123; if (context == null) &#123; logger.error(&quot;当前context为空,可能是Spring配置文件中没有配置加载本类[&#123;&#125;]!&quot;, RuntimeApplicationContext.class.getName()); throw new IllegalStateException(&quot;当前没有Spring的applicationContext注入,请确定是否有配置Spring,并在Spring中配置了本类的注入!&quot; + RuntimeApplicationContext.class); &#125; return context; &#125; /** * 取指定类型的Bean,如果不存在或存在多于1个,则抛出异常IllegalStateException. * * @param &lt;E&gt; E * @param type type * @return 指定类型的Bean */ @SuppressWarnings(&quot;unchecked&quot;) public static &lt;E&gt; E getBeanByType(Class&lt;? extends E&gt; type) &#123; try &#123; String[] beanNames = getContext().getBeanNamesForType(type); if (beanNames != null &amp;&amp; beanNames.length == 1) &#123; return (E) getContext().getBean(beanNames[0]); &#125; if (beanNames == null || beanNames.length == 0) &#123; throw new IllegalStateException(&quot;未找到指定类型的Bean定义.&quot;); &#125; throw new IllegalStateException(&quot;找到多个同类型的Bean定义.&quot;); &#125; catch (Exception e) &#123; logger.error(&quot;根据类型在Spring上下文查找对象出错:&quot; + type, e); throw new IllegalStateException(&quot;根据类型在Spring上下文查找对象出错:&quot; + type, e); &#125; &#125; /** * * 从Spring Context中获取指定的Bean * * @param &lt;E&gt; E * @param beanName bean的名称 * @return bean对象 */ @SuppressWarnings(&quot;unchecked&quot;) public static &lt;E&gt; E getBean(String beanName) &#123; try &#123; return (E) getContext().getBean(beanName); &#125; catch (Exception e) &#123; // logger.error(&quot;在Spring上下文查找对象出错:&quot; + beanName, th); throw new IllegalStateException(&quot;在Spring上下文查找对象出错:&quot; + beanName); &#125; &#125; public static Map&lt;String,Object&gt; getBeansWithAnnotation(Class annotationClass)&#123; return getContext().getBeansWithAnnotation(annotationClass); &#125; public static &lt;T&gt; Map&lt;String, T&gt; getBeansOfType(Class&lt;T&gt; type) &#123; return getContext().getBeansOfType(type); &#125; /** * 从Spring Context中获取指定的Bean * * @param &lt;E&gt; E * @param clazz clazz * @return 指定的Bean */ public static &lt;E&gt; E getBean(Class&lt;E&gt; clazz) &#123; return getBeanByType(clazz); // return getBean(clazz.getName()); &#125; /** * * 是否有指定的Bean存在. * * @param beanName beanName * @return 是否有指定的Bean存在. */ public static boolean containBean(String beanName) &#123; return getContext().containsBean(beanName); &#125; /** * * 用于在被Spring加载时，由Spring注入ApplicationContext对象 * * @param context 被注入的context对象 * @throws BeansException */ public void setApplicationContext(ApplicationContext context) throws BeansException &#123; logger.debug(&quot;Prepare injection spring applicationcontext[&#123;&#125;]&quot;, context.toString()); if (RuntimeApplicationContext.context != null) &#123; logger.warn(&quot;注意,已经注入过Spring上下文[&#123;&#125;],请检查配置是否有问题导致重复注入!&quot;, RuntimeApplicationContext.context.toString()); &#125; RuntimeApplicationContext.context = context; &#125; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; // TODO Auto-generated method stub &#125; @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; // TODO Auto-generated method stub &#125;&#125; SpringContextUtil.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class SpringContextUtil &#123; private static Logger logger=LoggerFactory.getLogger(SpringContextUtil.class); private static final String KEY_SPRING_APPLICATION_CONTEXT_AWARE_CLASS=&quot;spring.applicationcontextaware.class&quot;; private static Class getSpringApplicationContextAwareClass()throws Exception&#123; String className= PropertiesUtil.getProperty(KEY_SPRING_APPLICATION_CONTEXT_AWARE_CLASS, &quot;com.xxxx.xxxx.runtime.spring.RuntimeApplicationContext&quot;); return ClassUtils.forName(className, Thread.currentThread().getContextClassLoader()); &#125; /** * 获取Spring Bean * @param beanName bean名称 * @return */ public static &lt;E&gt; E getBean(String beanName)&#123; try&#123; Class applicationContextAwareClass=getSpringApplicationContextAwareClass(); Object result=MethodUtils.invokeStaticMethod(applicationContextAwareClass,&quot;getBean&quot;, new Object[]&#123;beanName&#125;); return (E)result; &#125;catch(Exception e)&#123; logger.error(&quot;Error get spring applicationContext bean &#123;&#125;&quot;,beanName,e); throw new RuntimeException(e); &#125; &#125; public static &lt;E&gt; E getBeanByType(Class&lt;? extends E&gt; type) &#123; try&#123; Class applicationContextAwareClass=getSpringApplicationContextAwareClass(); Object result=MethodUtils.invokeStaticMethod(applicationContextAwareClass,&quot;getBeanByType&quot;, new Object[]&#123;type&#125;); return (E)result; &#125;catch(Exception e)&#123; logger.error(&quot;Error get spring applicationContext bean of type &#123;&#125;&quot;,type.getClass(),e); throw new RuntimeException(e); &#125; &#125; public static &lt;T&gt; Map&lt;String, T&gt; getBeansOfType(Class&lt;T&gt; type)&#123; try&#123; Class applicationContextAwareClass=getSpringApplicationContextAwareClass(); Object result=MethodUtils.invokeStaticMethod(applicationContextAwareClass,&quot;getBeansOfType&quot;, new Object[]&#123;type&#125;); return (Map&lt;String, T&gt;)result; &#125;catch(Exception e)&#123; logger.error(&quot;Error get spring applicationContext bean of type &#123;&#125;&quot;,type.getClass(),e); throw new RuntimeException(e); &#125; &#125; /** * 根据注解获取Bean * @param type * @return */ public static Map&lt;String,Object&gt; getBeansWithAnnotation(Class type)&#123; try&#123; Class applicationContextAwareClass=getSpringApplicationContextAwareClass(); Object result=MethodUtils.invokeStaticMethod(applicationContextAwareClass,&quot;getBeansWithAnnotation&quot;, new Object[]&#123;type&#125;); return (Map&lt;String, Object&gt;)result; &#125;catch(Exception e)&#123; logger.error(&quot;Error get spring applicationContext bean with annotation &#123;&#125;&quot;,type.getClass(),e); throw new RuntimeException(e); &#125; &#125;&#125;]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring-annotation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令]]></title>
    <url>%2F2017%2F10%2F29%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要: Linux常用命令 1234567891011121314151617181920//查看java进程 不存在则表示未启动ps -ef | grep javaps -ef | grep redisps -ef | grep zookeeperps -ef | grep weblogic//杀死对应需要的线程kill -9 weblogic的pid//启动weblogic切换界面不关闭，不中断开启nohup ./startWebLogic.sh &gt;test101802.log 2&gt;&amp;1//查看对应的logtail -f test101802.log//查找 xxx.lok的文件find . -name &quot;*.lok&quot;# find . -a */.lok find: 路径必须在表达式之前: */.lok 用法: find [-H] [-L] [-P] [-Olevel] [-D help|tree|search|stat|rates|opt|exec] [path...] [expression]]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shiro学习记录]]></title>
    <url>%2F2017%2F10%2F29%2Fshiro%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[摘要: ssm+shiro+ehcache 遇到的问题问题一(NoClassDefFoundError) caused by: java.lang.NoClassDefFoundError: org/aspectj/weaver/reflect/ReflectionWorld$ReflectionWorldException 解决方案 缺少aspectjweaver.jar 12345&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.7.1&lt;/version&gt;&lt;/dependency&gt; 问题二(java包下无法更新编译.xml文件) IDEA src下的目录除了==.java==其他文件无法==更新编译加载== 解决方案 在pom.xml文件中配置 12345678910111213141516171819202122232425262728293031323334&lt;build&gt; &lt;finalName&gt;demo&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.6&lt;/source&gt; &lt;target&gt;1.6&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;!-- resources 编译执行包含以下类型文件 --&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.ini&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;!-- java 编译执行包含以下类型文件 --&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; 问题三(shiro一直处于登录页面,无法跳转到succeeURL) shiro一直处于登录页面,无法跳转到succeeURL,错误情况下可以进入到FormAuthenticationFilter 该文件中，但是正确情况下就无法进入，controller也接受不到错误信息。 提交Form表单给 (“/login”) methond必须是==POST== 不可以使用==GET==，否则就会出现上面的情况,可以查看下源码看到该情况。 shiro使用到 WebUtils 工具保存session 问题四(shiro实现了AuthorizingRealm，认证成功，无法授权) 错误的理解 拦截和授权为一回事。拦截是判断是是否登陆 授权是判断你是否有权限操作。在 filterChainDefinitions 配置(==/** = authc== 作用：所有url都必须认证通过才可以访问) 想要配置授权拦截应该配置(==/user/userList.do = perms[“user:query”]==) 或者使用注解 ==@RequiresPermissions(“user:query”)== applicationContext-shiro.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; &lt;property name=&quot;securityManager&quot; ref=&quot;securityManager&quot; /&gt; &lt;!-- loginUrl认证提交地址，如果没有认证将会请求此地址进行认证，请求此地址将由formAuthenticationFilter进行表单认证 --&gt; &lt;property name=&quot;loginUrl&quot; value=&quot;/login.do&quot; /&gt; &lt;!-- 认证成功统一跳转到first.action，建议不配置，shiro认证成功自动到上一个请求路径 --&gt; &lt;!--&lt;property name=&quot;successUrl&quot; value=&quot;/main.do&quot;/&gt;--&gt; &lt;!-- 通过unauthorizedUrl指定没有权限操作时跳转页面--&gt; &lt;property name=&quot;unauthorizedUrl&quot; value=&quot;/refuse.jsp&quot; /&gt; &lt;!-- 自定义filter配置 --&gt; &lt;property name=&quot;filters&quot;&gt; &lt;map&gt; &lt;!-- 将自定义 的FormAuthenticationFilter注入shiroFilter中--&gt; &lt;entry key=&quot;authc&quot; value-ref=&quot;formAuthenticationFilter&quot; /&gt; &lt;/map&gt; &lt;/property&gt; &lt;!-- 指定URL拦截规则 --&gt; &lt;!-- 过虑器链定义，从上向下顺序执行，一般将/**放在最下边 --&gt; &lt;property name=&quot;filterChainDefinitions&quot;&gt; &lt;!--authc:代表shiro框架提供的一个过滤器，这个过滤器用于判断当前用户是否已经完成认证， 如果当前用户已经认证，就放行，如果当前用户没有认证，跳转到登录页面 anon:代表shiro框架提供的一个过滤器，允许匿名访问--&gt; &lt;value&gt; &lt;!-- 对静态资源设置匿名访问 --&gt; /resouces/images/** = anon /resouces/js/** = anon /resouces/css/** = anon /resouces/bootstrap3/** = anon &lt;!-- 验证码，可匿名访问 --&gt; /authCode.do = anon &lt;!-- 请求 logout.action地址，shiro去清除session--&gt; /logout.do = logout &lt;!--商品查询需要商品查询权限 ，取消url拦截配置，使用注解授权方式 --&gt; &lt;!-- /items/queryItems.action = perms[item:query] /items/editItems.action = perms[item:edit] --&gt; &lt;!-- 配置记住我或认证通过可以访问的地址 --&gt; &lt;!--/main.do = user--&gt; /welcome.jsp = user &lt;!-- 使用配置方式实现授权操作 --&gt; &lt;!--/user/userList.do = perms[&quot;user:query&quot;]--&gt; &lt;!-- /** = authc 所有url都必须认证通过才可以访问--&gt; /** = authc &lt;!-- /** = anon所有url都可以匿名访问 --&gt; &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; UserController.java 12345678910@Controller@RequestMapping(&quot;/user&quot;)public class UserController &#123; @Autowired private UserService userService; @RequiresPermissions(&quot;user:query&quot;) @RequestMapping(&quot;/userList&quot;)]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>shiro学习记录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebService到今天流行的RESTful API(JSON) over HTTP]]></title>
    <url>%2F2017%2F10%2F29%2FWebService%E5%88%B0RESTful%20API(JSON)%20over%20HTTP%2F</url>
    <content type="text"><![CDATA[摘要: WebService到今天流行的RESTful API(JSON) over HTTP WebService有很多协议，为什么HTTP比较流行？WebService是个很重型的规范，它的应用协议是SOAP（简单对象访问协议），它所依赖的下层通信方式不单单是HTTP，也有SOAP over SMTP, SOAP over TCP，由于HTTP协议群众基础广，开发调试方便，所以，成了WebService中最为流行的方式。 甚至很多公司在内网通信，也用HTTP来做，比如，应用调用搜索引擎，Solr就是一个例子。 但HTTP也是TCP上性能比较差的协议，因为HTTP是基于TCP的，有3次握手，再加上HTTP是个文本传输协议（虽然也可以传二进制的附件，但业务逻辑还是文本用的多），又有很多复杂的HEADER。所以人们发明了一些更高效的通信协议来做远程调用，比如ACE、ICE、Corba、淘宝的HSF，但这是后话了，不展开细说。你只要知道，HTTP之所以流行，乃是简单易用群众基础广的结果。 WebService为什么不如RESTful API流行WebService诞生十几年了，最初是IBM、微软比较热心在推，一直也不温不火。倒是XML-RPC, RESTful以及比RESTful还要简陋的远程调用方式后来居上。感觉是不是有点像民间的Spring干掉官方的EJB？ 究其原因，还是WebService实在太笨重了，SOAP信封犹如婆娘的裹脚布，又臭又长，广大开发人员是叔可忍嫂不能忍，于是就有了简化版的，叫XML-RPC，后来伴随着Web2.0流行，RESTful独领风骚。我在10年前做过一个产品，纯PHP+JS，标准的WebService，连WSDL我都要专门写个PHP程序来生成，还好只是我一个人开发，要是团队协作，我早就被骂得不成人形了。 再后来，连RESTful都被嫌弃了，大伙儿干脆连PUT、DELETE都懒得用，直接用GET和POST。 同时，我得说，这只是在互联网领域，大部分企业的业务逻辑相对简单，同时工期又变态的短（就像大部分互联网创业公司用糙快猛的PHP，而不用相对严谨的Java一样）。在某些业务复杂，稳定性和正确性要求高的领域（如ERP、电商、支付），WebService还有是用武之地的。 为什么JSON比XML流行还是易用性，JSON的可读性比XML强几条长安街，解析规则也简单许多。XML解析的时候规则太多了，动不动就非法字符，动不动就抛异常。这对追求高开发速度和低开发门槛的企业来说，是个致命伤。 JSON的缺点是数据类型支持较少，且不精确。比方说： 1price:12580 在json里，你无法知道这个价格是int, float还是double。 所以，如上面第二条所述，在一些业务要求较高的领域，还是XML更合适。 最后说一下性能，JSON的性能高于XML，除此之外，基于XML和HTTP的WebService, 基于JSON的RESTful API，并没有性能差异。 XML性能糟糕到什么地步呢，有一种专门的CPU叫做XML Accelerator，专门为XML解析提供硬件加速。]]></content>
      <categories>
        <category>J2EE</category>
      </categories>
      <tags>
        <tag>WebService与RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Javascript开发学习记录]]></title>
    <url>%2F2017%2F10%2F14%2FJavascript%E5%BC%80%E5%8F%91%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[摘要: Javascript开发学习记录 找个时间整理]]></content>
      <categories>
        <category>Javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BS前端页面汇总]]></title>
    <url>%2F2017%2F09%2F28%2FBS%E5%89%8D%E7%AB%AF%E9%A1%B5%E9%9D%A2%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[摘要: BS前端页面汇总 前端部分（XML、JS）前端使用到GS的框架： xml标签：Page、items、Panel、Tree、XGrid…JS使用到的是requireJS：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556//define([&apos;引入外部js模块或控件&apos;],function(&apos;引入外部js或控件的别名&apos;)&#123;&#125;)define([&quot;app/widgets/window/app-dialog&quot;,&quot;目录&quot;,&quot;目录&quot;],function(Dialog,PageBase,dlg)&#123; var xxxModel = PageBase.extend(&#123; //类初始化 initialize : function()&#123; xxxModel.superclass.initialize.call(this); &#125;, //控件监听事件 格式：#控件id#:&#123;事件名:事件方法&#125; listeners:&#123; &#125;, //页面初始化 initPage:function()&#123; &#125;, //显示查看业 showViewPage:function(data,e)&#123; var _self=this; dlg.showPage(dlg.ACTION.VIEW,data,function()&#123; _self.refreshData(); &#125;); &#125;, refreshData:function()&#123; $(&quot;#receiptMaintenancePage_grid&quot;).grid(&quot;reload&quot;); &#125;, //显示编辑业 showEditPage:function(data,e)&#123; var _self=this; dlg.showPage(dlg.ACTION.EDIT,data,function()&#123; //_self.refreshData(); $(&quot;#receiptMaintenancePage_grid&quot;).grid(&quot;reload&quot;); &#125;); &#125;, //控件属性重置 initUIExtConfig : function() &#123; var _self=this; this.uiExtConfig=&#123; //格式 #控件id#:function(控件属性集类)&#123; config.setAttr(&quot;控件属性名&quot;,&quot;属性值&quot;),// 网格，下拉网格，特殊设置config.getColumn(&quot;网列id&quot;).setAttr(&quot;列属性名&quot;,&quot;列属性值&quot;)config.getButton(&quot;网格内包含的按钮id&quot;).setAttr(&quot;handler&quot;,&quot;点击事件&quot;) &#125; receiptMaintenancePage_grid:function(config)&#123; config.getButton(&quot;receiptMaintenancePage_grid_btnEdit&quot;).setAttr(&quot;handler&quot;,_self.showEditPage); config.getButton(&quot;receiptMaintenancePage_grid_btnView&quot;).setAttr(&quot;handler&quot;,_self.showViewPage); config.getButton(&quot;receiptMaintenancePage_grid_btnDel&quot;).setAttr(&quot;handler&quot;,_self.doDeleteData); &#125; &#125; &#125; &#125;); xxxModel.getInstance=function()&#123; if (!this.instance)&#123; this.instance =new xxxModel(); &#125; return this.instance; &#125; return xxxModel.getInstance();&#125;); XML经常使用到的方式树123456&lt;Tree id=&quot;receiptLeftTree&quot; layoutHeight=&quot;0&quot; width=&quot;100%&quot; hasRoot=&quot;true&quot; rootId=&quot;&quot; rootName=&quot;机构列表&quot; idField=&quot;treeId&quot; isAsync=&quot;true&quot; nameField=&quot;treeText&quot; parentField=&quot;treeParentId&quot; hasQry=&quot;true&quot; searchUrl=&quot;platform/appframe/afauser/searcherAfaUserTree.do&quot; searchFields=&quot;orgName&quot; loadUrl=&quot;platform/appframe/afauser/queryAfaUserTree.do&quot;&gt;&lt;/Tree&gt; 查询功能12345678910111213141516171819&lt;Query id=&quot;receiptMaintenancePage_query&quot; queryTarget=&quot;receiptMaintenancePage_grid&quot; isAdvance=&quot;true&quot; style=&quot;display:none;&quot; manual=&quot;false&quot; advColCount=&quot;2&quot;&gt; &lt;quicks&gt; &lt;QueryItem id=&quot;ticketedPointCode&quot; name=&quot;开票点&quot; tips=&quot;输入开票点编码查询&quot; field=&quot;TICKETED_POINT_CODE&quot; operator=&quot;like&quot; editorType=&quot;TEXTBOX&quot; /&gt; &lt;QueryItem id=&quot;startTime&quot; name=&quot;编制日期&quot; field=&quot;CREATE_TIME&quot; tips=&quot;输入编制日期查询&quot; operator=&quot;&gt;=&quot; editorType=&quot;DATETIME&quot; /&gt; &lt;QueryItem id=&quot;endTime&quot; name=&quot;至&quot; field=&quot;CREATE_TIME&quot; tips=&quot;输入编制日期查询&quot; operator=&quot;&amp;lt;=&quot; editorType=&quot;DATETIME&quot; /&gt; &lt;QueryItem id=&quot;gaoji&quot; name=&quot;高级&quot; value=&quot;1&quot; visible=&quot;false&quot; operator=&quot;=&quot; editorType=&quot;TEXTBOX&quot; /&gt; &lt;/quicks&gt; //高级查询 &lt;advances&gt; &lt;QueryItem id=&quot;ticketedPointCode&quot; name=&quot;开票点编码&quot; editorType=&quot;TEXTBOX&quot; /&gt; &lt;QueryItem id=&quot;createTime&quot; name=&quot;创建日期&quot; editorType=&quot;DATETIME&quot; /&gt; &lt;/advances&gt;&lt;/Query&gt; 标签页123456789101112131415161718192021&lt;Panel id=&quot;id必填&quot; region=&quot;定义布局面板的位置&quot;&gt; &lt;items&gt; &lt;Tabs id=&quot;receiptMaintenance_panel_right_bottom_tabs&quot;&gt; &lt;items&gt; &lt;TabPanel id=&quot;panel_south_tabs_projects_info&quot; name=&quot;项目&quot; layout=&quot;border&quot; style=&quot;height: 240px;&quot;&gt; &lt;items&gt; 内容可以是 XGrid或者Form &lt;/items&gt; &lt;/TabPanel&gt; &lt;TabPanel id=&quot;panel_south_tabs_user_info&quot; name=&quot;项目&quot; layout=&quot;border&quot; style=&quot;height: 240px;&quot;&gt; &lt;items&gt; 内容可以是 XGrid或者Form &lt;/items&gt; &lt;/TabPanel&gt; &lt;/items&gt; &lt;/Tabs&gt; &lt;/items&gt;&lt;/Panel&gt; XGridColumn实现下拉并且将row自动填写( XML 和 JS(在listeners中) )**1. XML: 12345678&lt;XGridColumn field=&quot;projectStandard&quot; title=&quot;项目标准&quot; editorType=&quot;COMBOBOX&quot; align=&quot;center&quot; editorOptions=&quot;&#123; textfield: &apos;projectStandard&apos;, valuefield: &apos;projectCode&apos;, url: &apos;platform/appframe/receipt/maintenance/receiptmaintenance/queryProjectList.do&apos; &#125;&quot; /&gt; 2. JS: 12345678910111213141516171819projects_grid_editable : &#123; onClickCell : function(rowData, rowIndex, field) &#123; var self = ReceiptMaintenanceDlg.getInstance(); if(field == &quot;projectStandard&quot;)&#123; var edProjectStandard = $(&apos;#projects_grid_editable&apos;).grid(&apos;getEditor&apos;, field); var edProjectCode = $(&apos;#projects_grid_editable&apos;).grid(&apos;getEditor&apos;, &quot;projectCode&quot;); $(edProjectStandard).combobox(&apos;reload&apos;,&apos;platform/appframe/receipt/maintenance/receiptmaintenance/queryProjectList.do?whichData=project&apos;); $(edProjectStandard).bind(&apos;change&apos;,function()&#123; var projectId = $(edProjectStandard).combobox(&quot;getValue&quot;); var projectStandard= $(edProjectStandard).combobox(&quot;getText&quot;); var rowIndex = $(&apos;#projects_grid_editable&apos;).grid(&apos;getCurrentEditRowIndex&apos;); var rowData = $(&apos;#projects_grid_editable&apos;).grid(&apos;getCurrentEditRowData&apos;); $(&apos;#projects_grid_editable&apos;).grid(&apos;getEditor&apos;, &quot;projectCode&quot;).textbox(&apos;setValue&apos;,projectId); $(&apos;#projects_grid_editable&apos;).grid(&apos;getEditor&apos;, &quot;projectCode&quot;).textbox(&apos;disable&apos;);// $(&apos;#projects_grid_editable&apos;).grid(&apos;saveRow&apos;, &#123;rowIndex : rowIndex, rowData:&#123;&apos;projectCode&apos;:projectId&#125;, command:&apos;update&apos;&#125;); &#125;); &#125; &#125;&#125; 将主表的数据和副表的数据一起发送给后台(增删改)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556doSave : function(config, callback) &#123; var gridData = $(&quot;#projects_grid_editable&quot;).grid(&apos;getAllData&apos;); var params = $A(&apos;#receiptMaintenancePage_form&apos;).getSumbitData(); var obj = new Object(); obj.gridData = gridData; obj.mainData = params.data; obj.type = &quot;modify&quot;; var myURL = &quot;platform/appframe/receipt/maintenance/receiptmaintenance/doInsertProject.do&quot;; $app.ajax.ajaxCall(&#123; url : myURL, data : obj, contentType:&apos;application/json&apos;, dataType: &apos;json&apos;, type: &apos;POST&apos;, callback : function(json) &#123; if (config.isSaveAdd) &#123; $A(&quot;#receiptMaintenancePage_form&quot;) .clearFormEditorValue(); _self.indexAction = _self.ACTION.ADD; &#125; else if (config.isSaveClose) &#123; $.closeDialog(); _self.indexAction = &quot;&quot;; &#125; else if (config.isSaveView) &#123; $A(&quot;#receiptMaintenancePage_form&quot;) .toggleFormState(&quot;view&quot;); $A(&quot;#id&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#ticketedPointCode&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#ticketedPointName&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#ticketedPointType&quot;).combobox(&quot;readonly&quot;, true); $A(&quot;#simpleCode&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#dataAcquisitionCycle&quot;).textbox(&quot;readonly&quot;, true);// $A(&quot;#createTime&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#sysAppMode&quot;).combobox(&quot;readonly&quot;, true); $A(&quot;#contacts&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#contactsInfo&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#superOrg&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#isOnline&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#remark&quot;).textbox(&quot;readonly&quot;, true); // $A(&quot;#sysAppMode&quot;).combobox(&quot;readonly&quot;, true); // $A(&quot;#sysAppModeRadioBox&quot;).radiobox(&quot;readonly&quot;, false);// $A(&quot;#emergencyTicketed&quot;).radiobox(&quot;readonly&quot;, false);// $A(&quot;#emergencyDays&quot;).textbox(&quot;readonly&quot;, false); _self.indexAction = _self.ACTION.VIEW; &#125; if (_self.showPageCallBack) &#123; _self.showPageCallBack(); &#125; &#125; &#125;);&#125; 从表的操作1234567891011121314151617181920initUIExtConfig : function() &#123; var _self = this; this.uiExtConfig = &#123; // 格式 #控件id#:function(控件属性集类)&#123; config.setAttr(&quot;控件属性名&quot;,&quot;属性值&quot;),// // 网格，下拉网格，特殊设置config.getColumn(&quot;网列id&quot;).setAttr(&quot;列属性名&quot;,&quot;列属性值&quot;)config.getButton(&quot;网格内包含的按钮id&quot;).setAttr(&quot;handler&quot;,&quot;点击事件&quot;) // &#125; projects_grid_editable:function(config)&#123; config.getButton(&quot;projects_grid_addBtn&quot;).setAttr(&quot;handler&quot;, _self.appendPGridRow); config.getButton(&quot;projects_grid_deleteBtn&quot;).setAttr(&quot;handler&quot;, _self.deletePGridRow); &#125;, receipts_grid_editable:function(config)&#123; config.getButton(&quot;receipts_grid_addBtn&quot;).setAttr(&quot;handler&quot;, _self.appendRGridRow); config.getButton(&quot;receipts_grid_deleteBtn&quot;).setAttr(&quot;handler&quot;, _self.deleteRGridRow); &#125;, users_grid_editable:function(config)&#123; config.getButton(&quot;users_grid_addBtn&quot;).setAttr(&quot;handler&quot;, _self.appendUGridRow); config.getButton(&quot;users_grid_deleteBtn&quot;).setAttr(&quot;handler&quot;, _self.deleteUGridRow); &#125; &#125;&#125; 前后台请求其中BS使用到的ajax自带的方式123456789101112131415161718192021222324252627前端JS：$app.ajax.ajaxCall(&#123; url : url, data : jsonData, callback : function(data) &#123; $(&quot;#receiptMaintenancePage_grid&quot;).grid(&quot;reload&quot;); &#125;&#125;);后台controller:public AajaxResult queryProect(@requestBody 对象 对象名)&#123;&#125;需要注意的是：Json格式：&#123; mainData:&#123;id:&apos;&apos;,name:&apos;&apos;&#125;, gridData:[&#123;gId:&apos;&apos;,gName:&apos;&apos;&#125;,&#123;gId:&apos;&apos;,gName:&apos;&apos;&#125;]&#125;pojo数据：public class myJsonRequest&#123; private Object mainData; private List&lt;Object&gt; gridData;&#125;才可以接受到 页面汇总echarts可视化图表 可以在bossjs中看到对应demo – js下拉框二级关联菜单js下拉框二级关联菜单效果代码具体实现(点击执行器得某一个，对应任务中的data会自动进行加载该执行器中的任务) 123456页面：&lt;QueryItem id=&quot;jobGroup&quot; name=&quot;执行器：&quot; editorType=&quot;COMBOBOX&quot; action=&quot;platform/appframe/jobcenter/joblog/jobGroupCBB.do&quot; comboFieldText=&quot;title&quot; comboFieldValue=&quot;val&quot; /&gt;&lt;QueryItem id=&quot;jobId&quot; name=&quot;任务：&quot; editorType=&quot;COMBOBOX&quot; data=&quot;[&#123;jobDesc:&apos;全部&apos;,id:&apos;0&apos;&#125;]&quot; comboFieldText=&quot;jobDesc&quot; comboFieldValue=&quot;id&quot; /&gt; 1234567891011121314151617181920212223242526272829303132js:(listener:&#123;&#125;)jobGroup : &#123; afterSelected : function(node)&#123; if(node.val == 0)&#123; $(&apos;#jobId&apos;).combobox(&apos;clearValue&apos;); $(&apos;#jobId&apos;).combobox(&apos;loadData&apos;, [&#123;jobDesc:&apos;全部&apos;,id:&apos;0&apos;&#125;]); &#125;else&#123; $(&apos;#jobId&apos;).combobox(&apos;clearValue&apos;); $(&apos;#jobId&apos;).combobox(&apos;reload&apos;,&apos;platform/appframe/jobcenter/joblog/getJobsByGroup.do?jobGroup=&apos;+node.val); &#125; &#125;&#125;获取数据：jobInfoPage_btnClear : &#123; click : function() &#123; var obj = &#123;&#125;; var jobNode = $(&apos;#jobId&apos;).data().selectNode; obj.jobNode = jobNode; var jobGroupNode = $(&apos;#jobGroup&apos;).data().selectNode; obj.jobGroupNode = jobGroupNode; if(jobNode == null || jobGroupNode == null)&#123; alert(&quot;请选择执行器和任务&quot;); return; &#125; dlg.showPage(dlg.ACTION.ADD, obj, function() &#123; JobLogModel.getInstance().refreshData(); &#125;) &#125;&#125;, – 时间区间选择(可选择时间段) 时间区间获取可以选择(昨天，上个月，去年。。。) 1234567&lt;QueryItem id=&quot;dateBegin&quot; name=&quot;开始时间：&quot; editorType=&quot;DATETIME&quot; width=&quot;210px&quot; editOptions=&quot;&#123; type: &apos;datetime&apos;, format:&apos;yyyy-mm-dd HH:ii:ss&apos;, dateend:&apos;dateEnd&apos; &#125;&quot;/&gt;&lt;QueryItem id=&quot;dateEnd&quot; name=&quot;结束时间：&quot; editorType=&quot;DATETIME&quot; width=&quot;210px&quot; editOptions=&quot;&#123; type: &apos;datetime&apos;,format:&apos;yyyy-mm-dd HH:ii:ss&apos; &#125;&quot;/&gt; – add/updat页面再弹窗并回填 在新增页面点击选择 -&gt; 跳转到 cron的页面选择时间（需要考虑的问题：点击选择时候，需要将新增页面的内容回填，同时带上cron的结果） 12345678910111213141516171819202122232425262728293031323334353637383940414243 选择按钮 在xxx_add.jsp中实现： &lt;af:page id=&quot;jobInfoPage&quot;&gt; &lt;button id=&quot;cronBtn&quot; style=&quot; position: absolute;right: 48px;top: 24px;cursor: pointer; background-color: #00c0ef;border-color: #00acd6; border-radius: 3px;color: #fff;box-shadow: none; width: 60px;height: 32px;border: 1px solid transparent; -webkit-box-shadow: none; touch-action: manipulation; &quot; &gt;选择&lt;/button&gt; &lt;/af:page&gt; //cron时间选择cronBtn : &#123; click : function() &#123; var self = JobInfoDlg.getInstance(); var d = &#123;&#125;; var data = $A(&apos;#jobInfoPage_form&apos;).serializeArray(); //将数组转换为对象 $.each(data, function() &#123; d[this.name] = this.value; &#125;); d[&apos;action&apos;] = self.indexAction; $.closeDialog(); // RequireJS 所以需要把该add的对象传递，用于回填add界面 jic.showPage(self,d, function(responseData) &#123; $A(&apos;#jobInfoPage_form&apos;).refreshFormData(responseData); &#125;); &#125;&#125;在xxx_add.js: showPage:function(.... 需要判断回填的data 不为空就回填数据，避免第一次add的data为空的带来的问题 if(data != &apos;&apos; &amp;&amp; data != &apos;undefined&apos; &amp;&amp; data != null)&#123; $A(&apos;#jobInfoPage_form&apos;).refreshFormData(data); &#125; Grid Column数据格式化 grid Column数据格式化 12345678config.getColumn(&quot;triggerCode&quot;).setAttr( &quot;formatter&quot;, function(val, row, i) &#123; if (val == 200) &#123; return &quot;&lt;span style=&apos;color:green;&apos;&gt;成功&lt;span/&gt;&quot;; &#125; else if (val == 500) &#123; return &quot;&lt;span style=&apos;color:red;&apos;&gt;失败&lt;span/&gt;&quot;; &#125; &#125;); – 页面combobox初始化 12345678910111213141516// 页面加载后初始化initPage : function() &#123; var title = $A(&apos;#jobGroup&apos;).combobox(&apos;getText&apos;); var val = $A(&apos;#jobGroup&apos;).combobox(&apos;getValue&apos;); var jobDesc = $A(&apos;#jobId&apos;).combobox(&apos;getText&apos;); var id = $A(&apos;#jobId&apos;).combobox(&apos;getValue&apos;); if(val == &apos;&apos; || val == undefined || title == &apos;&apos; || title == undefined)&#123; $A(&apos;#jobGroup&apos;).combobox(&apos;setValue&apos;,&apos;0&apos;); $A(&apos;#jobGroup&apos;).combobox(&apos;setText&apos;,&apos;全部&apos;); &#125; if(id == &apos;&apos; || id == undefined || jobDesc == &apos;&apos; || jobDesc == undefined)&#123; $A(&apos;#jobId&apos;).combobox(&apos;setValue&apos;,&apos;0&apos;); $A(&apos;#jobId&apos;).combobox(&apos;setText&apos;,&apos;全部&apos;); &#125;&#125;, – add/updat页面combobox初始化 1234567891011121314151617181920$.ajax(&#123; url : &apos;platform/appframe/jobcenter/jobinfo/ExecutorRouteStrategyEnum.do&apos;, async:false, type : &quot;post&quot;, dataType : &quot;json&quot;, success : function(data) &#123; //js全局变量 self.executorRouteStrategyMap = data; &#125; &#125;); var ERSCurrent = data.executorRouteStrategy;$.each(self.executorRouteStrategyMap, function() &#123; if(this.val = ERSCurrent) //data 是updat的数据来源 通过data.ersTitle 让combobox初始化 val已经注入 所以需要手动对Title注入 //$A(&quot;#jobInfoPage_form&quot;).refreshFormData(data); data.ersTitle = this.ersTitle;&#125;); – XGrid按钮不同行设置disabled 123456789//可以通过shift+command+R 输入 app-grid.js中的代码 看到api 中没有的部分config.getButton(&quot;jobLogPage_grid_StopTMsg&quot;).setAttr(&quot;disabled&quot;,function(data,e)&#123; if(data.handleCode == 0 &amp;&amp; row.triggerCode == 200)&#123; return false; &#125; return true; &#125;); – Multselect-sortable(多项选择项-可手动排序) xxx.xml 1234567891011121314151617181920212223242526&lt;items&gt; &lt;Panel id=&quot;afaAppMenuPage_panel_content&quot; region=&quot;center&quot; width=&quot;100%&quot; height=&quot;100%&quot; style=&quot;margin: 15px;&quot;&gt; &lt;items&gt; &lt;Panel id=&quot;afaAppMenuPage_panel_left&quot; region=&quot;west&quot; layout=&quot;border&quot; style=&quot;width:330px;height:510px;border:1px solid #CCC;float:left;&quot;&gt; &lt;items&gt; &lt;Tree id=&quot;afaAppMenuTree&quot; width=&quot;100%&quot; hasQry=&quot;false&quot; hasRoot=&quot;false&quot; style=&quot;overflow:scroll;&quot; idField=&quot;treeId&quot; isAsync=&quot;true&quot; nameField=&quot;treeText&quot; parentField=&quot;treeParentId&quot; height=&quot;510px&quot; loadUrl=&quot;platform/appframe/menu/afaappmenu/getAfaAppMenuTree.do&quot; checkable=&quot;false&quot; selectedMulti=&quot;true&quot;&gt; &lt;/Tree&gt; &lt;/items&gt; &lt;/Panel&gt; &lt;Panel id=&quot;afaAppMenuPage_panel_center&quot; region=&quot;center&quot; layout=&quot;border&quot; style=&quot;width:100px;height:510px;float:left;&quot;&gt; &lt;items&gt; &lt;ButtonArea id=&quot;afaAppMenuPage_panel_center-btns&quot; displayType=&quot;BUTTON&quot;&gt; &lt;Button id=&quot;btnRightward&quot; name=&quot; &gt;&gt;&quot; style=&quot;margin-top: 210px;&quot;&gt;&lt;/Button&gt; &lt;/ButtonArea&gt; &lt;/items&gt; &lt;/Panel&gt; &lt;Panel id=&quot;afaAppMenuPage_panel_right&quot; region=&quot;right&quot; layout=&quot;border&quot; style=&quot;width:330px;height:510px;border:1px solid #CCC;float:left;overflow:scroll;&quot;&gt; &lt;items&gt; &lt;/items&gt; &lt;/Panel&gt; &lt;/items&gt; &lt;/Panel&gt;&lt;/items&gt; xxx.jsp 12345678&lt;style&gt; #afaAppMenuPage_panel_right&#123;border-left: 1px solid #cbcbcb&#125; #afaAppMenuPage_panel_right &gt; .tag-list&#123;width: 90%; margin: 10px auto 0;&#125; #afaAppMenuPage_panel_right &gt; .tag-list &gt; li,#afaAppMenuPage_panel_right &gt; .tag-list &gt; li &gt; span &#123;width: 100%&#125; #afaAppMenuPage_panel_right &gt; .tag-list &gt; li &gt; span &#123;text-align: center&#125; #afaAppMenuPage_panel_right &gt; .tag-list &gt; li.icon-shanchutianchong::before&#123;cursor:pointer&#125;&lt;/style&gt; requireJs: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293//获得容器getContainer : function()&#123; var $div = $A(&quot;#afaAppMenuPage_panel_right &gt; .tag-list&quot;); if($div != null &amp;&amp; $div != &quot;undefined&quot; &amp;&amp; $div.length &gt; 0)&#123; &#125;else&#123; $div = &quot;&lt;ul class=&apos;tag-list&apos;&gt;&lt;/ul&gt;&quot;; $A(&quot;#afaAppMenuPage_panel_right&quot;).append($div); &#125; $A(&quot;#afaAppMenuPage_panel_right &gt; .tag-list&quot;).sortable(&#123; &quot;handle&quot;:&quot;span&quot;, &quot;start&quot;:function(e,ui)&#123; ui.item.addClass(&quot;curr&quot;); &#125;, &quot;stop&quot;:function(e,ui)&#123; ui.item.removeClass(&quot;curr&quot;); &#125; &#125;); $( &quot;#afaAppMenuPage_panel_right&quot; ).disableSelection();&#125;,//新增菜单选项insertUserMenu: function(treeNode)&#123; var $porlet = $A(&quot;#afaAppMenuPage_panel_right &gt; .tag-list &gt; li&quot;); var $po = $A(&quot;#afaAppMenuPage_panel_right &gt; .tag-list span[rel=&quot;+ treeNode.treeId +&quot;]&quot;); if($po != null &amp;&amp; $po != &quot;undefined&quot; &amp;&amp; $po.length &gt; 0)&#123; $a.messager.error(&quot;该菜单已选择&quot;); return false; &#125; var $userMenu = AfaShortCutMenuDlg.getInstance().setUserMenu(treeNode.treeId,treeNode.treeText); AfaShortCutMenuDlg.getInstance().getContainer(); $A(&quot;#afaAppMenuPage_panel_right &gt; .tag-list&quot;).append($userMenu);&#125;,//设置门户setUserMenu: function(key,value)&#123; var style=&quot;&quot;; var div = &quot;&lt;li style=&apos;border-radius: 5px;margin-bottom:5px;border: 1px solid #cecece;padding: 5px;text-align: center;&apos;&apos;&gt;&lt;span style=&apos;font-size:12px;&apos; href=\&quot;javascript:void(0)\&quot; rel=&quot;+ key +&quot; name=\&quot;&quot;+ value +&quot;\&quot;&gt;&lt;span class=\&quot;icon-shanchutianchong\&quot; style=\&quot;display:inline-block;height:1.3em;width:1em;margin-right:.4em;cursor:pointer;\&quot;&gt;&lt;/span&gt;&quot;+ value +&quot; &lt;/span&gt;&lt;/li&gt;&quot;; return div;&#125;,doSave : function(config, callback) &#123; var $userMenu = $A(&quot;#afaAppMenuPage_panel_right &gt; .tag-list &gt; li &gt; span&quot;); if($userMenu.length==0)&#123; alert(&quot;请选择授权对象&quot;); return false; &#125; var menuIdString=&quot;&quot;; for(var i=0;i&lt;$userMenu.length;i++)&#123; var obj=&#123;&#125;; menuIdString += $($userMenu[i]).attr(&quot;rel&quot;)+&quot;,&quot;; &#125; menuIdString = menuIdString.substring(0,menuIdString.length-1); var url = &quot;platform/appframe/menu/afashortcutmenu/batchAddShortcutMenu.do&quot;; $app.ajax.ajaxCall(&#123; url: url, data: &#123;menuIds: menuIdString&#125;, callback: function()&#123; $a.messager.correct(&quot;操作成功&quot;); &#125; &#125;); /*if (_self.showPageCallBack) &#123; _self.showPageCallBack(); &#125;*/ $.closeDialog();&#125;,// 页面加载后初始化initPage : function() &#123; var url = &quot;platform/appframe/menu/afashortcutmenu/getShortcutMenuByUserCode.do&quot;; $app.ajax.ajaxCall(&#123; url: url, data: &#123;&#125;, callback: function(data)&#123; console.log(data); for(var i=0;i&lt;data.length;i++)&#123; var $userMenu = AfaShortCutMenuDlg.getInstance().setUserMenu(data[i].menuId,data[i].menuName); AfaShortCutMenuDlg.getInstance().getContainer(); $A(&quot;#afaAppMenuPage_panel_right &gt; .tag-list&quot;).append($userMenu); &#125; &#125; &#125;); $(&quot;#afaAppMenuPage_panel_right&quot;).click(function(e)&#123; console.log(event.target.className.indexOf(&apos;icon-shanchutianchong&apos;)) if (e.target.tagName.toLowerCase() === &quot;span&quot; &amp;&amp; e.target.className.indexOf(&apos;icon-shanchutianchong&apos;) !== -1) &#123; $(e.target.parentElement.parentElement).remove() &#125; &#125;); &#125;,]]></content>
      <categories>
        <category>BS前端页面汇总</category>
      </categories>
      <tags>
        <tag>BS前端页面汇总</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac_eclipse调制代码方式]]></title>
    <url>%2F2017%2F09%2F20%2Feclipse%E8%B0%83%E5%88%B6%E4%BB%A3%E7%A0%81%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[摘要: mac_eclipse调制代码方式 调制代码时，常用到的方式shift + command + T -&gt; Open Type control + H -&gt; Search (File Search、Java Search …) command + O -&gt; 查看该class中的方法和成员变量 command + e -&gt; 快速转换编辑器 option + command + 上下 -&gt; 将高亮显示处往上或下复制 command + m -&gt; 窗口最大化切换 command + / -&gt; 自动注释掉选择的代码块 command + shift + / -&gt; 自动注释掉选择的代码块 command + shift + X 和 command + shift + Y -&gt; 英文字母大小写的转换 command +shift + O -&gt; 自动引入包和删除无用包 command +option + 左右 -&gt; 回到上次光标的位置 debug模式情况下：想立刻执行一条语句刚写的语句，此时断点正在附近: command + U 左边的是将所有包缩小 右边勾选 会自动跟从你所浏览的代码所在的包的位置 Projects Presentation(项目介绍)展示方式： Flat（平坦式 一大串）； Hierarchical（分等级式 像ztree的感觉） Variables 可以在debug时看到对应的变量的情况BreakPoints 可以在这里看到你打得断点的信息（位置，数量，也可以对端点进行操作）Expressions 在端点执行过程中 执行想要的方法 对Tomcat进行部分操作修改Servers中某个Tomcat的config(后台代码修改不会导致Tomcat重启) server.xml： 修改最后几行的 Context标签中 reloadable=”false” debug=”0” 现在有个很好用的插件不需要上面的配置就可以实现 后台代码修改即可以使用，不需要重启Tomcat。JRebel 支持 eclipse、Intelli IDEA、android studio 对Git进行操作 Commit的操作然后Pull（更新）Push（提交git合并） 对Maven包依赖查看]]></content>
      <categories>
        <category>eclipse</category>
      </categories>
      <tags>
        <tag>mac_eclipse调制代码方式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进入BS部门第一天]]></title>
    <url>%2F2017%2F09%2F20%2F%E9%83%A8%E9%97%A8%E7%AC%AC%E4%B8%80%E5%A4%A9%2F</url>
    <content type="text"><![CDATA[摘要: 遇到问题及解决 遇到问题及解决 web项目出现Dynamic Web Module 无法从2.3转化为2.5的版本。 解决方案：首先出现问题的原因在于你的web.xml： 1234&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:web=&quot;http://java.sun.com/xml/ns/javaee&quot;xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot;id=&quot;WebApp_ID&quot; version=&quot;2.5&quot;&gt; 项目还是2.3的，而使用的version=2.5的，项目会报错（大致的意思就是无法转化），可以通过在本地项目中.setting文件中进行手动改变为2.5。 引用的项目来自gitlab上，gitlab所引用的项目已经在gitlab上已经更新的，但是在maven repository中的还未改变。 解决方案：可以通过将gitlab上的项目下载下来，然后进行install 生成新的jar包或者其他的包 其中用到的操作： git init git clone gitLab地址 cd 对应的项目中 mvn clean install 生成最新的jar包或其他包 将项目也导入进eclipse中，原本引用该gitlab上的项目优先在本地上进行搜索并且加载，如果没有在从远程repository中下载对应的包。]]></content>
      <categories>
        <category>遇到问题及解决</category>
      </categories>
      <tags>
        <tag>遇到问题及解决</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小组项目学习记录]]></title>
    <url>%2F2017%2F09%2F12%2FBS%E5%B0%8F%E7%BB%84%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[摘要: BS小组项目学习记录 前端部分（XML、JS）前端使用到公司的框架： xml标签：Page、items、Panel、Tree、XGrid…JS使用到的是requireJS： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556//define([&apos;引入外部js模块或控件&apos;],function(&apos;引入外部js或控件的别名&apos;)&#123;&#125;)define([&quot;app/widgets/window/app-dialog&quot;,&quot;目录&quot;,&quot;目录&quot;],function(Dialog,PageBase,dlg)&#123; var xxxModel = PageBase.extend(&#123; //类初始化 initialize : function()&#123; xxxModel.superclass.initialize.call(this); &#125;, //控件监听事件 格式：#控件id#:&#123;事件名:事件方法&#125; listeners:&#123; &#125;, //页面初始化 initPage:function()&#123; &#125;, //显示查看业 showViewPage:function(data,e)&#123; var _self=this; dlg.showPage(dlg.ACTION.VIEW,data,function()&#123; _self.refreshData(); &#125;); &#125;, refreshData:function()&#123; $(&quot;#receiptMaintenancePage_grid&quot;).grid(&quot;reload&quot;); &#125;, //显示编辑业 showEditPage:function(data,e)&#123; var _self=this; dlg.showPage(dlg.ACTION.EDIT,data,function()&#123; //_self.refreshData(); $(&quot;#receiptMaintenancePage_grid&quot;).grid(&quot;reload&quot;); &#125;); &#125;, //控件属性重置 initUIExtConfig : function() &#123; var _self=this; this.uiExtConfig=&#123; //格式 #控件id#:function(控件属性集类)&#123; config.setAttr(&quot;控件属性名&quot;,&quot;属性值&quot;),// 网格，下拉网格，特殊设置config.getColumn(&quot;网列id&quot;).setAttr(&quot;列属性名&quot;,&quot;列属性值&quot;)config.getButton(&quot;网格内包含的按钮id&quot;).setAttr(&quot;handler&quot;,&quot;点击事件&quot;) &#125; receiptMaintenancePage_grid:function(config)&#123; config.getButton(&quot;receiptMaintenancePage_grid_btnEdit&quot;).setAttr(&quot;handler&quot;,_self.showEditPage); config.getButton(&quot;receiptMaintenancePage_grid_btnView&quot;).setAttr(&quot;handler&quot;,_self.showViewPage); config.getButton(&quot;receiptMaintenancePage_grid_btnDel&quot;).setAttr(&quot;handler&quot;,_self.doDeleteData); &#125; &#125; &#125; &#125;); xxxModel.getInstance=function()&#123; if (!this.instance)&#123; this.instance =new xxxModel(); &#125; return this.instance; &#125; return xxxModel.getInstance();&#125;); XML经常使用到的方式1.树 123456&lt;Tree id=&quot;receiptLeftTree&quot; layoutHeight=&quot;0&quot; width=&quot;100%&quot; hasRoot=&quot;true&quot; rootId=&quot;&quot; rootName=&quot;机构列表&quot; idField=&quot;treeId&quot; isAsync=&quot;true&quot; nameField=&quot;treeText&quot; parentField=&quot;treeParentId&quot; hasQry=&quot;true&quot; searchUrl=&quot;platform/appframe/afauser/searcherAfaUserTree.do&quot; searchFields=&quot;orgName&quot; loadUrl=&quot;platform/appframe/afauser/queryAfaUserTree.do&quot;&gt;&lt;/Tree&gt; 2.查询功能 12345678910111213141516171819&lt;Query id=&quot;receiptMaintenancePage_query&quot; queryTarget=&quot;receiptMaintenancePage_grid&quot; isAdvance=&quot;true&quot; style=&quot;display:none;&quot; manual=&quot;false&quot; advColCount=&quot;2&quot;&gt; &lt;quicks&gt; &lt;QueryItem id=&quot;ticketedPointCode&quot; name=&quot;开票点&quot; tips=&quot;输入开票点编码查询&quot; field=&quot;TICKETED_POINT_CODE&quot; operator=&quot;like&quot; editorType=&quot;TEXTBOX&quot; /&gt; &lt;QueryItem id=&quot;startTime&quot; name=&quot;编制日期&quot; field=&quot;CREATE_TIME&quot; tips=&quot;输入编制日期查询&quot; operator=&quot;&gt;=&quot; editorType=&quot;DATETIME&quot; /&gt; &lt;QueryItem id=&quot;endTime&quot; name=&quot;至&quot; field=&quot;CREATE_TIME&quot; tips=&quot;输入编制日期查询&quot; operator=&quot;&amp;lt;=&quot; editorType=&quot;DATETIME&quot; /&gt; &lt;QueryItem id=&quot;gaoji&quot; name=&quot;高级&quot; value=&quot;1&quot; visible=&quot;false&quot; operator=&quot;=&quot; editorType=&quot;TEXTBOX&quot; /&gt; &lt;/quicks&gt; //高级查询 &lt;advances&gt; &lt;QueryItem id=&quot;ticketedPointCode&quot; name=&quot;开票点编码&quot; editorType=&quot;TEXTBOX&quot; /&gt; &lt;QueryItem id=&quot;createTime&quot; name=&quot;创建日期&quot; editorType=&quot;DATETIME&quot; /&gt; &lt;/advances&gt;&lt;/Query&gt; 3.标签页 123456789101112131415161718192021&lt;Panel id=&quot;id必填&quot; region=&quot;定义布局面板的位置&quot;&gt; &lt;items&gt; &lt;Tabs id=&quot;receiptMaintenance_panel_right_bottom_tabs&quot;&gt; &lt;items&gt; &lt;TabPanel id=&quot;panel_south_tabs_projects_info&quot; name=&quot;项目&quot; layout=&quot;border&quot; style=&quot;height: 240px;&quot;&gt; &lt;items&gt; 内容可以是 XGrid或者Form &lt;/items&gt; &lt;/TabPanel&gt; &lt;TabPanel id=&quot;panel_south_tabs_user_info&quot; name=&quot;项目&quot; layout=&quot;border&quot; style=&quot;height: 240px;&quot;&gt; &lt;items&gt; 内容可以是 XGrid或者Form &lt;/items&gt; &lt;/TabPanel&gt; &lt;/items&gt; &lt;/Tabs&gt; &lt;/items&gt;&lt;/Panel&gt; 4.XGridColumn实现下拉并且将row自动填写( XML 和 JS(在listeners中) ) 4.1 XML: 12345678&lt;XGridColumn field=&quot;projectStandard&quot; title=&quot;项目标准&quot; editorType=&quot;COMBOBOX&quot; align=&quot;center&quot; editorOptions=&quot;&#123; textfield: &apos;projectStandard&apos;, valuefield: &apos;projectCode&apos;, url: &apos;platform/appframe/receipt/maintenance/receiptmaintenance/queryProjectList.do&apos; &#125;&quot; /&gt; 4.2 JS: 12345678910111213141516171819projects_grid_editable : &#123; onClickCell : function(rowData, rowIndex, field) &#123; var self = ReceiptMaintenanceDlg.getInstance(); if(field == &quot;projectStandard&quot;)&#123; var edProjectStandard = $(&apos;#projects_grid_editable&apos;).grid(&apos;getEditor&apos;, field); var edProjectCode = $(&apos;#projects_grid_editable&apos;).grid(&apos;getEditor&apos;, &quot;projectCode&quot;); $(edProjectStandard).combobox(&apos;reload&apos;,&apos;platform/appframe/receipt/maintenance/receiptmaintenance/queryProjectList.do?whichData=project&apos;); $(edProjectStandard).bind(&apos;change&apos;,function()&#123; var projectId = $(edProjectStandard).combobox(&quot;getValue&quot;); var projectStandard= $(edProjectStandard).combobox(&quot;getText&quot;); var rowIndex = $(&apos;#projects_grid_editable&apos;).grid(&apos;getCurrentEditRowIndex&apos;); var rowData = $(&apos;#projects_grid_editable&apos;).grid(&apos;getCurrentEditRowData&apos;); $(&apos;#projects_grid_editable&apos;).grid(&apos;getEditor&apos;, &quot;projectCode&quot;).textbox(&apos;setValue&apos;,projectId); $(&apos;#projects_grid_editable&apos;).grid(&apos;getEditor&apos;, &quot;projectCode&quot;).textbox(&apos;disable&apos;);// $(&apos;#projects_grid_editable&apos;).grid(&apos;saveRow&apos;, &#123;rowIndex : rowIndex, rowData:&#123;&apos;projectCode&apos;:projectId&#125;, command:&apos;update&apos;&#125;); &#125;); &#125; &#125;&#125; 5.将主表的数据和副表的数据一起发送给后台(增删改) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556doSave : function(config, callback) &#123; var gridData = $(&quot;#projects_grid_editable&quot;).grid(&apos;getAllData&apos;); var params = $A(&apos;#receiptMaintenancePage_form&apos;).getSumbitData(); var obj = new Object(); obj.gridData = gridData; obj.mainData = params.data; obj.type = &quot;modify&quot;; var myURL = &quot;platform/appframe/receipt/maintenance/receiptmaintenance/doInsertProject.do&quot;; $app.ajax.ajaxCall(&#123; url : myURL, data : obj, contentType:&apos;application/json&apos;, dataType: &apos;json&apos;, type: &apos;POST&apos;, callback : function(json) &#123; if (config.isSaveAdd) &#123; $A(&quot;#receiptMaintenancePage_form&quot;) .clearFormEditorValue(); _self.indexAction = _self.ACTION.ADD; &#125; else if (config.isSaveClose) &#123; $.closeDialog(); _self.indexAction = &quot;&quot;; &#125; else if (config.isSaveView) &#123; $A(&quot;#receiptMaintenancePage_form&quot;) .toggleFormState(&quot;view&quot;); $A(&quot;#id&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#ticketedPointCode&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#ticketedPointName&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#ticketedPointType&quot;).combobox(&quot;readonly&quot;, true); $A(&quot;#simpleCode&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#dataAcquisitionCycle&quot;).textbox(&quot;readonly&quot;, true);// $A(&quot;#createTime&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#sysAppMode&quot;).combobox(&quot;readonly&quot;, true); $A(&quot;#contacts&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#contactsInfo&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#superOrg&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#isOnline&quot;).textbox(&quot;readonly&quot;, true); $A(&quot;#remark&quot;).textbox(&quot;readonly&quot;, true); // $A(&quot;#sysAppMode&quot;).combobox(&quot;readonly&quot;, true); // $A(&quot;#sysAppModeRadioBox&quot;).radiobox(&quot;readonly&quot;, false);// $A(&quot;#emergencyTicketed&quot;).radiobox(&quot;readonly&quot;, false);// $A(&quot;#emergencyDays&quot;).textbox(&quot;readonly&quot;, false); _self.indexAction = _self.ACTION.VIEW; &#125; if (_self.showPageCallBack) &#123; _self.showPageCallBack(); &#125; &#125; &#125;);&#125; 6.小表的操作 1234567891011121314151617181920initUIExtConfig : function() &#123; var _self = this; this.uiExtConfig = &#123; // 格式 #控件id#:function(控件属性集类)&#123; config.setAttr(&quot;控件属性名&quot;,&quot;属性值&quot;),// // 网格，下拉网格，特殊设置config.getColumn(&quot;网列id&quot;).setAttr(&quot;列属性名&quot;,&quot;列属性值&quot;)config.getButton(&quot;网格内包含的按钮id&quot;).setAttr(&quot;handler&quot;,&quot;点击事件&quot;) // &#125; projects_grid_editable:function(config)&#123; config.getButton(&quot;projects_grid_addBtn&quot;).setAttr(&quot;handler&quot;, _self.appendPGridRow); config.getButton(&quot;projects_grid_deleteBtn&quot;).setAttr(&quot;handler&quot;, _self.deletePGridRow); &#125;, receipts_grid_editable:function(config)&#123; config.getButton(&quot;receipts_grid_addBtn&quot;).setAttr(&quot;handler&quot;, _self.appendRGridRow); config.getButton(&quot;receipts_grid_deleteBtn&quot;).setAttr(&quot;handler&quot;, _self.deleteRGridRow); &#125;, users_grid_editable:function(config)&#123; config.getButton(&quot;users_grid_addBtn&quot;).setAttr(&quot;handler&quot;, _self.appendUGridRow); config.getButton(&quot;users_grid_deleteBtn&quot;).setAttr(&quot;handler&quot;, _self.deleteUGridRow); &#125; &#125;&#125; 前后台请求1.其中BS使用到的ajax自带的方式 123456789101112131415161718192021222324252627前端JS：$app.ajax.ajaxCall(&#123; url : url, data : jsonData, callback : function(data) &#123; $(&quot;#receiptMaintenancePage_grid&quot;).grid(&quot;reload&quot;); &#125;&#125;);后台controller:public AajaxResult queryProect(@requestBody 对象 对象名)&#123;&#125;需要注意的是：Json格式：&#123; mainData:&#123;id:&apos;&apos;,name:&apos;&apos;&#125;, gridData:[&#123;gId:&apos;&apos;,gName:&apos;&apos;&#125;,&#123;gId:&apos;&apos;,gName:&apos;&apos;&#125;]&#125;pojo数据：public class myJsonRequest&#123; private Object mainData; private List&lt;Object&gt; gridData;&#125;才可以接受到 2.BS使用$.ajax({});方式 12]]></content>
      <categories>
        <category>bs学习记录</category>
      </categories>
      <tags>
        <tag>bs学习记录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[next博客进阶]]></title>
    <url>%2F2017%2F08%2F28%2Fnext%E5%8D%9A%E5%AE%A2%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[摘要: next添加RSS、字数统计及阅读时长、next主题修改动态背景 next添加RSS 进入本地hexo目录,输入以下命令: 1npm install hexo-generator-feed 添加配置，在本地hexo根目录下的_config.yml文件中，添加以下配置: 12345678910# Extensions## Plugins: http://hexo.io/plugins/#RSS订阅plugin:- hexo-generator-feed#Feed Atomfeed:type: atompath: atom.xmllimit: 20 添加主题配置，在主题目录下的_config.yml目录下，添加如下配置: 1rss: /atom.xml 字数统计及阅读时长 Install 1npm install hexo-wordcount --save *修改对应的代码（blog/themes/next/layout/_macro/post.swig） &lt;span title=&quot;{{ __('post.wordcount') }}&quot;&gt; {{ wordcount(post.content) }} 字 &lt;/span&gt; &lt;span title=&quot;{{ __('post.min2read') }}&quot;&gt; {{ min2read(post.content) }} 分钟 &lt;/span&gt; next主题修改动态背景(这里只说next主题在5.1.1以上版本) 在对应的目录下修改(blog/themes/next/_config.yml)自行尝试 123456789101112131415# Canvas-nestcanvas_nest: true# three_wavesthree_waves: false# canvas_linescanvas_lines: false# canvas_spherecanvas_sphere: false# Only fit scheme Pisces# Canvas-ribboncanvas_ribbon: true 参考的网站：Hexo文章计数插件WordCounthexo博客安装RSS插件next主题如何添加动态背景]]></content>
      <categories>
        <category>next</category>
      </categories>
      <tags>
        <tag>next进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初步了解Redis和ZooKeeper]]></title>
    <url>%2F2017%2F08%2F28%2F%E5%88%9D%E6%AD%A5%E4%BA%86%E8%A7%A3Redis%E5%92%8CZookeeper%2F</url>
    <content type="text"><![CDATA[摘要: 初步了解Redis和ZooKeeper作用及使用场景;mac依赖brew快速安装Redis和ZooKeeper RedisRedis是一个开源，高级的键值存储和一个适用的解决方案，用于构建高性能，可扩展的Web应用程序。(键值对 key-value) Redis有三个主要特点，使它优越于其它键值数据存储系统: Redis将其数据库完全保存在内存中，仅使用磁盘进行持久化。 与其它键值数据存储相比，Redis有一组相对丰富的数据类型。 Redis可以将数据复制到任意数量的从机中。 Redis的优点 异常快 - Redis非常快，每秒可执行大约 ==110000== 次的设置( ==SET== )操作，每秒大约可执行81000次的读取/获取( ==GET== )操作。 支持丰富的数据类型 - Redis支持开发人员常用的大多数数据类型，例如列表，集合，排序集和散列等等。这使得Redis很容易被用来解决各种问题，因为我们知道哪些问题可以更好使用地哪些数据类型来处理解决。 操作具有原子性 - 所有Redis操作都是原子操作，这确保如果两个客户端并发访问，Redis服务器能接收更新的值。 多实用工具 - Redis是一个多实用工具，可用于多种用例，如：缓存，消息队列(Redis本地支持发布/订阅)，应用程序中的任何短期数据，例如，web应用程序中的会话，网页命中计数等。 “原子操作(atomic operation)是不需要synchronized”，这是Java多线程编程的老生常谈了。所谓原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch （切换到另一个线程） —- 度娘 Redis与其他键值存储系统 Redis是键值数据库系统的不同进化路线，它的值可以包含更复杂的数据类型，可在这些数据类型上定义原子操作。 Redis是一个内存数据库，但在磁盘数据库上是持久的，因此它代表了一个不同的权衡，在这种情况下，在不能大于存储器(内存)的数据集的限制下实现非常高的写和读速度。 内存数据库的另一个优点是，它与磁盘上的相同数据结构相比，复杂数据结构在内存中存储表示更容易操作。 因此，Redis可以做很少的内部复杂性。 ZooKeeper 首先需要了解分布式系统（distributed system） 建立在网络之上的软件系统。正是因为软件的特性，所以分布式系统具有高度的内聚性和透明性。在分布式数据库系统中，用户感觉不到数据是分布的，即用户不须知道关系是否分割、有无副本、数据存于哪个站点以及事务在哪个站点上执行等。 内聚性是指每一个数据库分布节点高度自治，有本地的数据库管理系统。 透明性是指每一个数据库分布节点对用户的应用来说都是透明的，看不出是本地还是远程。 了解分布式协调技术 主要用来解决分布式环境当中多个进程之间的同步控制，让他们有序的去访问某种临界资源，防止造成”脏数据”的后果。 分布式协调技术的核心就是实现分布式锁 顺带提下mac上安装Redis和ZooKeeper很快捷（需要已经安装过 ==Homebrew== ）[Homebrew官方](https://brew.sh/) 123456789安装 Homebrew ：/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;安装 Redis ：brew install redis安装 ZooKeeper ：brew install zookeeper 参考网站 Redis快速入门 ZooKeeper学习第一期—Zookeeper简单介绍]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Redis &amp; ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站框架初识]]></title>
    <url>%2F2017%2F08%2F28%2F%E7%BD%91%E7%AB%99%E6%A1%86%E6%9E%B6%E5%88%9D%E8%AF%86%2F</url>
    <content type="text"><![CDATA[摘要: 网站框架初识，其中框架的演变和技术 网站框架初识 随着互联网的发展，网站应用的规模不断扩大，常规的垂直应用架构已无法应对，分布式服务架构以及流动计算架构势在必行，亟需一个治理系统确保架构有条不紊的演进。 单一应用架构 当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM)是关键。 垂直应用架构 当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的Web框架(MVC)是关键。 分布式服务架构 当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的分布式服务框架(RPC)是关键。 流动计算架构 当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)是关键。 待续… 参考的网站：dubbo]]></content>
      <categories>
        <category>J2EE</category>
      </categories>
      <tags>
        <tag>网站框架初识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jetbrains软件(WS、IJ)]]></title>
    <url>%2F2017%2F08%2F28%2F%E7%A0%B4%E8%A7%A3Jetbrains%E8%BD%AF%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[摘要: 破解Jetbrains软件 Ubuntu下面 PHPSTORM2017.2破解方法 在 http://idea.lanyus.com/ 上面新下载一个破解文件。 破解步骤 将JetbrainsCrack-2.6.3_proc.jar放到phpstorm安装目录的lib文件夹下面 进入到phpstorm安装目录的bin目录下面。找到phpstorm64.vmoptions文件，然后打开，在最后面一行输入-javaagent:/opt/phpstorm2017/lib/JetbrainsCrack-2.6.3_proc.jar保存文件。 打开http://idea.lanyus.com/getkey?userName=username username可以随便更改成你想要的，然后生成一个激活码， 再打开phpstorm，选择Activation Code选项，将生成的激活码复制进去，然后激活。 完结 重启phpstorm，然后就可以开始coding之路了。]]></content>
      <categories>
        <category>Jetbrains</category>
      </categories>
      <tags>
        <tag>Jetbrains</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github命令]]></title>
    <url>%2F2017%2F08%2F28%2Fgithub%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要: github命令 github使用的基本步骤 mac环境1、 创建一个Test文件夹，然后进去到此文件夹中(初始化git仓库) 1git init 2、 git clone 命令将存储库克隆到新目录中 12git clone http://bogon/huangdonghua/mytest.git输入对应的账号密码 3、 查看状态 1git status 4、 把 myTest/test.txt 文件添加到本地Git仓库，将myTest一并add 1git add myTest/ 5、 可以选择设置下自己的用户名与邮箱 12git config —global user.name &quot;huangdonghua&quot; git config —global user.email &quot;591327356@qq.com&quot; 6、 正式提交 1git commit -m ‘myTest’ 7、 查看所有产生的 commit 记录 1git log 8、 把本地 Test 项目与 GitLab 上的 myTest 项目进行关联（切换到Test 目录） 123git remote add origin http://bogon/huangdonghua/mytest.gitgit remote -v //查看我们当前项目有哪些远程仓库 9、 向远程仓库进行代码提交 (需要事先配置好公钥和密钥 id_rsa.pub 和 id_rsa) 1git push origin master 出现过的错误: 123456789$ git push origin master To http://bogon/huangdonghua/mytest.git ! [rejected] master -&gt; master (fetch Mytest) error: failed to push some refs to &apos;http://bogon/huangdonghua/mytest.git&apos; hint: Updates were rejected because the remote contains work that you do hint: not have locally. This is usually caused by another repository pushing hint: to the same ref. You may want to first integrate the remote changes hint: (e.g., &apos;git pull ...&apos;) before pushing again. hint: See the &apos;Note about fast-forwards&apos; in &apos;git push --help&apos; for details. 理解： 远程仓库已经更新了，本地仓库还未更新，在 push 之前需要做 pull 用来更新本地仓库（保证一致，才可以进行合并) 1git pull origin master 这时候又有可能遇到的问题： 1234$ git pull origin master From http://bogon/huangdonghua/mytest.git * branch master -&gt; FETCH_HEAD fatal: refusing to merge unrelated histories 解决方案：1git pull origin master --allow-unrelated-histories 成功后，就可以执行 push 操作了 在mac下 SSH Key设置： 1234567$ cd ~/.ssh/$ ls如果看到 id_rsa id_rsa.pub 这2个文件就说明已经有了SSH Key；这时候只要 vim id_rsa.pub 赋值就可以了如果没有： ssh-keygen -t rsa 选择默认和输入密码就可以省下就和上面一样了 其余git命令123456789101112131415161718git branch aaa 新建分枝aaa git branch 查看分枝 git checkout aaa 切换到分枝aaa git checkout -b aaa 新建并切换到aaa git merge aaa 把aaa分支的代码合并过来(当前所在分枝，比如master) git branch -d aaa 删除分枝aaa git branch -D aaa 强制删除aaa git tag v1.0 加版本号 git tag 查看版本号 git checkout v1.0 切换到版本v1.0//恢复某个文件的修改，若存在暂存区域的话，就恢复到暂存区域的状态，//若不存在暂存区域的话，就恢复到本地库的状态。git checkout 文件名//下面的.是表示所有文件git checkout .//若存在暂存区域，就是工作区与暂存区域的具体差异，若不存在暂存区域，则是工作区与本地库的具体差异。git diff 懒人避免冲突的方式：先将本地修改存储起来 1$ git stash 这样本地的所有修改就都被暂时存储起来 123$ git stash listgit stash暂存修改其中stash@&#123;0&#125;就是刚才保存的标记。 暂存了本地修改之后，就可以pull了 1$ git pull 还原暂存的内容 1$ git stash pop stash@&#123;0&#125; 详细懒人方式]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[macdown操作手册]]></title>
    <url>%2F2017%2F08%2F28%2Fmacdown%E6%93%8D%E4%BD%9C%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[摘要: 认识MarkDown 一、认识MarkDown什么是 MarkDown ? MarkDown 是一种 轻量级的标记语言 ,可以使用普通文本编辑器编写的语言。通过简单的标记语法，使普通的文本具有一定的格式。 MarkDown 的优点在于，它用简洁的语法代替了排版。而不像一般我们用的处理软件 Word或 Pages 有大量的排版、字体设置。它使我们专注于内容的编写。 MarkDown 不仅支持文字排版，还支持插入 图片，连接 ，视频，音频 等。而这些操作我们都可以只用键盘完成。 MarkDown 优点 使我们专注于内容，而不用再去使用鼠标进行排版 可以导出为 PDF、 HTML以及.md 本身的格式文件。 上手简单 二、 MacDown编辑器 在线 MacDown编辑器 现在多个 论坛或者博客都支持markdown 语法，例如：CSDN、 简书等。 MAC系统专用的MarkDown编辑器为 MacDown 下载地址:http://macdown.uranusjr.com MacDown 是一款即简单又容易使用的 MarkDown编辑器。 MacDown即可以把 内容导出为 HTML文件 、PDF文件，还可以实时预览。 比如：左边是 内容，右边是 实时预览。 macDown特性 支持原始的 MarkDown语言，并且有更多功能 支持实时预览 三、常用语法换行 在 markdown 语法中，使用两个空格 + 回车换行 空格 空格 +回车 或者 使用两个回车换行 回车回车 标题 标题有两种方式 使用文字 + 一行= 号，表示1级标题，文字 +一行 ---减号，2级标题 使用文字 + 多个#号 标题使用 文字 1行等号 表示1级标题文字 ------- 1行减号 表示2级标题 标题1或者 标题1通常我们使用 #号，来标记 标题等级。如下所示： Header 1Header 2Header 3Header 4Header 5Header 6文本样式 粗体**粗体** 粗体 斜体*斜体* 删除线~~删除线~~需要设置偏好设置 preferences-&gt;MarkDown-&gt;Strikethrough ==高亮====高亮==需要支持高亮 preferences-&gt;MarkDown-&gt;highlight 段落段落与 段落之间一定要空一行 水平线-- 两个减号表示实线，--- 三个减号表示虚线 – 图片 插入图片格式： ![图片说明](图片链接) 图片链接可以为本地链接，也可以为 网络链接。 本地链接，需要在 ( )小括号里面需要填写图片在本地的地址。 本篇文章MarkDown介绍.md路径 和图片 avatar.jpg所在文件夹在同一个路径下,因此先使用点. 号获取当前路径，然后使用./images 获取图片文件夹路径，进一步获取图片路径 图片路径: ./images/avatar.jpg 例如：本地图片 如果是 网络图片链接，小括号里面直接填写图片的网络链接即可。 例如：网络图片 引用 引用内容使用 右尖括号&gt; + 文字， 支持多级引用使用多个 右尖括号&gt;，表示多级引用。 这里是引用内容 二级引用 三级引用 插入代码 markdown 支持插入代码，使用 三个上点号 ```开头，和三个上点号结尾 ```。代码放在中间，例如： 1NSLog(@&quot;这里是插入的代码&quot;); 插入表格 mardown 插入表格，使用以下语法: | 列名 | |:----:|水平排列模式。 | :-- |居左， | :---: |居中, | ---: |居右。 12345| 列1 |列2 | 列3 ||:--- |:---:|---:|| 居左 |居中 | 居右| | 单元格1 |单元格列2 | 单元格列3 ||:— |:—: |—: || 居左 |居中 | 居右 | 插入视频 markdown 支持 html语法，因此可以通过&lt;iframe&gt; &lt;/iframe&gt;标签插入视频。 1&lt;iframe height= 600 width= 100% src=&quot;http://www.bilibili.com/video/av2993071/&quot; frameborder=0 allowfullscreen&gt;&lt;/iframe&gt; 常见格式和 快捷键 ==MarkDown 常见格式和 快捷键:== ==MacDown 常用快捷键:==]]></content>
      <categories>
        <category>macdown操作手册</category>
      </categories>
      <tags>
        <tag>macdown</tag>
      </tags>
  </entry>
</search>
